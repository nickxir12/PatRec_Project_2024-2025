{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":10611406,"sourceType":"datasetVersion","datasetId":6569340}],"dockerImageVersionId":30887,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true},"colab":{"authorship_tag":"ABX9TyMSJa3XxLl7rvVV5eF0x78J","gpuType":"T4","provenance":[]},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"064bec9d457349bb9fa6a559339e9263":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_c9bf43e30b5a499a8de4604dc3f10ee2","IPY_MODEL_17166645b0b14019a9f5fe3d70b6caa5","IPY_MODEL_e451f4ad11bc44f8ab881eed658a8ee3"],"layout":"IPY_MODEL_ceb7ec9cff0049c098ac4b5fc5b6bd3c"}},"07c3736f38804f78bea83bb64c695cac":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"0ff27ff9889744e6af586debee44669c":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":"inline-flex","flex":null,"flex_flow":"row wrap","grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"100%"}},"17166645b0b14019a9f5fe3d70b6caa5":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_1776d91874314cd0ab3df42e1b77bd5d","max":100,"min":0,"orientation":"horizontal","style":"IPY_MODEL_915f46f7e6694bf0b14a91ced2256596","value":100}},"1776d91874314cd0ab3df42e1b77bd5d":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":"2","flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2c00be62ed5f48868daac8e39944ba63":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_740bfc3868e947e68c87f28690b96945","placeholder":"​","style":"IPY_MODEL_73b20e21e4394b6c9326c75594d6f062","value":"Loss: 7.6e+00|1.2e+01. Acc: 11.7%|12.5%: 100%"}},"30e1fcaaa18c40fcbb2182e33df28ea1":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5c0b6a5234ea48e3bf8fa9fb04e7442d","placeholder":"​","style":"IPY_MODEL_ccfc9ef4719e4aef9379f11160003ce1","value":" 100/100 [04:53&lt;00:00,  3.31s/it]"}},"328beb9c29ed4dc094b6e476734a725f":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"36d9e94b822a4a5bb069cd474608bdb6":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"37733b27dcd64ffaafd07959bc847f26":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3a3e587d4127443eb3bbae84621d4d06":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4eb47dc8d09747718044ca73cfadc307":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_936aa9172b2d4e0aa2f0cb84c0dabfad","max":100,"min":0,"orientation":"horizontal","style":"IPY_MODEL_07c3736f38804f78bea83bb64c695cac","value":100}},"5c0b6a5234ea48e3bf8fa9fb04e7442d":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"73b20e21e4394b6c9326c75594d6f062":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"740bfc3868e947e68c87f28690b96945":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"915f46f7e6694bf0b14a91ced2256596":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"936aa9172b2d4e0aa2f0cb84c0dabfad":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":"2","flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c9bf43e30b5a499a8de4604dc3f10ee2":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3a3e587d4127443eb3bbae84621d4d06","placeholder":"​","style":"IPY_MODEL_37733b27dcd64ffaafd07959bc847f26","value":"Loss: 7.6e+00|1.2e+01. Acc: 11.7%|12.5%: 100%"}},"ccfc9ef4719e4aef9379f11160003ce1":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ceb7ec9cff0049c098ac4b5fc5b6bd3c":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":"inline-flex","flex":null,"flex_flow":"row wrap","grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"100%"}},"e451f4ad11bc44f8ab881eed658a8ee3":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_328beb9c29ed4dc094b6e476734a725f","placeholder":"​","style":"IPY_MODEL_36d9e94b822a4a5bb069cd474608bdb6","value":" 100/100 [04:51&lt;00:00,  3.11s/it]"}},"fe873b542e0243ebbf591f5bc21ccd2c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_2c00be62ed5f48868daac8e39944ba63","IPY_MODEL_4eb47dc8d09747718044ca73cfadc307","IPY_MODEL_30e1fcaaa18c40fcbb2182e33df28ea1"],"layout":"IPY_MODEL_0ff27ff9889744e6af586debee44669c"}}}}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Idea 4: Samples fitering - online\n\n## Περιγραφή του αλγορίθμου\n- Γίνεται εκπαίδευση με grokfast - EMA. Όταν **appl_sampl_filter** is False έχω μόνο αυτό, ενώ για True εφαρμόζω επιπλέον και την ιδέα 4 για πιο έξυπνη επιλογή δειγμάτων.\n- Ο Dataloader έχει έναν custom sampler (WeightedRandomSampler) ο οποίος κάθε φορά διαλέγει ένα δείγμα με βάση κάποιο βάρος/πιθανότητα.\n- Στην αρχή τα βάρη είναι όλα ίδια (ομοιόμορφη κατανομή) οπότε ο Dataloader λειτουργεί όπως συνήθως διαλέγοντας τυχαία ένα sample.\n- Σε κάθε επανάληψη φτιάχνεται ένα ranking των δειγμάτων (με βάση του πόσο high frequency περιέχει το καθένα) το οποίο χρησιμοποιείται για να αποφασιστεί τι βάρος/πιθανότητα θα δοθεί σε κάθε δείγμα να επιλεγεί για εκπαίδευση. Το διάνυσμα βαρών/πιθανοτήτων ανανεώνεται κάθε **sampling_distr_upd_freq** επαναλήψεις.\n- Στην κατασκευή του διανύσματος βαρών από την συνολική πιθανότητα 1 δίνουμε στα **top_k** δείγματα συνολικά **top_k_sampling_prob** (και στα υπόλοιπα length(dataset) - **top_k** δείγματα δίνουμε συνολικά το υπόλοιπο 1 - **top_k_sampling_prob**).\n- Με **high_freq_better** is True ακολουθούμε την αρχική μας υπόθεση ότι τα δείγματα με high frequency είναι αυτά που θα πρέπει να ταΐσουμε το δίκτυο περισσότερο για να μάθει γρηγορότερα, για False γίνεται το αντίθετο.\n\n## Οδηγίες χρήσης για τρέξιμο\nΠήγαινε στον τίτλο **Execute training (by running main funciton)**. Πήγαινε στο parser.parse_args και όρισε τις τιμές που θες να δοκιμάσεις για grid search. Οι υπερπαράμετροι που σχετίζονται με την ιδέα 4 online είναι:\n\n- **top_k**\n- **top_k_sampling_prob**\n- **high_freq_better**\n- **sampling_distr_upd_freq**: Μάλλον είναι οκ στο 1 γιατί ακόμα και έτσι η εκπαίδευση δεν είναι αργή οπότε δεν έχω λόγο να το αυξήσω.\n\nΑν κάποιος θέλει να τρέξει κάποιες τιμές για το grid search, έχω βάλει στον φάκελο και ένα αρχείο για να σημειώνουμε τις τιμές των υπερπαραμέτρων που δοκίμασε ο καθένας για να μην τρέχουμε όλοι τα ίδια. Βάλτε GPU P100 (νομίζω είναι ελαφρώς καλύτερη), εμένα για τα 100.000 βήματα που έχω βάλει να είναι το default ένα τρέξιμο που κάνω μόνο με grokfast (δηλαδή **appl_sampl_filter** is False) παίρνει περίπου **7 λεπτά** οπότε καλά είμαστε από χρόνο.\n\n","metadata":{}},{"cell_type":"code","source":"import kagglehub\n\n# Maybe this is needed if you want to import private datasets \n# kagglehub.login()\n","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":24569,"status":"ok","timestamp":1737367419894,"user":{"displayName":"Nikolas Xiros","userId":"00495869844002127525"},"user_tz":-120},"id":"f4s6HWPGPSBJ","outputId":"be8dc80d-eeb5-492c-f36e-15ba319dec89","trusted":true,"execution":{"iopub.status.busy":"2025-02-10T17:41:46.741211Z","iopub.execute_input":"2025-02-10T17:41:46.741521Z","iopub.status.idle":"2025-02-10T17:41:47.393716Z","shell.execute_reply.started":"2025-02-10T17:41:46.741491Z","shell.execute_reply":"2025-02-10T17:41:47.393007Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES,\n# THEN FEEL FREE TO DELETE THIS CELL.\n# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n# NOTEBOOK.\n\n# hojjatk_mnist_dataset_path = kagglehub.dataset_download(\"hojjatk/mnist-dataset\")\n\n# The dataset was uploaded from me but I made it public so you too can probably load it with this line\n# _ = kagglehub.dataset_download(\"konstantinosbarkas/mnist-dataset-processed-from-local\")\n\n# print(\"Data source import complete.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-10T17:41:47.394845Z","iopub.execute_input":"2025-02-10T17:41:47.395288Z","iopub.status.idle":"2025-02-10T17:41:47.398708Z","shell.execute_reply.started":"2025-02-10T17:41:47.395254Z","shell.execute_reply":"2025-02-10T17:41:47.397983Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"import sys, os\n# Install the Grokfast library\n!wget https://raw.githubusercontent.com/ironjr/grokfast/main/grokfast.py\n\nsys.path.append(\"/kaggle/working\")\nos.makedirs('/kaggle/working/results/algo_online', exist_ok=True)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-10T17:41:47.400082Z","iopub.execute_input":"2025-02-10T17:41:47.400308Z","iopub.status.idle":"2025-02-10T17:41:47.685661Z","shell.execute_reply.started":"2025-02-10T17:41:47.400288Z","shell.execute_reply":"2025-02-10T17:41:47.684520Z"}},"outputs":[{"name":"stdout","text":"--2025-02-10 17:41:47--  https://raw.githubusercontent.com/ironjr/grokfast/main/grokfast.py\nResolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.110.133, 185.199.109.133, ...\nConnecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 1703 (1.7K) [text/plain]\nSaving to: ‘grokfast.py.5’\n\ngrokfast.py.5       100%[===================>]   1.66K  --.-KB/s    in 0s      \n\n2025-02-10 17:41:47 (29.0 MB/s) - ‘grokfast.py.5’ saved [1703/1703]\n\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"# import argparse\n# import gzip\nimport math\nimport random\n# import struct\nimport time\nfrom argparse import ArgumentParser\n# from collections import Counter, defaultdict, deque\nfrom itertools import islice\n# from pathlib import Path\n# from typing import Dict, List, Literal, Optional\n\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torchvision\nimport torchvision.transforms as transforms\nfrom functorch import grad, vmap\nfrom sklearn.model_selection import train_test_split\nfrom torch.autograd import grad\n\n# from torch.nn.utils.stateless import functional_call, # This is deprecated, use the next one instead\nfrom torch.func import functional_call\nfrom torch.utils.data import DataLoader, Subset, WeightedRandomSampler, Dataset\nfrom tqdm.auto import tqdm\nfrom torch.utils.data import DataLoader\nfrom itertools import islice\nimport torch.nn.functional as F\n\nfrom grokfast import gradfilter_ema,gradfilter_ma\n","metadata":{"executionInfo":{"elapsed":36273,"status":"ok","timestamp":1737367466050,"user":{"displayName":"Nikolas Xiros","userId":"00495869844002127525"},"user_tz":-120},"id":"QLUi9XZMRpId","trusted":true,"execution":{"iopub.status.busy":"2025-02-10T17:41:47.687346Z","iopub.execute_input":"2025-02-10T17:41:47.687666Z","iopub.status.idle":"2025-02-10T17:41:50.840876Z","shell.execute_reply.started":"2025-02-10T17:41:47.687632Z","shell.execute_reply":"2025-02-10T17:41:50.840190Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"import os\nos.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\"  # Enables detailed CUDA error messages","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-10T17:41:50.841640Z","iopub.execute_input":"2025-02-10T17:41:50.842029Z","iopub.status.idle":"2025-02-10T17:41:50.845874Z","shell.execute_reply.started":"2025-02-10T17:41:50.842005Z","shell.execute_reply":"2025-02-10T17:41:50.845024Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-10T17:41:50.846573Z","iopub.execute_input":"2025-02-10T17:41:50.846915Z","iopub.status.idle":"2025-02-10T17:41:50.881830Z","shell.execute_reply.started":"2025-02-10T17:41:50.846884Z","shell.execute_reply":"2025-02-10T17:41:50.881045Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"optimizer_dict = {\"AdamW\": torch.optim.AdamW, \"Adam\": torch.optim.Adam, \"SGD\": torch.optim.SGD}\n\nactivation_dict = {\"ReLU\": nn.ReLU, \"Tanh\": nn.Tanh, \"Sigmoid\": nn.Sigmoid, \"GELU\": nn.GELU}\n\nloss_function_dict = {\"MSE\": nn.MSELoss, \"CrossEntropy\": nn.CrossEntropyLoss}\n","metadata":{"executionInfo":{"elapsed":10,"status":"ok","timestamp":1737367466051,"user":{"displayName":"Nikolas Xiros","userId":"00495869844002127525"},"user_tz":-120},"id":"8hhZpMIuSC4q","trusted":true,"execution":{"iopub.status.busy":"2025-02-10T17:41:50.882629Z","iopub.execute_input":"2025-02-10T17:41:50.882924Z","iopub.status.idle":"2025-02-10T17:41:50.894651Z","shell.execute_reply.started":"2025-02-10T17:41:50.882892Z","shell.execute_reply":"2025-02-10T17:41:50.893882Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"class Block(nn.Module):\n    \"\"\"Causal transformer block\n    \"\"\"\n\n    def __init__(self, dim, num_heads):\n        super().__init__()\n        self.ln_1 = nn.LayerNorm(dim)\n        self.ln_2 = nn.LayerNorm(dim)\n        self.attn = nn.MultiheadAttention(dim, num_heads)\n        self.mlp = nn.Sequential(\n            nn.Linear(dim, dim * 4),\n            nn.GELU(),\n            nn.Linear(dim * 4, dim),\n        )\n\n    def forward(self, x):\n        attn_mask = torch.full(\n            (len(x), len(x)), -float(\"Inf\"), device=x.device, dtype=x.dtype\n        )\n        attn_mask = torch.triu(attn_mask, diagonal=1)\n        attn_mask[torch.isnan(attn_mask)] = 0.0 # fixes all 'nan' on 'mps' device\n\n        x = self.ln_1(x)\n        a, _ = self.attn(x, x, x, attn_mask=attn_mask, need_weights=False)\n        x = x + a\n        m = self.mlp(self.ln_2(x))\n        x = x + m\n        return x\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-10T17:41:50.896820Z","iopub.execute_input":"2025-02-10T17:41:50.897044Z","iopub.status.idle":"2025-02-10T17:41:50.907885Z","shell.execute_reply.started":"2025-02-10T17:41:50.897025Z","shell.execute_reply":"2025-02-10T17:41:50.907057Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\n\nclass Decoder(nn.Module):\n    \"\"\"Causal Transformer Decoder\"\"\"\n\n    def __init__(self, dim=128, num_layers=2, num_heads=4, num_tokens=97, seq_len=5):\n        super().__init__()\n        self.token_embeddings = nn.Embedding(num_tokens, dim)\n        self.position_embeddings = nn.Embedding(seq_len, dim)\n        self.layers = nn.ModuleList([Block(dim, num_heads) for _ in range(num_layers)])\n\n        self.ln_f = nn.LayerNorm(dim)\n        self.head = nn.Linear(dim, num_tokens, bias=False)\n\n    def forward(self, x):\n        # Ensure input is a LongTensor for embeddings\n        x = x.long()\n        \n        h = self.token_embeddings(x)  # Token embeddings\n        batch_size, seq_len = x.shape  # Get batch size and sequence length\n        \n        # Ensure positions are correctly shaped\n        positions = torch.arange(seq_len, device=x.device).expand(batch_size, seq_len)\n        print(f\"positions.min() = {positions.min()}, positions.max() = {positions.max()}\")  # Debug print\n\n        # Ensure positions are within bounds (e.g., between 0 and num_embeddings-1)\n        positions = torch.clamp(positions, 0, self.position_embeddings.num_embeddings - 1)\n        \n        # Convert to long type (required for embedding layer)\n        positions = positions.long()\n        # Get position embeddings\n        position_embeddings = self.position_embeddings(positions)\n\n        # Debugging prints\n        print(f\"x shape: {x.shape}, device: {x.device}\")\n        print(f\"h shape: {h.shape}, device: {h.device}\")\n        print(f\"positions shape: {positions.shape}, device: {positions.device}\")\n        print(f\"position_embeddings shape: {position_embeddings.shape}, device: {position_embeddings.device}\")\n\n        # Ensure embeddings are correctly added\n        if h.shape != position_embeddings.shape:\n            raise ValueError(f\"Shape mismatch: h {h.shape} != position_embeddings {position_embeddings.shape}\")\n\n        h = h + position_embeddings  # Combine token and position embeddings\n        \n        # Pass through Transformer blocks\n        for layer in self.layers:\n            h = layer(h)\n\n        h = self.ln_f(h)\n        logits = self.head(h)\n        return logits\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-10T17:41:50.908935Z","iopub.execute_input":"2025-02-10T17:41:50.909224Z","iopub.status.idle":"2025-02-10T17:41:50.925221Z","shell.execute_reply.started":"2025-02-10T17:41:50.909202Z","shell.execute_reply":"2025-02-10T17:41:50.924365Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"def multiplication_mod_p_data(p, eq_token, op_token):\n    \"\"\"x◦y = x/y (mod p) for 0 ≤ x < p, 0 < y < p\n    \"\"\"\n    x = torch.arange(p)\n    y = torch.arange(1, p)\n    x, y = torch.cartesian_prod(x, y).T\n\n    eq = torch.ones_like(x) * eq_token\n    op = torch.ones_like(x) * op_token\n    result = x * y % p\n\n    # \"All of our experiments used a small transformer trained on datasets of\n    # equations of the form a◦b = c, where each of “a”, “◦”, “b”, “=”, and “c”\n    # is a seperate token\"\n    return torch.stack([x, op, y, eq, result])","metadata":{"executionInfo":{"elapsed":11,"status":"ok","timestamp":1737367466051,"user":{"displayName":"Nikolas Xiros","userId":"00495869844002127525"},"user_tz":-120},"id":"RIifrNowR89e","trusted":true,"execution":{"iopub.status.busy":"2025-02-10T17:41:50.925902Z","iopub.execute_input":"2025-02-10T17:41:50.926116Z","iopub.status.idle":"2025-02-10T17:41:50.943770Z","shell.execute_reply.started":"2025-02-10T17:41:50.926097Z","shell.execute_reply":"2025-02-10T17:41:50.943024Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"def cycle(iterable):\n    while True:\n        for x in iterable:\n            yield x","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-10T17:41:50.944628Z","iopub.execute_input":"2025-02-10T17:41:50.944939Z","iopub.status.idle":"2025-02-10T17:41:50.956452Z","shell.execute_reply.started":"2025-02-10T17:41:50.944907Z","shell.execute_reply":"2025-02-10T17:41:50.955596Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"def custom_collate_fn_2(batch):\n    \"\"\"Custom collate function to handle extra fields in the dataset.\"\"\"\n    images, labels, _, _ = zip(*batch)  # Ignore the indices and extra_fields for loss computation\n    images = torch.stack(images)  # Stack images into a single tensor\n    labels = torch.tensor(labels)  # Convert labels to a tensor\n    return images, labels\n","metadata":{"executionInfo":{"elapsed":212,"status":"ok","timestamp":1737367551771,"user":{"displayName":"Nikolas Xiros","userId":"00495869844002127525"},"user_tz":-120},"id":"zlciE-2nKkLg","trusted":true,"execution":{"iopub.status.busy":"2025-02-10T17:41:50.957235Z","iopub.execute_input":"2025-02-10T17:41:50.957521Z","iopub.status.idle":"2025-02-10T17:41:50.969828Z","shell.execute_reply.started":"2025-02-10T17:41:50.957491Z","shell.execute_reply":"2025-02-10T17:41:50.969072Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"# Added extra fields to keep ema_gra and history\n# In this implementation I use variance metric --> I don't also store deviation metric for memory efficiency\nclass MyAlgo(torch.utils.data.Dataset):\n    def __init__(self, dataset,targets, transform=None):\n        \"\"\"\n        Custom dataset to extend Algorithmic with extra fields.\n        \"\"\"\n        \n        self.data = dataset.data.float()\n        self.targets = targets\n        self.transform = transform\n\n        # Initialize extra fields\n        self.extra_fields = [\n            {\n                \"ema_grad\": 0.0,\n                \"num_updates\": 0,\n                \"variance_metric\": 0.0,\n            }\n            for _ in range(self.data.shape[1])  # Change this from len(self.data) to self.data.shape[1]\n        ]\n        \n    def __getitem__(self, index):\n        print(f\"self.data shape: {self.data.shape}\")\n        print(f\"self.targets shape: {self.targets.shape}\")\n        print(f\"Index: {index}\")\n        \n        # Extracting the indices correctly\n        if isinstance(index, tuple):\n            row_idx = index[0]\n            col_idx = index[1]\n        else:\n            row_idx = index\n            col_idx = None\n        \n        # Ensure valid indexing\n        if col_idx is None:\n            x, target = self.data[row_idx], self.targets[row_idx]\n        else:\n            x, target = self.data[:, col_idx], self.targets[col_idx]\n        \n        # Normalize image data if needed\n        x = torch.tensor(x).float() / 255.0  # Ensure x is a tensor and normalize it to [0, 1]\n        \n        # Apply any other transformations if they exist\n        if self.transform:\n            x = self.transform(x)\n        \n        # Handle slicing case separately\n        if isinstance(index, slice):\n            # If index is a slice, return corresponding `extra_field` entries\n            extra_fields_subset = self.extra_fields[index]\n            if isinstance(extra_fields_subset, list):\n                # Ensure we are accessing a list of dictionaries\n                if isinstance(extra_fields_subset[0], dict):\n                    ema_grad = [entry[\"ema_grad\"] for entry in extra_fields_subset]\n                    num_updates = [entry[\"num_updates\"] for entry in extra_fields_subset]\n                    variance_metric = [entry[\"variance_metric\"] for entry in extra_fields_subset]\n                else:\n                    raise ValueError(f\"Expected list of dictionaries, but got: {type(extra_fields_subset[0])}\")\n            else:\n                raise ValueError(f\"Expected extra_fields to be a list of dictionaries, but got: {type(extra_fields_subset)}\")\n        else:\n            # Normal index access, fetch the dictionary for a specific index\n            extra_field = self.extra_fields[index]\n            \n            if isinstance(extra_field, dict):\n                ema_grad = extra_field[\"ema_grad\"]\n                num_updates = extra_field[\"num_updates\"]\n                variance_metric = extra_field[\"variance_metric\"]\n            else:\n                raise ValueError(f\"Expected extra_field to be a dictionary, but got: {type(extra_field)}\")\n        \n        # Return x, the relevant extra fields, and target\n        return x, ema_grad, num_updates, variance_metric, target\n\n\n\n    def __len__(self):\n        return len(self.data)\n        \n    def update_fields(self, indices, grad_stats, ema_alpha=0.9):\n        \"\"\"\n        Update the extra fields for specified dataset indices.\n        \"\"\"\n\n        for idx, grad in zip(indices, grad_stats):\n            # Update EMA\n            sample_field = self.extra_fields[idx]\n\n            current_ema = sample_field[\"ema_grad\"]\n            updated_ema = ema_alpha * current_ema + (1 - ema_alpha) * grad\n            sample_field[\"ema_grad\"] = updated_ema\n\n            deviation = abs(grad - current_ema)\n\n            num_updates = sample_field[\"num_updates\"] + 1  # Increment the update count\n            \n            current_avg_deviation = sample_field[\"variance_metric\"] ** 0.5\n            new_avg_deviation = ((current_avg_deviation * (num_updates - 1)) + deviation) / num_updates\n\n            sample_field[\"num_updates\"] = num_updates\n\n            # Variance estimate (for higher sensitivity to fast changes)\n            sample_field[\"variance_metric\"] = new_avg_deviation**2\n            \n    @property\n    def shape(self):\n        \"\"\"\n        Mimics the behavior of a tensor's shape by returning the shape of the dataset.\n        \"\"\"\n        return self.data.shape[1]\n        \n    def split(self, batch_size, dim=0):\n        \"\"\"\n        Splits the dataset into batches of size `batch_size` along the specified dimension.\n        Returns a list of `MyAlgo` instances (or whatever splitting method you prefer).\n        \"\"\"\n        # Assuming self.data is a tensor of shape (num_samples, features)\n        num_samples = len(self.data)\n        batch_indices = torch.arange(0, num_samples, batch_size)\n\n        # Create a list to hold the batched datasets\n        batched_datasets = []\n\n        for i in batch_indices:\n            # Slice the data tensor into batches\n            batch_data = self.data[i:i + batch_size]\n            batch_targets = self.targets[i:i + batch_size]\n            batch_extra_fields = self.extra_fields[i:i + batch_size]\n            \n            # Create a new MyAlgo instance for each batch\n            batched_datasets.append(MyAlgo(batch_data, batch_targets, self.transform))\n        \n        return batched_datasets\n        \n    def to(self, device):\n        \"\"\"Move dataset to the specified device.\"\"\"\n        self.data = self.data.to(device)\n        self.targets = self.targets.to(device)  # Fix this line, use self.targets instead of s\n        return self","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-10T17:42:55.123720Z","iopub.execute_input":"2025-02-10T17:42:55.124180Z","iopub.status.idle":"2025-02-10T17:42:55.144117Z","shell.execute_reply.started":"2025-02-10T17:42:55.124148Z","shell.execute_reply":"2025-02-10T17:42:55.143087Z"}},"outputs":[],"execution_count":21},{"cell_type":"code","source":"def custom_collate_fn(batch):\n    x, labels, indices, extra_fields = zip(*batch)\n    x = torch.stack(x)  # Stack inputs into a single tensor\n    labels = torch.tensor(labels)  # Convert labels to a tensor\n    return x, labels, indices, extra_fields","metadata":{"executionInfo":{"elapsed":215,"status":"ok","timestamp":1737367559166,"user":{"displayName":"Nikolas Xiros","userId":"00495869844002127525"},"user_tz":-120},"id":"zif6Q-IEjFJ7","trusted":true,"execution":{"iopub.status.busy":"2025-02-10T17:41:50.989351Z","iopub.execute_input":"2025-02-10T17:41:50.989647Z","iopub.status.idle":"2025-02-10T17:41:51.005236Z","shell.execute_reply.started":"2025-02-10T17:41:50.989597Z","shell.execute_reply":"2025-02-10T17:41:51.004399Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"# Needed for per sample gradient computations\ndef select_random_subset(tensor, percentage, seed=42):\n    \"\"\"\n    Flatten the parameter dimensions for each batch sample, select a percentage of elements,\n    and return a tensor with shape [batch_size, selected_elements].\n\n    Args:\n        tensor (torch.Tensor): The gradient tensor of shape [batch_size, *parameter_dims].\n        percentage (float): The percentage of elements to select.\n        seed (int): Random seed for reproducibility.\n\n    Returns:\n        torch.Tensor: A tensor of shape [batch_size, selected_elements].\n    \"\"\"\n    batch_size, *param_dims = tensor.shape  # Extract batch and parameter dimensions\n    total_params = torch.prod(torch.tensor(param_dims))  # Total parameters per sample\n    subset_size = int(total_params * percentage)  # 20% of parameters\n\n    # Set seed for reproducibility\n    random.seed(seed)\n    indices = random.sample(range(total_params), subset_size)  # Random indices for selection\n\n    # Flatten parameter dimensions and select elements for each batch\n    flat_tensor = tensor.view(batch_size, -1)  # Flatten parameter dimensions for each sample\n    selected_subset = flat_tensor[:, indices]  # Select the same random indices across the batch\n\n    return selected_subset\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-10T17:41:51.005965Z","iopub.execute_input":"2025-02-10T17:41:51.006225Z","iopub.status.idle":"2025-02-10T17:41:51.021269Z","shell.execute_reply.started":"2025-02-10T17:41:51.006205Z","shell.execute_reply":"2025-02-10T17:41:51.020676Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"# Needed for online sample filtering\ndef rank_to_sampling_weights(my_dataset, top_k, top_k_sampling_prob, high_freq_better):\n    \"\"\"\n    Rank samples by variance_metric and assign sampling weights.\n\n    Parameters:\n    - my_dataset: MyMNIST object.\n    - top_k: Fraction of top samples to assign higher sampling probability.\n    - top_k_sampling_prob: Probability assigned to the top_k fraction of samples.\n\n    Returns:\n    - new_weights: List of sampling weights for each sample.\n    \"\"\"\n    # Calculate the number of top_k samples\n    num_samples = len(my_dataset)\n    top_k_count = int(top_k * num_samples)\n\n    # Sort indices by variance_metric in descending order\n    sorted_indices = sorted(\n        range(num_samples),\n        key=lambda idx: my_dataset.dataset.extra_fields[idx][\"variance_metric\"],\n        reverse=high_freq_better,\n    )\n\n    # Initialize new_weights with zeros\n    new_weights = [0.0] * num_samples\n\n    # Assign weights to the top_k samples\n    for idx in sorted_indices[:top_k_count]:\n        new_weights[idx] = top_k_sampling_prob / top_k_count\n\n    # Assign weights to the rest of the samples\n    for idx in sorted_indices[top_k_count:]:\n        new_weights[idx] = (1 - top_k_sampling_prob) / (num_samples - top_k_count)\n\n    return new_weights\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-10T17:41:51.022107Z","iopub.execute_input":"2025-02-10T17:41:51.022307Z","iopub.status.idle":"2025-02-10T17:41:51.035006Z","shell.execute_reply.started":"2025-02-10T17:41:51.022279Z","shell.execute_reply":"2025-02-10T17:41:51.034357Z"}},"outputs":[],"execution_count":16},{"cell_type":"markdown","source":"## def main","metadata":{}},{"cell_type":"code","source":"def main(args):\n    torch.manual_seed(args.seed)\n\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    \n    eq_token = args.p\n    op_token = args.p + 1\n    \n    # Create model\n    model = Decoder(\n        dim=128, num_layers=2, num_heads=4, num_tokens=args.p + 2, seq_len=5\n    ).to(device)\n    print(model)\n    nparams = sum([p.numel() for p in model.parameters() if p.requires_grad])\n    print(f'Total number of parameters: {nparams}')\n    for name, param in model.named_parameters():\n        print(name)\n\n    data = multiplication_mod_p_data(args.p, eq_token, op_token)\n    \n    # Split the subset into training and validation sets\n    split_idx = data.shape[1] // 2\n    perm = torch.randperm(data.shape[1])\n    train_idx = perm[:split_idx]\n    valid_idx = perm[split_idx:]\n    train_data = MyAlgo(data[:, train_idx], targets=data[:, train_idx])\n    valid_data = MyAlgo(data[:, valid_idx], targets=data[:, valid_idx])\n\n    # Create initial weights for uniform sampling\n    weights = [1.0] * len(train_data)\n    sampler = WeightedRandomSampler(weights, len(weights))\n\n    # DataLoader\n    train_loader = DataLoader(train_data, batch_size=args.batch_size, sampler=sampler, collate_fn=custom_collate_fn)\n\n    data_iter = cycle(train_loader)\n    \n    activation_fn = activation_dict[args.activation]\n\n    # Optimizer\n    optimizer = getattr(torch.optim, args.optimizer)(\n        model.parameters(),\n        lr=args.lr,\n        weight_decay=args.weight_decay,\n        betas=(args.beta1, args.beta2),\n    )\n\n    # Scheduler\n    scheduler = torch.optim.lr_scheduler.LambdaLR(\n        optimizer, lambda update: 1 if update > 10 else update / 10\n    )\n    \n    steps_per_epoch = math.ceil(data.shape[0] / args.batch_size)\n\n    # Start Training below\n    its, train_acc, val_acc, train_loss, val_loss = [], [], [], [], []\n    grads = None\n    i = 0\n\n    # For logging network weights.\n    net_its, nets = [], []\n\n    stable_steps = 0\n    stable_threshold = 10\n    reached_early_stop = False\n    steps_to_reach_val_acc = None\n\n    for e in tqdm(range(int(args.budget) // steps_per_epoch)):\n\n        # randomly shuffle train data \n        train_data.data = train_data.data[:, torch.randperm(train_data.data.shape[1])]\n\n        for data, is_train in [(train_data, True), (valid_data, False)]:\n\n            model.train(is_train)\n            total_loss = 0\n            total_acc = 0\n\n            # Unpack data\n            x, ema_grad, num_updates, variance_metric, target = data  \n            dl = torch.split(data, args.batch_size, dim=0)\n            \n            for input in dl:\n                input = input.to(device)\n\n                with torch.set_grad_enabled(is_train):\n                    x, ema_grad, num_updates, variance_metric, target = input \n                    print(x.shape)\n                    print(x)\n                    logits = model(x)  # Model forward pass\n                    logits = logits[-1].float()  # Ensure logits are in float32\n                    target = input[-1].long()  # Ensure target is long (int64)\n\n                    loss = F.cross_entropy(logits, target)  # Compute the loss\n                    total_loss += loss.item() * input.shape[-1]\n                    \n                if is_train:\n                    model.zero_grad()\n                    loss.backward()\n\n                    # Gradient filtering logic\n                    trigger = i < 500 if args.two_stage else False\n                    if args.filter == \"none\":\n                        pass\n                    elif args.filter == \"ma\":\n                        grads = gradfilter_ma(model, grads=grads, window_size=args.window_size, lamb=args.lamb, trigger=trigger)\n                    elif args.filter == \"ema\":\n                        grads = gradfilter_ema(model, grads=grads, alpha=args.alpha, lamb=args.lamb)\n                    else:\n                        raise ValueError(f\"Invalid gradient filter type `{args.filter}`\")\n\n                    optimizer.step()\n                    scheduler.step()\n                    i += 1\n                    \n                # Compute accuracy\n                acc = (logits[-1].argmax(-1) == input[-1]).float().mean()\n                total_acc += acc.item() * input.shape[-1]\n\n            if is_train:\n                train_acc.append(total_acc / train_data.shape[-1])\n                train_loss.append(total_loss / train_data.shape[-1])\n                its.append(i)\n            else:\n                val_acc.append(total_acc / valid_data.shape[-1])\n                val_loss.append(total_loss / valid_data.shape[-1])\n\n        # Update sampling distribution periodically\n        if args.apply_sample_filter and e % args.sampling_distr_upd_freq == 0:\n            new_weights = rank_to_sampling_weights(train_data, args.top_k, args.top_k_sampling_prob, args.high_freq_better)\n            new_sampler = WeightedRandomSampler(new_weights, num_samples=len(train_data), replacement=True)\n            train_loader = DataLoader(\n                train_data,\n                batch_size=args.batch_size,\n                sampler=new_sampler,\n                collate_fn=custom_collate_fn\n            )\n            del data_iter\n            data_iter = cycle(train_loader)\n\n   \n              # Update sample distribution based on gradient statistics\n\n        # per-sample gradient computations for the Decoder model\n        if args.appl_sampl_filter:\n            # Define a function for forward + loss computation\n            def compute_loss_vmap(params, buffers, model, x, y):\n                # Forward pass through the model\n                logits = model(x)  # `x` is the input batch\n        \n                # Here, we assume the target `y` corresponds to the expected output for classification\n                loss = F.cross_entropy(logits[-1], y)  # Loss computed using the output of the final layer\n                return loss.mean()\n        \n            # Prepare model parameters and buffers\n            params_and_buffers = {**dict(model.named_parameters()), **dict(model.named_buffers())}\n            \n            # Separate the parameters that require gradients and those that don't\n            params = {k: v for k, v in params_and_buffers.items() if v.requires_grad}\n            buffers = {k: v for k, v in params_and_buffers.items() if not v.requires_grad}\n            \n            # Create the gradient function using torch.autograd.grad or vmap\n            gradient_fn = grad(compute_loss_vmap)\n            \n            # Initialize EMA and metric history for each sample (if necessary)\n            gradient_ema = [0.0 for _ in range(len(train_subset))]  # If you're storing gradient EMA for each sample\n\n        \n        if args.appl_sampl_filter and e % args.sampling_distr_upd_freq == 0:\n            # -----------------------------------------------------------------\n            # Gradient Stats: Capture gradients for each sample\n            # -----------------------------------------------------------------\n            with torch.no_grad():\n                # Capture gradients for the layers dynamically\n                per_sample_grads = vmap(gradient_fn, in_dims=(None, None, None, 0, 0))(\n                    params, buffers, model, x, labels\n                )\n            \n                # Extract gradients for the target layers\n                last_layer_grad = per_sample_grads[\"layers.1.mlp.2.weight\"]  # Last Linear layer in the second block\n                second_last_layer_grad = per_sample_grads[\"layers.0.mlp.2.weight\"]  # Last Linear layer in the first block\n                final_layer_grad = per_sample_grads[\"head.weight\"]  # Final output layer\n            \n                # Select a subset of gradients (percentage selection as before)\n                percentage_s_l = 0.2\n                percentage_l = 1\n                selected_last = select_random_subset(last_layer_grad, percentage_l, seed=42)\n                selected_second_last = select_random_subset(second_last_layer_grad, percentage_s_l, seed=42)\n                selected_final = select_random_subset(final_layer_grad, percentage_s_l, seed=42)  # Adding final layer gradient\n            \n                # Compute the average of selected gradients and detach\n                selected_last_avg = selected_last.mean(dim=-1).detach().cpu()\n                selected_second_last_avg = selected_second_last.mean(dim=-1).detach().cpu()\n                selected_final_avg = selected_final.mean(dim=-1).detach().cpu()  # Average for the final layer\n            \n                # Combine the averages of selected gradients\n                total_avg = (selected_last_avg + selected_second_last_avg + selected_final_avg) / 3\n\n            # Update the dataset with the computed average gradients\n            train_data.dataset.update_fields(train_idx, total_avg, args.ema_alpha_sampl_rank)\n        \n        # Early Stopping Logic\n        val_acc_last = val_acc[-1] if len(val_acc) > 0 else 0\n        if val_acc_last >= 0.92 and steps_to_reach_val_acc is None:\n            steps_to_reach_val_acc = i\n\n        # Check for stable performance\n        if val_acc_last > 0.9:\n            stable_steps += 1\n        else:\n            stable_steps = 0  # Reset counter if accuracy drops below 0.85\n\n        if stable_steps >= stable_threshold and val_acc_last >= 0.9 and steps_to_reach_val_acc is not None:\n            reached_early_stop = True\n            print(f\"Validation accuracy of 0.92 reached and remained > 0.9 for {stable_threshold} steps at step {i}\")\n\n        if reached_early_stop:\n            print(\"Early stopping triggered.\")\n            break\n\n\n    # Save results\n    specific_result_dir = f\"algo_{args.label}.pt\"\n    results_filename = os.path.join(results_dir, specific_result_dir)\n    torch.save(\n        {\n            \"its\": its,\n            \"train_acc\": train_acc,\n            \"train_loss\": train_loss,\n            \"val_acc\": val_acc,\n            \"val_loss\": val_loss,\n            \"steps_to_reach\": None,  # Steps to reach validation accuracy\n            \"model_state_dict\": model.state_dict(),\n        },\n        results_filename,\n    )\n\n    print(f\"\\nTraining complete!\")\n    print(f\"Steps to reach 0.9 validation accuracy: {steps_to_reach_val_acc}\")\n","metadata":{"executionInfo":{"elapsed":221,"status":"ok","timestamp":1737370352760,"user":{"displayName":"Nikolas Xiros","userId":"00495869844002127525"},"user_tz":-120},"id":"LWPwaBWpSF52","trusted":true,"execution":{"iopub.status.busy":"2025-02-10T17:49:19.496298Z","iopub.execute_input":"2025-02-10T17:49:19.496800Z","iopub.status.idle":"2025-02-10T17:49:19.517224Z","shell.execute_reply.started":"2025-02-10T17:49:19.496754Z","shell.execute_reply":"2025-02-10T17:49:19.516388Z"}},"outputs":[],"execution_count":41},{"cell_type":"code","source":"# Remove the extra arguments passed by the Jupyter Notebook kernel\nsys.argv = [\"\"]\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-10T17:49:20.808141Z","iopub.execute_input":"2025-02-10T17:49:20.808436Z","iopub.status.idle":"2025-02-10T17:49:20.812266Z","shell.execute_reply.started":"2025-02-10T17:49:20.808413Z","shell.execute_reply":"2025-02-10T17:49:20.811329Z"}},"outputs":[],"execution_count":42},{"cell_type":"code","source":"# Functions for creating plot\nimport os\nimport torch\nimport matplotlib.pyplot as plt\n\ndef analyze_results(label, results_dir=\"/kaggle/working/results/algo_online\"):\n    \"\"\"\n    Loads model results, extracts accuracy/loss data, and generates plots.\n    \n    Args:\n        label (str): Label identifier for the results file.\n        results_dir (str): Directory where results are stored.\n    \n    Returns:\n        None\n    \"\"\"\n\n    # Define file paths\n    filename = f\"mnist_{label}.pt\"\n    results_filename = os.path.join(results_dir, filename)\n\n    filename_plot_acc = f\"mnist_{label}_acc.png\"\n    results_filename_plot_acc = os.path.join(results_dir, filename_plot_acc)\n\n    filename_plot_loss = f\"mnist_{label}_loss.png\"\n    results_filename_plot_loss = os.path.join(results_dir, filename_plot_loss)\n\n    try:\n        # Load results\n        results = torch.load(results_filename, weights_only=True)\n\n        # Extract data\n        its = results[\"its\"]  # Optimization steps\n        train_acc = results[\"train_acc\"]  # Training accuracy\n        val_acc = results[\"val_acc\"]  # Validation accuracy\n        train_loss = results[\"train_loss\"]  # Training loss\n        val_loss = results[\"val_loss\"]  # Validation loss\n        steps_to_reach = results[\"steps_to_reach\"]  # Steps to reach 90% validation accuracy\n\n        print(f\"Steps needed to reach 0.9 validation accuracy: {steps_to_reach}\")\n\n        # Plot Accuracy\n        plt.figure()\n        plt.plot(its, train_acc, label=\"Train Accuracy\")\n        plt.plot(its, val_acc, label=\"Validation Accuracy\")\n\n        # Find and annotate the maximum validation accuracy\n        max_val_acc = max(val_acc)\n        max_val_idx = val_acc.index(max_val_acc)\n        plt.annotate(f\"Max Val Acc: {max_val_acc:.4f}\", \n                     (its[max_val_idx], max_val_acc), \n                     textcoords=\"offset points\", \n                     xytext=(0, 10), \n                     ha='center', \n                     fontsize=10, \n                     color='red')\n\n        plt.legend()\n        plt.title(f\"Accuracy - Grokfast:{args.filter} Sample Filtering:{args.appl_sampl_filter}\")\n        plt.xlabel(\"Optimization Steps\")\n        plt.ylabel(\"Accuracy\")\n        plt.xscale(\"log\", base=10)\n        plt.grid()\n        plt.figtext(0.5, -0.1, f\"Steps to reach val=0.9 = {steps_to_reach}\", \n            ha=\"center\", fontsize=10, style=\"italic\")\n       # plt.savefig(results_filename_plot_acc, dpi=150)\n        plt.show()\n        plt.close()\n\n        print(\"Plots saved successfully.\")\n\n    except FileNotFoundError:\n        print(f\"Error: Results file {results_filename} not found.\")\n    except Exception as e:\n        print(f\"Error while processing {label}: {e}\")\n\ndef plot_all_experiments_together(labels, results_dir=\"/kaggle/working/results/mnist_online\", show_only_val=False):\n    \"\"\"\n    Plots train and validation accuracy for multiple experiments in a single graph.\n    Allows showing only validation accuracy if `show_only_val=True`.\n\n    Args:\n        labels (list of str): List of labels corresponding to result files.\n        results_dir (str): Directory where results are stored.\n        show_only_val (bool): If True, only plots validation accuracy.\n\n    Returns:\n        None\n    \"\"\"\n    plt.figure(figsize=(10, 6))  # Set figure size\n\n    # Generate distinct colors for each experiment\n    base_colors = plt.cm.viridis(np.linspace(0, 1, len(labels)))  \n\n    for i, label in enumerate(labels):\n        results_filename = os.path.join(results_dir, f\"mnist_{label}.pt\")\n\n        try:\n            # Load results\n            results = torch.load(results_filename, weights_only=True)\n            its = results[\"its\"]\n            train_acc = results[\"train_acc\"]\n            val_acc = results[\"val_acc\"]\n\n            # Assign colors for train and validation curves\n            val_color = base_colors[i]  # Primary color for validation\n            train_color = tuple(c * 0.7 for c in base_colors[i])  # Slightly darker shade for train\n            steps_to_reach = results[\"steps_to_reach\"]\n            \n            # Plot validation accuracy (always shown)\n            plt.plot(its, val_acc, label=f\"Validation ({label})\", color=val_color, linestyle=\"solid\")\n            plt.figtext(0.5, -0.1, f\"Steps to reach val=0.9 = {steps_to_reach}\", \n                ha=\"center\", fontsize=10, style=\"italic\")\n        \n            # Plot train accuracy if `show_only_val` is False\n            if not show_only_val:\n                plt.plot(its, train_acc, label=f\"Train ({label})\", color=train_color, linestyle=\"dashed\")\n\n        except FileNotFoundError:\n            print(f\"Warning: Results file {results_filename} not found.\")\n        except Exception as e:\n            print(f\"Error while processing {label}: {e}\")\n\n    plt.legend()\n    plt.title(\"Train & Validation Accuracy for Multiple Experiments\" if not show_only_val else \"Validation Accuracy for Multiple Experiments\")\n    plt.xlabel(\"Optimization Steps\")\n    plt.ylabel(\"Accuracy\")\n    plt.xscale(\"log\", base=10)\n    plt.grid()\n    \n    # Save and show the plot\n    filename = \"combined_train_val_plot.png\" if not show_only_val else \"combined_val_plot.png\"\n    plot_path = os.path.join(results_dir, filename)\n    #plt.savefig(plot_path, dpi=150)\n    plt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-10T17:49:20.991853Z","iopub.execute_input":"2025-02-10T17:49:20.992095Z","iopub.status.idle":"2025-02-10T17:49:21.003460Z","shell.execute_reply.started":"2025-02-10T17:49:20.992073Z","shell.execute_reply":"2025-02-10T17:49:21.002711Z"}},"outputs":[],"execution_count":43},{"cell_type":"markdown","source":"## Execute training (by running main function)","metadata":{}},{"cell_type":"markdown","source":"From now on i just train networks with different configurations every timeand then I print their results after.","metadata":{}},{"cell_type":"markdown","source":"Below is Benchmark:\n\n    * no grokfast applied\n    * no filtering\n    * wd = 0\n\n\n\n            ","metadata":{}},{"cell_type":"code","source":"if __name__ == \"__main__\":\n    # Same as used in paper of Grokfast\n    parser = ArgumentParser(description=\"Train a model on Algorithmic Dataset without custom sampling\")\n    \n    parser.add_argument(\"--label\", type=str, default=\"\")\n    parser.add_argument(\"--seed\", type=int, default=0)\n    parser.add_argument(\"--p\", type=int, default=97)\n    parser.add_argument(\"--budget\", type=int, default=3e5)\n    parser.add_argument(\"--train_points\", type=int, default=1000)\n    parser.add_argument(\"--optimization_steps\", type=int, default=100000)\n    parser.add_argument(\"--batch_size\", type=int, default=512)\n    parser.add_argument(\"--optimizer\", type=str, default=\"Adam\")\n    parser.add_argument(\"--beta1\", type=float, default=0.9)\n    parser.add_argument(\"--beta2\", type=float, default=0.98)\n    parser.add_argument(\"--weight_decay\", type=float, default=0)\n    parser.add_argument(\"--lr\", type=float, default=1e-3)\n    parser.add_argument(\"--initialization_scale\", type=float, default=8.0)\n    parser.add_argument(\"--download_directory\", type=str, default=\".\")\n    parser.add_argument(\"--depth\", type=int, default=3)\n    parser.add_argument(\"--width\", type=int, default=200)\n    parser.add_argument(\"--activation\", type=str, default=\"ReLU\")\n\n    # Grokfast\n    parser.add_argument(\"--filter\", type=str, choices=[\"none\", \"ma\", \"ema\", \"fir\"], default=\"none\")\n    parser.add_argument(\"--alpha\", type=float, default=0.99)\n    parser.add_argument(\"--window_size\", type=int, default=100)\n    parser.add_argument(\"--lamb\", type=float, default=0.1)\n\n    # Ablation studies\n    parser.add_argument(\"--two_stage\", action='store_true')\n    parser.add_argument(\"--save_weights\", action='store_true')\n\n    # Samples ranking\n    parser.add_argument(\"--ema_alpha_sampl_rank\", type=float, default=0.9)\n\n    # Boolean arguements need this due to bad behavior of parser.parse_args\n    def boolean_string(s):\n        if s not in {\"False\", \"True\"}:\n            raise ValueError(\"Not a valid boolean string\")\n        return s == \"True\"\n\n    # These are the hyperparameters related to our online sampling filtering algorithm\n    parser.add_argument(\"--appl_sampl_filter\", type=boolean_string, default=True)  # If False, perform regular training\n    parser.add_argument(\"--sampling_distr_upd_freq\", type=int, default=1)  # How often to update the sampling distribution\n    parser.add_argument(\"--top_k\", type=float, default=0.1)  # Fraction of samples to select more frequently\n    parser.add_argument(\"--top_k_sampling_prob\", type=float, default=0.9)  # Probability of selecting a sample from the top-k\n    parser.add_argument(\"--high_freq_better\", type=boolean_string, default=True)  # If True, samples with higher frequency gradient content are considered better for training\n\n    # -----------------------------------------------------------------\n    # Try different hyperparameter values for your grid search here\n    # -----------------------------------------------------------------\n    args = parser.parse_args(\n        [\n            \"--appl_sampl_filter\", \"False\", # booleans as non strings in order to work\n            \"--sampling_distr_upd_freq\", \"1\", # the rest as strings for some reason\n            \"--top_k\", \"0.1\",\n            \"--top_k_sampling_prob\", \"0.9\",\n            \"--high_freq_better\", \"True\",\n        ]\n    )\n    # -----------------------------------------------------------------\n    # -----------------------------------------------------------------\n\n    # Create arg.label for the filename of the saved results\n    if not args.appl_sampl_filter:\n        args.label = f\"filter{args.filter}_sampling_{args.appl_sampl_filter}\"\n    else:\n        args.label = f\"high_freq_{args.high_freq_better}_top_k_{args.top_k}_top_k_prob_{args.top_k_sampling_prob}_upd_freq_{args.sampling_distr_upd_freq}\"\n\n    # Training with time recording\n\n    # Start the timer\n    start_time = time.time()\n\n    # Call your training function\n    main(args)\n\n    # End the timer\n    end_time = time.time()\n\n    # Calculate elapsed time\n    elapsed_time = end_time - start_time\n\n    # Convert to minutes and seconds (optional)\n    minutes, seconds = divmod(elapsed_time, 60)\n\n    print(f\"Training completed in {int(minutes)} minutes and {int(seconds)} seconds.\")\n    print(f\"label:{args.label}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-10T17:49:21.671860Z","iopub.execute_input":"2025-02-10T17:49:21.672158Z","iopub.status.idle":"2025-02-10T17:49:21.745038Z","shell.execute_reply.started":"2025-02-10T17:49:21.672135Z","shell.execute_reply":"2025-02-10T17:49:21.743933Z"}},"outputs":[{"name":"stdout","text":"Decoder(\n  (token_embeddings): Embedding(99, 128)\n  (position_embeddings): Embedding(5, 128)\n  (layers): ModuleList(\n    (0-1): 2 x Block(\n      (ln_1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n      (ln_2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n      (attn): MultiheadAttention(\n        (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n      )\n      (mlp): Sequential(\n        (0): Linear(in_features=128, out_features=512, bias=True)\n        (1): GELU(approximate='none')\n        (2): Linear(in_features=512, out_features=128, bias=True)\n      )\n    )\n  )\n  (ln_f): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n  (head): Linear(in_features=128, out_features=99, bias=False)\n)\nTotal number of parameters: 422784\ntoken_embeddings.weight\nposition_embeddings.weight\nlayers.0.ln_1.weight\nlayers.0.ln_1.bias\nlayers.0.ln_2.weight\nlayers.0.ln_2.bias\nlayers.0.attn.in_proj_weight\nlayers.0.attn.in_proj_bias\nlayers.0.attn.out_proj.weight\nlayers.0.attn.out_proj.bias\nlayers.0.mlp.0.weight\nlayers.0.mlp.0.bias\nlayers.0.mlp.2.weight\nlayers.0.mlp.2.bias\nlayers.1.ln_1.weight\nlayers.1.ln_1.bias\nlayers.1.ln_2.weight\nlayers.1.ln_2.bias\nlayers.1.attn.in_proj_weight\nlayers.1.attn.in_proj_bias\nlayers.1.attn.out_proj.weight\nlayers.1.attn.out_proj.bias\nlayers.1.mlp.0.weight\nlayers.1.mlp.0.bias\nlayers.1.mlp.2.weight\nlayers.1.mlp.2.bias\nln_f.weight\nln_f.bias\nhead.weight\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/300000 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d2e72668a0574f32a0648c6d8927b2de"}},"metadata":{}},{"name":"stdout","text":"self.data shape: torch.Size([5, 4656])\nself.targets shape: torch.Size([5, 4656])\nIndex: 0\nself.data shape: torch.Size([5, 4656])\nself.targets shape: torch.Size([5, 4656])\nIndex: 1\nself.data shape: torch.Size([5, 4656])\nself.targets shape: torch.Size([5, 4656])\nIndex: 2\nself.data shape: torch.Size([5, 4656])\nself.targets shape: torch.Size([5, 4656])\nIndex: 3\nself.data shape: torch.Size([5, 4656])\nself.targets shape: torch.Size([5, 4656])\nIndex: 4\nself.data shape: torch.Size([5, 4656])\nself.targets shape: torch.Size([5, 4656])\nIndex: 5\nself.data shape: torch.Size([5, 4656])\nself.targets shape: torch.Size([5, 4656])\nIndex: 0\nself.data shape: torch.Size([5, 4656])\nself.targets shape: torch.Size([5, 4656])\nIndex: 1\nself.data shape: torch.Size([5, 4656])\nself.targets shape: torch.Size([5, 4656])\nIndex: 2\nself.data shape: torch.Size([5, 4656])\nself.targets shape: torch.Size([5, 4656])\nIndex: 3\nself.data shape: torch.Size([5, 4656])\nself.targets shape: torch.Size([5, 4656])\nIndex: 4\nself.data shape: torch.Size([5, 4656])\nself.targets shape: torch.Size([5, 4656])\nIndex: 5\n","output_type":"stream"},{"name":"stderr","text":"<ipython-input-21-7a6205a64be1>:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  x = torch.tensor(x).float() / 255.0  # Ensure x is a tensor and normalize it to [0, 1]\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-44-68de4f7f9a73>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m     \u001b[0;31m# Call your training function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m     \u001b[0;31m# End the timer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-41-3b87dba4e59f>\u001b[0m in \u001b[0;36mmain\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m     86\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_grad_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m                     \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mema_grad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_updates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvariance_metric\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m                     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m                     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m                     \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Model forward pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'shape'"],"ename":"AttributeError","evalue":"'tuple' object has no attribute 'shape'","output_type":"error"}],"execution_count":44},{"cell_type":"code","source":"args.label=\"filternone_sampling_False\" analyze_results(args.label)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"if __name__ == \"__main__\":\n    # Same as used in paper of Grokfast\n    parser = ArgumentParser(description=\"Train a model on MNIST without custom sampling\")\n    \n    parser.add_argument(\"--label\", type=str, default=\"\")\n    parser.add_argument(\"--seed\", type=int, default=0)\n    \n    parser.add_argument(\"--train_points\", type=int, default=1000)\n    parser.add_argument(\"--optimization_steps\", type=int, default=100000)\n    parser.add_argument(\"--batch_size\", type=int, default=200)\n    parser.add_argument(\"--loss_function\", type=str, default=\"MSE\") #MSE or CrossEntropy\n    parser.add_argument(\"--optimizer\", type=str, default=\"AdamW\")\n    parser.add_argument(\"--weight_decay\", type=float, default=2.0)\n    parser.add_argument(\"--lr\", type=float, default=1e-3)\n    parser.add_argument(\"--initialization_scale\", type=float, default=8.0)\n    parser.add_argument(\"--download_directory\", type=str, default=\".\")\n    parser.add_argument(\"--depth\", type=int, default=3)\n    parser.add_argument(\"--width\", type=int, default=200)\n    parser.add_argument(\"--activation\", type=str, default=\"ReLU\")\n\n    # Grokfast\n    parser.add_argument(\"--filter\", type=str, choices=[\"none\", \"ma\", \"ema\", \"fir\"], default=\"ema\")\n    parser.add_argument(\"--alpha\", type=float, default=0.8)\n    parser.add_argument(\"--lamb\", type=float, default=0.1)\n\n    # Samples ranking\n    parser.add_argument(\"--ema_alpha_sampl_rank\", type=float, default=0.9)\n\n    # Boolean arguements need this due to bad behavior of parser.parse_args\n    def boolean_string(s):\n        if s not in {\"False\", \"True\"}:\n            raise ValueError(\"Not a valid boolean string\")\n        return s == \"True\"\n\n    # These are the hyperparameters related to our online sampling filtering algorithm\n    parser.add_argument(\"--appl_sampl_filter\", type=boolean_string, default=True)  # If False, perform regular training\n    parser.add_argument(\"--sampling_distr_upd_freq\", type=int, default=1)  # How often to update the sampling distribution\n    parser.add_argument(\"--top_k\", type=float, default=0.1)  # Fraction of samples to select more frequently\n    parser.add_argument(\"--top_k_sampling_prob\", type=float, default=0.9)  # Probability of selecting a sample from the top-k\n    parser.add_argument(\"--high_freq_better\", type=boolean_string, default=True)  # If True, samples with higher frequency gradient content are considered better for training\n\n    # -----------------------------------------------------------------\n    # Try different hyperparameter values for your grid search here\n    # -----------------------------------------------------------------\n    args = parser.parse_args(\n        [\n            \"--appl_sampl_filter\", \"False\", # booleans as non strings in order to work\n            \"--sampling_distr_upd_freq\", \"1\", # the rest as strings for some reason\n            \"--top_k\", \"0.1\",\n            \"--top_k_sampling_prob\", \"0.9\",\n            \"--high_freq_better\", \"True\",\n        ]\n    )\n    # -----------------------------------------------------------------\n    # -----------------------------------------------------------------\n\n    # Create arg.label for the filename of the saved results\n    if not args.appl_sampl_filter:\n        args.label = f\"filter{args.filter}_sampling_{args.appl_sampl_filter}\"\n    else:\n        args.label = f\"high_freq_{args.high_freq_better}_top_k_{args.top_k}_top_k_prob_{args.top_k_sampling_prob}_upd_freq_{args.sampling_distr_upd_freq}\"\n\n    # Training with time recording\n\n    # Start the timer\n    start_time = time.time()\n\n    # Call your training function\n    main(args)\n\n    # End the timer\n    end_time = time.time()\n\n    # Calculate elapsed time\n    elapsed_time = end_time - start_time\n\n    # Convert to minutes and seconds (optional)\n    minutes, seconds = divmod(elapsed_time, 60)\n\n    print(f\"Training completed in {int(minutes)} minutes and {int(seconds)} seconds.\")\n    print(f\"label:{args.label}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-10T17:45:18.119906Z","iopub.execute_input":"2025-02-10T17:45:18.120239Z","iopub.status.idle":"2025-02-10T17:45:18.149790Z","shell.execute_reply.started":"2025-02-10T17:45:18.120217Z","shell.execute_reply":"2025-02-10T17:45:18.148711Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-32-a8ad78f262c0>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;31m# Call your training function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0;31m# End the timer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-28-03f2ddb4f9aa>\u001b[0m in \u001b[0;36mmain\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cuda\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"cpu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0meq_token\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mop_token\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mp\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAttributeError\u001b[0m: 'Namespace' object has no attribute 'p'"],"ename":"AttributeError","evalue":"'Namespace' object has no attribute 'p'","output_type":"error"}],"execution_count":32},{"cell_type":"code","source":"args.label=\"filterema_sampling_False\"\nanalyze_results(args.label)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Define possible values for each parameter\nparam_grid = {\n    \"top_k\": [0.2],  # Convert to float\n    \"top_k_sampling_prob\": [0.7],  # Convert to float\n    \"sampling_distr_upd_freq\": [10],  # Convert to int\n    \"high_freq_better\": [True]  # Boolean parameter\n}\n\n# Generate all combinations of parameters\nparam_combinations = list(itertools.product(*param_grid.values()))\n\n# Run main in a loop for each combination\nfor param_values in param_combinations:\n    # Extract parameter values\n    top_k = param_values[0]\n    top_k_sampling_prob = param_values[1]\n    sampling_distr_upd_freq = param_values[2]\n    high_freq_better = param_values[3]  # Boolean value\n    \n    # Ensure boolean values are correctly formatted as strings for argparse\n    high_freq_better_str = \"True\" if high_freq_better else \"False\"\n\n    # Create args dynamically\n    args_list = [\n        \"--appl_sampl_filter\" , \"True\",\n        \"--top_k\", str(top_k),\n        \"--top_k_sampling_prob\", str(top_k_sampling_prob),\n        \"--sampling_distr_upd_freq\", str(sampling_distr_upd_freq),\n        \"--high_freq_better\", high_freq_better_str,\n        \"--label\", f\"{top_k}_{top_k_sampling_prob}_{sampling_distr_upd_freq}_{high_freq_better}\"\n    ]\n\n    # Debug print statement\n    print(f\"\\nRunning with parameters: {args_list}\")\n\n    # Parse the arguments dynamically\n    args = parser.parse_args(args_list)\n\n    # Call main() with the updated args\n    main(args)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#/kaggle/working/results/mnist_online/mnist_high_freq_True_top_k_0.2_top_k_prob_0.9_upd_freq_1.pt\nargs.label=\"high_freq_True_top_k_0.2_top_k_prob_0.9_upd_freq_1\"\nanalyze_results(args.label)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"    args_list = [\n        \"--appl_sampl_filter\" , \"False\",\n    ]\n\n    # Parse the arguments dynamically\n    args = parser.parse_args(args_list)\n\n    # Call main() with the updated args\n    main(args)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"analyze_results(args.label)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"if __name__ == \"__main__\":\n    # Same as used in paper of Grokfast\n    parser = ArgumentParser(description=\"Train a model on MNIST without custom sampling\")\n    \n    parser.add_argument(\"--label\", type=str, default=\"\")\n    parser.add_argument(\"--seed\", type=int, default=0)\n    \n    parser.add_argument(\"--train_points\", type=int, default=1000)\n    parser.add_argument(\"--optimization_steps\", type=int, default=10000)\n    parser.add_argument(\"--batch_size\", type=int, default=200)\n    parser.add_argument(\"--loss_function\", type=str, default=\"MSE\") #MSE or CrossEntropy\n    parser.add_argument(\"--optimizer\", type=str, default=\"AdamW\")\n    parser.add_argument(\"--weight_decay\", type=float, default=2.0)\n    parser.add_argument(\"--lr\", type=float, default=1e-3)\n    parser.add_argument(\"--initialization_scale\", type=float, default=8.0)\n    parser.add_argument(\"--download_directory\", type=str, default=\".\")\n    parser.add_argument(\"--depth\", type=int, default=3)\n    parser.add_argument(\"--width\", type=int, default=200)\n    parser.add_argument(\"--activation\", type=str, default=\"ReLU\")\n\n    # Grokfast\n    parser.add_argument(\"--filter\", type=str, choices=[\"none\", \"ma\", \"ema\", \"fir\"], default=\"none\")\n    parser.add_argument(\"--alpha\", type=float, default=0.8)\n    parser.add_argument(\"--lamb\", type=float, default=0.1)\n\n    # Samples ranking\n    parser.add_argument(\"--ema_alpha_sampl_rank\", type=float, default=0.9)\n\n    # Boolean arguements need this due to bad behavior of parser.parse_args\n    def boolean_string(s):\n        if s not in {\"False\", \"True\"}:\n            raise ValueError(\"Not a valid boolean string\")\n        return s == \"True\"\n\n    # These are the hyperparameters related to our online sampling filtering algorithm\n    parser.add_argument(\"--appl_sampl_filter\", type=boolean_string, default=True)  # If False, perform regular training\n    parser.add_argument(\"--sampling_distr_upd_freq\", type=int, default=1)  # How often to update the sampling distribution\n    parser.add_argument(\"--top_k\", type=float, default=0.1)  # Fraction of samples to select more frequently\n    parser.add_argument(\"--top_k_sampling_prob\", type=float, default=0.9)  # Probability of selecting a sample from the top-k\n    parser.add_argument(\"--high_freq_better\", type=boolean_string, default=True)  # If True, samples with higher frequency gradient content are considered better for training\n\n    # -----------------------------------------------------------------\n    # Try different hyperparameter values for your grid search here\n    # -----------------------------------------------------------------\n    args = parser.parse_args(\n        [\n            \"--appl_sampl_filter\", \"False\", # booleans as non strings in order to work\n            \"--sampling_distr_upd_freq\", \"1\", # the rest as strings for some reason\n            \"--top_k\", \"0.1\",\n            \"--top_k_sampling_prob\", \"0.9\",\n            \"--high_freq_better\", \"True\",\n        ]\n    )\n    # -----------------------------------------------------------------\n    # -----------------------------------------------------------------\n\n    # Create arg.label for the filename of the saved results\n    if not args.appl_sampl_filter:\n        args.label = f\"filter{args.filter}_sampling_{args.appl_sampl_filter}_v2\"\n    else:\n        args.label = f\"high_freq_{args.high_freq_better}_top_k_{args.top_k}_top_k_prob_{args.top_k_sampling_prob}_upd_freq_{args.sampling_distr_upd_freq}\"\n\n    # Training with time recording\n\n    # Start the timer\n    start_time = time.time()\n\n    # Call your training function\n    main(args)\n\n    # End the timer\n    end_time = time.time()\n\n    # Calculate elapsed time\n    elapsed_time = end_time - start_time\n\n    # Convert to minutes and seconds (optional)\n    minutes, seconds = divmod(elapsed_time, 60)\n\n    print(f\"Training completed in {int(minutes)} minutes and {int(seconds)} seconds.\")\n    print(f\"label:{args.label}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"args.label=\"filternone_sampling_False_v2\"\nanalyze_results(args.label)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"if __name__ == \"__main__\":\n    # Same as used in paper of Grokfast\n    parser = ArgumentParser(description=\"Train a model on MNIST without custom sampling\")\n    \n    parser.add_argument(\"--label\", type=str, default=\"\")\n    parser.add_argument(\"--seed\", type=int, default=1)\n    \n    parser.add_argument(\"--train_points\", type=int, default=1000)\n    parser.add_argument(\"--optimization_steps\", type=int, default=10000)\n    parser.add_argument(\"--batch_size\", type=int, default=200)\n    parser.add_argument(\"--loss_function\", type=str, default=\"MSE\") #MSE or CrossEntropy\n    parser.add_argument(\"--optimizer\", type=str, default=\"AdamW\")\n    parser.add_argument(\"--weight_decay\", type=float, default=2.0)\n    parser.add_argument(\"--lr\", type=float, default=1e-3)\n    parser.add_argument(\"--initialization_scale\", type=float, default=8.0)\n    parser.add_argument(\"--download_directory\", type=str, default=\".\")\n    parser.add_argument(\"--depth\", type=int, default=3)\n    parser.add_argument(\"--width\", type=int, default=200)\n    parser.add_argument(\"--activation\", type=str, default=\"ReLU\")\n\n    # Grokfast\n    parser.add_argument(\"--filter\", type=str, choices=[\"none\", \"ma\", \"ema\", \"fir\"], default=\"none\")\n    parser.add_argument(\"--alpha\", type=float, default=0.8)\n    parser.add_argument(\"--lamb\", type=float, default=0.1)\n\n    # Samples ranking\n    parser.add_argument(\"--ema_alpha_sampl_rank\", type=float, default=0.9)\n\n    # Boolean arguements need this due to bad behavior of parser.parse_args\n    def boolean_string(s):\n        if s not in {\"False\", \"True\"}:\n            raise ValueError(\"Not a valid boolean string\")\n        return s == \"True\"\n\n    # These are the hyperparameters related to our online sampling filtering algorithm\n    parser.add_argument(\"--appl_sampl_filter\", type=boolean_string, default=True)  # If False, perform regular training\n    parser.add_argument(\"--sampling_distr_upd_freq\", type=int, default=1)  # How often to update the sampling distribution\n    parser.add_argument(\"--top_k\", type=float, default=0.1)  # Fraction of samples to select more frequently\n    parser.add_argument(\"--top_k_sampling_prob\", type=float, default=0.9)  # Probability of selecting a sample from the top-k\n    parser.add_argument(\"--high_freq_better\", type=boolean_string, default=True)  # If True, samples with higher frequency gradient content are considered better for training\n\n    # -----------------------------------------------------------------\n    # Try different hyperparameter values for your grid search here\n    # -----------------------------------------------------------------\n    args = parser.parse_args(\n        [\n            \"--appl_sampl_filter\", \"False\", # booleans as non strings in order to work\n            \"--sampling_distr_upd_freq\", \"1\", # the rest as strings for some reason\n            \"--top_k\", \"0.1\",\n            \"--top_k_sampling_prob\", \"0.9\",\n            \"--high_freq_better\", \"True\",\n        ]\n    )\n    # -----------------------------------------------------------------\n    # -----------------------------------------------------------------\n\n    # Create arg.label for the filename of the saved results\n    if not args.appl_sampl_filter:\n        args.label = f\"filter{args.filter}_sampling_{args.appl_sampl_filter}\"\n    else:\n        args.label = f\"high_freq_{args.high_freq_better}_top_k_{args.top_k}_top_k_prob_{args.top_k_sampling_prob}_upd_freq_{args.sampling_distr_upd_freq}\"\n\n    # Training with time recording\n\n    # Start the timer\n    start_time = time.time()\n\n    # Call your training function\n    main(args)\n\n    # End the timer\n    end_time = time.time()\n\n    # Calculate elapsed time\n    elapsed_time = end_time - start_time\n\n    # Convert to minutes and seconds (optional)\n    minutes, seconds = divmod(elapsed_time, 60)\n\n    print(f\"Training completed in {int(minutes)} minutes and {int(seconds)} seconds.\")\n    print(f\"label:{args.label}\")","metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1737367489050,"user":{"displayName":"Nikolas Xiros","userId":"00495869844002127525"},"user_tz":-120},"id":"MawvRmI9yt3T","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\nargs.label=\"filternone_sampling_False\"\nanalyze_results(args.label)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import itertools\n\nparser = ArgumentParser(description=\"Train a model on MNIST without custom sampling\")\n\nparser.add_argument(\"--label\", type=str, default=\"\")\nparser.add_argument(\"--seed\", type=int, default=1)\n\nparser.add_argument(\"--train_points\", type=int, default=1000)\nparser.add_argument(\"--optimization_steps\", type=int, default=10000)\nparser.add_argument(\"--batch_size\", type=int, default=200)\nparser.add_argument(\"--loss_function\", type=str, default=\"MSE\") #MSE or CrossEntropy\nparser.add_argument(\"--optimizer\", type=str, default=\"AdamW\")\nparser.add_argument(\"--weight_decay\", type=float, default=2.0)\nparser.add_argument(\"--lr\", type=float, default=1e-3)\nparser.add_argument(\"--initialization_scale\", type=float, default=8.0)\nparser.add_argument(\"--download_directory\", type=str, default=\".\")\nparser.add_argument(\"--depth\", type=int, default=3)\nparser.add_argument(\"--width\", type=int, default=200)\nparser.add_argument(\"--activation\", type=str, default=\"ReLU\")\n\n# Grokfast\nparser.add_argument(\"--filter\", type=str, choices=[\"none\", \"ma\", \"ema\", \"fir\"], default=\"ema\")\nparser.add_argument(\"--alpha\", type=float, default=0.8)\nparser.add_argument(\"--lamb\", type=float, default=1)\n\n# Samples ranking\nparser.add_argument(\"--ema_alpha_sampl_rank\", type=float, default=0.9)\n\n# Boolean arguements need this due to bad behavior of parser.parse_args\ndef boolean_string(s):\n    if s not in {\"False\", \"True\"}:\n        raise ValueError(\"Not a valid boolean string\")\n    return s == \"True\"\n\n# These are the hyperparameters related to our online sampling filtering algorithm\nparser.add_argument(\"--appl_sampl_filter\", type=boolean_string, default=True)  # If False, perform regular training\nparser.add_argument(\"--sampling_distr_upd_freq\", type=int, default=1)  # How often to update the sampling distribution\nparser.add_argument(\"--top_k\", type=float, default=0.1)  # Fraction of samples to select more frequently\nparser.add_argument(\"--top_k_sampling_prob\", type=float, default=0.9)  # Probability of selecting a sample from the top-k\nparser.add_argument(\"--high_freq_better\", type=boolean_string, default=True)  # If True, samples with higher frequency gradient content are considered better for training\n\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Define possible values for each parameter\nparam_grid = {\n    \"top_k\": [0.2],  # Convert to float\n    \"top_k_sampling_prob\": [0.6, 0.8],  # Convert to float\n    \"sampling_distr_upd_freq\": [100],  # Convert to int\n    \"high_freq_better\": [False, True]  # Boolean parameter\n}\n\n# Generate all combinations of parameters\nparam_combinations = list(itertools.product(*param_grid.values()))\n\n# Run main in a loop for each combination\nfor param_values in param_combinations:\n    # Extract parameter values\n    top_k = param_values[0]\n    top_k_sampling_prob = param_values[1]\n    sampling_distr_upd_freq = param_values[2]\n    high_freq_better = param_values[3]  # Boolean value\n    \n    # Ensure boolean values are correctly formatted as strings for argparse\n    high_freq_better_str = \"True\" if high_freq_better else \"False\"\n\n    # Create args dynamically\n    args_list = [\n        \"--top_k\", str(top_k),\n        \"--top_k_sampling_prob\", str(top_k_sampling_prob),\n        \"--sampling_distr_upd_freq\", str(sampling_distr_upd_freq),\n        \"--high_freq_better\", high_freq_better_str,\n        \"--label\", f\"{top_k}_{top_k_sampling_prob}_{sampling_distr_upd_freq}_{high_freq_better}\"\n    ]\n\n    # Debug print statement\n    print(f\"\\nRunning with parameters: {args_list}\")\n\n    # Parse the arguments dynamically\n    args = parser.parse_args(args_list)\n\n    # Call main() with the updated args\n    main(args)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"labels = [\n    f\"{param_values[0]}_{param_values[1]}_{param_values[2]}_{param_values[3]}\"\n    for param_values in param_combinations\n]\n\n\n# Compare multiple accuracy curves on the same plot\nplot_all_experiments_together(labels, show_only_val=True)","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}