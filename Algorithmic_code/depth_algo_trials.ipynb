{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyMvprDhVz/uv3HMfiXrd8OF"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"RLNMqt_y8y0J"},"outputs":[],"source":["#Experimenting with depth - filtering  code for Algorithmic dataset\n","#   Omada 2 -- Grokfast experiments"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"f4s6HWPGPSBJ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1737227427357,"user_tz":-120,"elapsed":104380,"user":{"displayName":"Nikolas Xiros","userId":"00495869844002127525"}},"outputId":"fcfd5a42-3b66-43a2-b664-5f8096dd96a9"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gADYjdBHN1cg"},"outputs":[],"source":["# from google.colab import files\n","# files.upload()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":402,"status":"ok","timestamp":1737227479587,"user":{"displayName":"Nikolas Xiros","userId":"00495869844002127525"},"user_tz":-120},"id":"pUw0ejsKP3sp","outputId":"bfc695bc-13c0-4bd0-e2a3-b235bcc93e69"},"outputs":[{"output_type":"stream","name":"stdout","text":[" algorithmic\t\t\t\t      Grokking_mnist_v1.ipynb   __pycache__\n"," grokfast.py\t\t\t\t      Grokking_qm9_v1.ipynb     requirements.txt\n","'Grokking and how to accelerate it.gslides'   Grokking_qm9_v2.ipynb     results\n"]}],"source":["!ls /content/drive/MyDrive/PatRec_Project_Shared_Folder/"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qdXeIGW_QC3w"},"outputs":[],"source":["import sys\n","sys.path.append('/content/drive/MyDrive/PatRec_Project_Shared_Folder')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5041,"status":"ok","timestamp":1737227486930,"user":{"displayName":"Nikolas Xiros","userId":"00495869844002127525"},"user_tz":-120},"id":"C13vv8V-KHUI","outputId":"06936ddd-3dc3-4e68-fc2a-107ad8c98854"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from -r /content/drive/MyDrive/PatRec_Project_Shared_Folder/requirements.txt (line 1)) (3.8.0)\n","Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from -r /content/drive/MyDrive/PatRec_Project_Shared_Folder/requirements.txt (line 2)) (2.5.1+cu121)\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from -r /content/drive/MyDrive/PatRec_Project_Shared_Folder/requirements.txt (line 3)) (0.20.1+cu121)\n","Collecting torch_geometric (from -r /content/drive/MyDrive/PatRec_Project_Shared_Folder/requirements.txt (line 4))\n","  Downloading torch_geometric-2.6.1-py3-none-any.whl.metadata (63 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.1/63.1 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from -r /content/drive/MyDrive/PatRec_Project_Shared_Folder/requirements.txt (line 5)) (2.2.2)\n","Requirement already satisfied: seaborn in /usr/local/lib/python3.10/dist-packages (from -r /content/drive/MyDrive/PatRec_Project_Shared_Folder/requirements.txt (line 6)) (0.13.2)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from -r /content/drive/MyDrive/PatRec_Project_Shared_Folder/requirements.txt (line 7)) (4.67.1)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from -r /content/drive/MyDrive/PatRec_Project_Shared_Folder/requirements.txt (line 8)) (1.13.1)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r /content/drive/MyDrive/PatRec_Project_Shared_Folder/requirements.txt (line 1)) (1.3.1)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r /content/drive/MyDrive/PatRec_Project_Shared_Folder/requirements.txt (line 1)) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r /content/drive/MyDrive/PatRec_Project_Shared_Folder/requirements.txt (line 1)) (4.55.3)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r /content/drive/MyDrive/PatRec_Project_Shared_Folder/requirements.txt (line 1)) (1.4.7)\n","Requirement already satisfied: numpy<2,>=1.21 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r /content/drive/MyDrive/PatRec_Project_Shared_Folder/requirements.txt (line 1)) (1.26.4)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r /content/drive/MyDrive/PatRec_Project_Shared_Folder/requirements.txt (line 1)) (24.2)\n","Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r /content/drive/MyDrive/PatRec_Project_Shared_Folder/requirements.txt (line 1)) (11.0.0)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r /content/drive/MyDrive/PatRec_Project_Shared_Folder/requirements.txt (line 1)) (3.2.0)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r /content/drive/MyDrive/PatRec_Project_Shared_Folder/requirements.txt (line 1)) (2.8.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->-r /content/drive/MyDrive/PatRec_Project_Shared_Folder/requirements.txt (line 2)) (3.16.1)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->-r /content/drive/MyDrive/PatRec_Project_Shared_Folder/requirements.txt (line 2)) (4.12.2)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->-r /content/drive/MyDrive/PatRec_Project_Shared_Folder/requirements.txt (line 2)) (3.4.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->-r /content/drive/MyDrive/PatRec_Project_Shared_Folder/requirements.txt (line 2)) (3.1.4)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->-r /content/drive/MyDrive/PatRec_Project_Shared_Folder/requirements.txt (line 2)) (2024.10.0)\n","Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch->-r /content/drive/MyDrive/PatRec_Project_Shared_Folder/requirements.txt (line 2)) (1.13.1)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch->-r /content/drive/MyDrive/PatRec_Project_Shared_Folder/requirements.txt (line 2)) (1.3.0)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from torch_geometric->-r /content/drive/MyDrive/PatRec_Project_Shared_Folder/requirements.txt (line 4)) (3.11.10)\n","Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch_geometric->-r /content/drive/MyDrive/PatRec_Project_Shared_Folder/requirements.txt (line 4)) (5.9.5)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch_geometric->-r /content/drive/MyDrive/PatRec_Project_Shared_Folder/requirements.txt (line 4)) (2.32.3)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->-r /content/drive/MyDrive/PatRec_Project_Shared_Folder/requirements.txt (line 5)) (2024.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->-r /content/drive/MyDrive/PatRec_Project_Shared_Folder/requirements.txt (line 5)) (2024.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->-r /content/drive/MyDrive/PatRec_Project_Shared_Folder/requirements.txt (line 1)) (1.17.0)\n","Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric->-r /content/drive/MyDrive/PatRec_Project_Shared_Folder/requirements.txt (line 4)) (2.4.4)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric->-r /content/drive/MyDrive/PatRec_Project_Shared_Folder/requirements.txt (line 4)) (1.3.2)\n","Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric->-r /content/drive/MyDrive/PatRec_Project_Shared_Folder/requirements.txt (line 4)) (4.0.3)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric->-r /content/drive/MyDrive/PatRec_Project_Shared_Folder/requirements.txt (line 4)) (24.3.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric->-r /content/drive/MyDrive/PatRec_Project_Shared_Folder/requirements.txt (line 4)) (1.5.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric->-r /content/drive/MyDrive/PatRec_Project_Shared_Folder/requirements.txt (line 4)) (6.1.0)\n","Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric->-r /content/drive/MyDrive/PatRec_Project_Shared_Folder/requirements.txt (line 4)) (0.2.1)\n","Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric->-r /content/drive/MyDrive/PatRec_Project_Shared_Folder/requirements.txt (line 4)) (1.18.3)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->-r /content/drive/MyDrive/PatRec_Project_Shared_Folder/requirements.txt (line 2)) (3.0.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric->-r /content/drive/MyDrive/PatRec_Project_Shared_Folder/requirements.txt (line 4)) (3.4.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric->-r /content/drive/MyDrive/PatRec_Project_Shared_Folder/requirements.txt (line 4)) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric->-r /content/drive/MyDrive/PatRec_Project_Shared_Folder/requirements.txt (line 4)) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric->-r /content/drive/MyDrive/PatRec_Project_Shared_Folder/requirements.txt (line 4)) (2024.12.14)\n","Downloading torch_geometric-2.6.1-py3-none-any.whl (1.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m65.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: torch_geometric\n","Successfully installed torch_geometric-2.6.1\n"]}],"source":["!pip install -r /content/drive/MyDrive/PatRec_Project_Shared_Folder/requirements.txt"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Hrb9IxqrJeok"},"outputs":[],"source":["import math\n","from argparse import ArgumentParser\n","from itertools import permutations\n","import copy\n","\n","import matplotlib.pyplot as plt\n","from tqdm import tqdm\n","import itertools\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from collections import deque\n","from typing import Dict, Optional, Literal\n","import torch\n","import torch.nn as nn\n","from typing import List, Optional, Dict, Literal\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UtT0IRac8_19"},"outputs":[],"source":["from grokfast import gradfilter_ma, gradfilter_ema, gradfilter_with_depth_scaling"]},{"cell_type":"code","source":["\n","def gradfilter_with_depth_scaling(\n","    m: nn.Module,\n","    grads: Optional[Dict[str, deque]] = None,\n","    window_size: int = 100,\n","    alpha: float = 0.98,\n","    lamb_max: float = 3.0,\n","    lamb_min: float = 1.0,\n","    d_max: int = 12,  # Total number of transformer layers\n","    filter_type: Literal['mean', 'sum'] = 'mean',\n","    warmup: bool = True,\n","    trigger: bool = False,\n","    embedding_layer_name: str = \"embedding\",\n","    final_and_output_layer_names: List[str] = [\"ln_f\", \"head\"],  # Default final and output layer names\n",") -> Dict[str, deque]:\n","    \"\"\"\n","    Applies gradient filtering with dynamic depth-based lambda scaling.\n","\n","    Args:\n","        m (nn.Module): The model containing the parameters.\n","        grads (Optional[Dict[str, deque]]): Dictionary for storing past gradients.\n","        window_size (int): Number of past gradients to consider.\n","        lamb_max (float): Maximum lambda value for scaling.\n","        lamb_min (float): Minimum lambda value for scaling.\n","        d_max (int): Total depth (number of transformer layers).\n","        filter_type (Literal['mean', 'sum']): Filtering strategy ('mean' or 'sum').\n","        warmup (bool): Whether to enable warmup for gradient filtering.\n","        trigger (bool): Optional trigger condition for gradient filtering.\n","        embedding_layer_name (str): Substring identifying embedding layer parameters.\n","        final_and_output_layer_names (List[str]): List of substrings identifying final/output layer parameters.\n","\n","    Returns:\n","        Dict[str, deque]: Updated gradient storage for the model parameters.\n","     \"\"\"\n","    if grads is None:\n","        grads = {n: p.grad.data.clone() for n, p in m.named_parameters() if p.requires_grad and p.grad is not None}\n","\n","    for n, p in m.named_parameters():\n","        if p.requires_grad and p.grad is not None:\n","            # Determine depth or position\n","            if embedding_layer_name in n:\n","                depth = 0  # Embedding layers are assigned depth 0\n","            elif \"layers\" in n:\n","                # Extract depth information from name, e.g., \"layers.0\", \"layers.1\"\n","                depth = int(n.split(\".\")[1]) + 1  # Increment depth for transformer layers\n","            elif final_and_output_layer_names and any(layer_name in n for layer_name in final_and_output_layer_names):\n","                depth = d_max + 1  # Final and output layers are d_max + 1\n","            else:\n","                depth = d_max  # Default depth for unclassified layers\n","\n","            # Adjust lambda based on depth\n","            lambda_d = lamb_max - (depth / (d_max + 1)) * (lamb_max - lamb_min)\n","\n","            # Apply EMA update\n","            if n not in grads:\n","                grads[n] = p.grad.data.clone()  # Initialize EMA\n","            else:\n","                grads[n] = grads[n] * alpha + p.grad.data.clone() * (1 - alpha)\n","\n","            # Scale gradient by depth-aware lambda\n","            p.grad.data = p.grad.data + grads[n] * lambda_d\n","\n","    return grads\n"],"metadata":{"id":"ygU6xx1Z5PDl"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Gw5pFYxWJbGL"},"outputs":[],"source":["\n","class Block(nn.Module):\n","    \"\"\"Causal transformer block\n","    \"\"\"\n","\n","    def __init__(self, dim, num_heads):\n","        super().__init__()\n","        self.ln_1 = nn.LayerNorm(dim)\n","        self.ln_2 = nn.LayerNorm(dim)\n","        self.attn = nn.MultiheadAttention(dim, num_heads)\n","        self.mlp = nn.Sequential(\n","            nn.Linear(dim, dim * 4),\n","            nn.GELU(),\n","            nn.Linear(dim * 4, dim),\n","        )\n","\n","    def forward(self, x):\n","        attn_mask = torch.full(\n","            (len(x), len(x)), -float(\"Inf\"), device=x.device, dtype=x.dtype\n","        )\n","        attn_mask = torch.triu(attn_mask, diagonal=1)\n","        attn_mask[torch.isnan(attn_mask)] = 0.0 # fixes all 'nan' on 'mps' device\n","\n","        x = self.ln_1(x)\n","        a, _ = self.attn(x, x, x, attn_mask=attn_mask, need_weights=False)\n","        x = x + a\n","        m = self.mlp(self.ln_2(x))\n","        x = x + m\n","        return x\n","\n","\n","class Decoder(nn.Module):\n","    \"\"\"Causal Transformer decoder\n","    \"\"\"\n","\n","    def __init__(self, dim=128, num_layers=2, num_heads=4, num_tokens=97, seq_len=5):\n","        super().__init__()\n","        self.token_embeddings = nn.Embedding(num_tokens, dim)\n","        self.position_embeddings = nn.Embedding(seq_len, dim)\n","        self.layers = nn.ModuleList()\n","        for _ in range(num_layers):\n","            self.layers.append(Block(dim, num_heads))\n","\n","        self.ln_f = nn.LayerNorm(dim)\n","        self.head = nn.Linear(dim, num_tokens, bias=False)\n","\n","    def forward(self, x):\n","        h = self.token_embeddings(x)\n","        positions = torch.arange(x.shape[0], device=x.device).unsqueeze(-1)\n","        h = h + self.position_embeddings(positions).expand_as(h)\n","        for layer in self.layers:\n","            h = layer(h)\n","\n","        h = self.ln_f(h)\n","        logits = self.head(h)\n","        return logits\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CjzP8njaJkJU"},"outputs":[],"source":["def multiplication_mod_p_data(p, eq_token, op_token):\n","    \"\"\"x◦y = x/y (mod p) for 0 ≤ x < p, 0 < y < p\n","    \"\"\"\n","    x = torch.arange(p)\n","    y = torch.arange(1, p)\n","    x, y = torch.cartesian_prod(x, y).T\n","\n","    eq = torch.ones_like(x) * eq_token\n","    op = torch.ones_like(x) * op_token\n","    result = x * y % p\n","\n","    # \"All of our experiments used a small transformer trained on datasets of\n","    # equations of the form a◦b = c, where each of “a”, “◦”, “b”, “=”, and “c”\n","    # is a seperate token\"\n","    return torch.stack([x, op, y, eq, result])\n","\n"]},{"cell_type":"code","source":["import os\n","\n","# Specify the path to save in Google Drive\n","results_dir = \"/content/drive/MyDrive/PatRec_Project_Shared_Folder/results/Algorithmic\"\n","os.makedirs(results_dir, exist_ok=True)"],"metadata":{"id":"fPwoxB0RIxv0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["            #    Demo to see labdas for each layer - also need to add fields (lambda,depth,..) in grads inside the filtering function for it to work\n","\n","# #         Dummy training just to showcase depth-lambas of network\n","\n","# def main(args):\n","#     import torch\n","#     import torch.nn as nn\n","#     from collections import deque\n","#     from typing import Optional, Dict, Literal\n","\n","#     torch.manual_seed(args.seed)\n","\n","#     device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","#     # Mock tokens for the task\n","#     eq_token = args.p\n","#     op_token = args.p + 1\n","#     depth=args.depth\n","\n","#     # Initialize the model\n","#     model = Decoder(\n","#         dim=128, num_layers=depth, num_heads=4, num_tokens=args.p + 2, seq_len=5\n","#     ).to(device)\n","#     print(model)\n","#     print(f\"Total number of parameters: {sum(p.numel() for p in model.parameters() if p.requires_grad)}\")\n","\n","#     # Create dummy input\n","#     dummy_input = torch.randint(0, args.p + 2, (5, 16)).to(device)  # Sequence of length 5, batch size 16\n","\n","#     # Create dummy target (last token prediction task)\n","#     dummy_target = torch.randint(0, args.p + 2, (16,)).to(device)  # Batch size 16\n","\n","#     # Forward pass\n","#     logits = model(dummy_input[:-1])  # Skip the last input token for causal prediction\n","\n","#     # Loss computation\n","#     loss_fn = nn.CrossEntropyLoss()\n","#     loss = loss_fn(logits[-1], dummy_target)  # Compute loss for the last token\n","\n","#     # Backward pass to generate gradients\n","#     loss.backward()\n","\n","#     # Inspect parameter names and gradients\n","#     # print(\"\\nParameter Names and Gradients:\")\n","#     # for name, param in model.named_parameters():\n","#     #     if param.requires_grad:\n","#     #         grad_status = \"Gradient computed\" if param.grad is not None else \"No gradient\"\n","#     #         print(f\"{name}: {grad_status}, Shape: {param.shape}\")\n","\n","#     # Pass gradients to the gradfilter_with_depth_scaling function for inspection\n","#     grads = gradfilter_with_depth_scaling(\n","#         model,\n","#         grads=None,  # Start with no previous gradients\n","#         window_size=args.window_size,\n","#         lamb_max=args.lamb_max,\n","#         lamb_min=args.lamb_min,\n","#         d_max=depth,  # Total number of transformer layers\n","#         filter_type='mean',\n","#         warmup=False,  # Skip warmup to apply the filtering immediately\n","#         trigger=False,\n","#         embedding_layer_name=\"embedding\",\n","#         final_and_output_layer_names=[\"ln_f\", \"head\"]\n","#     )\n","\n","#     for name, grad_metadata in grads.items():\n","#       depth = grad_metadata.get(\"depth\", \"Unknown\")\n","#       lambda_d = grad_metadata.get(\"lambda\", \"Unknown\")\n","#       print(f\"Layer: {name}, Depth: {depth}, Lambda: {lambda_d}, Queue Length: {len(grad_metadata['queue'])}\")\n","\n","\n","#     # Print the filtered gradients for inspection\n","#     # print(\"\\nFiltered Gradients:\")\n","#     # for name, grad_queue in grads.items():\n","#     #     print(f\"{name}: Queue length = {len(grad_queue)}\")\n"],"metadata":{"id":"2d9TyuRDyYMo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# if __name__ == \"__main__\":\n","#     parser = ArgumentParser()\n","#     parser.add_argument(\"--label\", default=\"\")\n","#     parser.add_argument(\"--seed\", type=int, default=0)\n","#     parser.add_argument(\"--depth\", type=int, default=2)\n","#     parser.add_argument(\"--p\", type=int, default=97)\n","#     parser.add_argument(\"--budget\", type=int, default=3e5)\n","#     parser.add_argument(\"--batch_size\", type=int, default=256)\n","#     parser.add_argument(\"--lr\", type=float, default=1e-3)\n","#     parser.add_argument(\"--beta1\", type=float, default=0.9)\n","#     parser.add_argument(\"--beta2\", type=float, default=0.98)\n","#     parser.add_argument(\"--weight_decay\", type=float, default=0)\n","#     parser.add_argument(\"--optimizer\", default=\"Adam\")\n","#     parser.add_argument(\"--filter\", type=str, choices=[\"none\", \"ma\", \"ema\", \"fir\"], default=\"none\")\n","#     parser.add_argument(\"--alpha\", type=float, default=0.99)\n","#     parser.add_argument(\"--window_size\", type=int, default=50)\n","#     parser.add_argument(\"--lamb\", type=float, default=5.0)\n","#     parser.add_argument(\"--lamb_max\", type=float, default=5.0, help=\"Maximum lambda for depth scaling\")\n","#     parser.add_argument(\"--lamb_min\", type=float, default=1.0, help=\"Minimum lambda for depth scaling\")\n","#     parser.add_argument(\"--two_stage\", action='store_true')\n","#     parser.add_argument(\"--save_weights\", action='store_true')\n","#     parser.add_argument(\"--dataset_fraction\", type=float, default=1.0, help=\"Fraction of the dataset to use (0.0 to 1.0)\")\n","\n","\n","#     # Parse known arguments to handle Jupyter conflicts\n","#     args, unknown = parser.parse_known_args()\n","\n","#     # Modify label dynamically\n","#     filter_str = ('_' if args.label != '' else '') + args.filter\n","#     window_size_str = f'_w{args.window_size}'\n","#     alpha_str = f'_a{args.alpha:.3f}'.replace('.', '')\n","#     lamb_str = f'_l{int(args.lamb)}'\n","\n","#     if args.filter == \"none\":\n","#         filter_suffix = \"\"\n","#     elif args.filter == \"ma\":\n","#         filter_suffix = window_size_str + lamb_str\n","#     elif args.filter == \"ema\":\n","#         filter_suffix = alpha_str + lamb_str\n","#     else:\n","#         raise ValueError(f\"Unrecognized filter type {args.filter}\")\n","\n","#     optim_suffix = \"\"\n","#     if args.weight_decay != 0:\n","#         optim_suffix = optim_suffix + f'_wd{args.weight_decay:.1e}'.replace('.', '')\n","#     if args.lr != 1e-3:\n","#         optim_suffix = optim_suffix + f'_lrx{int(args.lr / 1e-3)}'\n","\n","#     args.label = args.label + filter_str + filter_suffix + optim_suffix\n","\n","#    # Call main\n","#     main(args)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lHQLAzkqycQF","executionInfo":{"status":"ok","timestamp":1736960346296,"user_tz":-120,"elapsed":243,"user":{"displayName":"Nikolas Xiros","userId":"00495869844002127525"}},"outputId":"02dab7f5-c622-4d7f-eb76-a647842cbbae"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Decoder(\n","  (token_embeddings): Embedding(99, 128)\n","  (position_embeddings): Embedding(5, 128)\n","  (layers): ModuleList(\n","    (0-1): 2 x Block(\n","      (ln_1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n","      (ln_2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n","      (attn): MultiheadAttention(\n","        (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n","      )\n","      (mlp): Sequential(\n","        (0): Linear(in_features=128, out_features=512, bias=True)\n","        (1): GELU(approximate='none')\n","        (2): Linear(in_features=512, out_features=128, bias=True)\n","      )\n","    )\n","  )\n","  (ln_f): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n","  (head): Linear(in_features=128, out_features=99, bias=False)\n",")\n","Total number of parameters: 422784\n","Layer: token_embeddings.weight, Depth: 0, Lambda: 5.0, Queue Length: 1\n","Layer: position_embeddings.weight, Depth: 0, Lambda: 5.0, Queue Length: 1\n","Layer: layers.0.ln_1.weight, Depth: 1, Lambda: 3.666666666666667, Queue Length: 1\n","Layer: layers.0.ln_1.bias, Depth: 1, Lambda: 3.666666666666667, Queue Length: 1\n","Layer: layers.0.ln_2.weight, Depth: 1, Lambda: 3.666666666666667, Queue Length: 1\n","Layer: layers.0.ln_2.bias, Depth: 1, Lambda: 3.666666666666667, Queue Length: 1\n","Layer: layers.0.attn.in_proj_weight, Depth: 1, Lambda: 3.666666666666667, Queue Length: 1\n","Layer: layers.0.attn.in_proj_bias, Depth: 1, Lambda: 3.666666666666667, Queue Length: 1\n","Layer: layers.0.attn.out_proj.weight, Depth: 1, Lambda: 3.666666666666667, Queue Length: 1\n","Layer: layers.0.attn.out_proj.bias, Depth: 1, Lambda: 3.666666666666667, Queue Length: 1\n","Layer: layers.0.mlp.0.weight, Depth: 1, Lambda: 3.666666666666667, Queue Length: 1\n","Layer: layers.0.mlp.0.bias, Depth: 1, Lambda: 3.666666666666667, Queue Length: 1\n","Layer: layers.0.mlp.2.weight, Depth: 1, Lambda: 3.666666666666667, Queue Length: 1\n","Layer: layers.0.mlp.2.bias, Depth: 1, Lambda: 3.666666666666667, Queue Length: 1\n","Layer: layers.1.ln_1.weight, Depth: 2, Lambda: 2.3333333333333335, Queue Length: 1\n","Layer: layers.1.ln_1.bias, Depth: 2, Lambda: 2.3333333333333335, Queue Length: 1\n","Layer: layers.1.ln_2.weight, Depth: 2, Lambda: 2.3333333333333335, Queue Length: 1\n","Layer: layers.1.ln_2.bias, Depth: 2, Lambda: 2.3333333333333335, Queue Length: 1\n","Layer: layers.1.attn.in_proj_weight, Depth: 2, Lambda: 2.3333333333333335, Queue Length: 1\n","Layer: layers.1.attn.in_proj_bias, Depth: 2, Lambda: 2.3333333333333335, Queue Length: 1\n","Layer: layers.1.attn.out_proj.weight, Depth: 2, Lambda: 2.3333333333333335, Queue Length: 1\n","Layer: layers.1.attn.out_proj.bias, Depth: 2, Lambda: 2.3333333333333335, Queue Length: 1\n","Layer: layers.1.mlp.0.weight, Depth: 2, Lambda: 2.3333333333333335, Queue Length: 1\n","Layer: layers.1.mlp.0.bias, Depth: 2, Lambda: 2.3333333333333335, Queue Length: 1\n","Layer: layers.1.mlp.2.weight, Depth: 2, Lambda: 2.3333333333333335, Queue Length: 1\n","Layer: layers.1.mlp.2.bias, Depth: 2, Lambda: 2.3333333333333335, Queue Length: 1\n","Layer: ln_f.weight, Depth: 3, Lambda: 1.0, Queue Length: 1\n","Layer: ln_f.bias, Depth: 3, Lambda: 1.0, Queue Length: 1\n","Layer: head.weight, Depth: 3, Lambda: 1.0, Queue Length: 1\n"]}]},{"cell_type":"code","source":["import copy\n","#           Proper Training now\n","\n","def main(args):\n","    torch.manual_seed(args.seed)\n","\n","\n","    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","    # tokens for <op> and <=>. It's not clear why <=> is needed at all since it\n","    # has no effect on the output, but we'll leave it in to best follow the\n","    # paper.\n","    eq_token = args.p\n","    op_token = args.p + 1\n","    depth=args.depth\n","\n","    #Values to validate on\n","    lambdas = [1.0, 2.0, 5.0]\n","    alphas = [0.8,  0.9, 0.98]\n","\n","    stop_threshold = 0.95\n","    stop_patience = 10000  # Number of epochs to sustain 0.95 validation accuracy\n","\n","\n","    # Loop over all combinations of lambdas and alphas\n","    for lamb, alpha in itertools.product(lambdas, alphas):\n","        print(f\"Testing lambda={lamb}, alpha={alpha}\")\n","\n","        # Initialize the model\n","        model = Decoder(\n","            dim=128, num_layers=depth, num_heads=4, num_tokens=args.p + 2, seq_len=5\n","        ).to(device)\n","\n","        nparams = sum([p.numel() for p in model.parameters() if p.requires_grad])\n","        print(model)\n","        print(f\"Total number of parameters: {nparams}\")\n","\n","        # Split data into training and validation sets\n","        data = multiplication_mod_p_data(args.p, eq_token, op_token)\n","        split_idx = data.shape[1] // 2\n","        perm = torch.randperm(data.shape[1])\n","        train_idx = perm[:split_idx]\n","        valid_idx = perm[split_idx:]\n","        train_data = data[:, train_idx]\n","        valid_data = data[:, valid_idx]\n","\n","        # Initialize optimizer and scheduler\n","        optimizer = getattr(torch.optim, args.optimizer)(\n","            model.parameters(),\n","            lr=args.lr,\n","            weight_decay=args.weight_decay,\n","            betas=(args.beta1, args.beta2),\n","        )\n","        scheduler = torch.optim.lr_scheduler.LambdaLR(\n","            optimizer, lambda update: 1 if update > 10 else update / 10\n","        )\n","\n","        steps_per_epoch = math.ceil(train_data.shape[1] / args.batch_size)\n","        its, train_acc, val_acc, train_loss, val_loss = [], [], [], [], []\n","        grads = None\n","        i = 0\n","        net_its, nets = [], []\n","        best_val_acc = 0\n","        best_params = {}\n","        patience_counter = 0\n","        stop_early = False\n","        steps_to_achieve = None\n","\n","        for e in tqdm(range(int(args.budget) // steps_per_epoch)):\n","            if stop_early:\n","                break\n","\n","            # Shuffle training data\n","            train_data = train_data[:, torch.randperm(train_data.shape[1])]\n","\n","            for data, is_train in [(train_data, True), (valid_data, False)]:\n","                model.train(is_train)\n","                total_loss = 0\n","                total_acc = 0\n","                dl = torch.split(data, args.batch_size, dim=1)\n","\n","                for input in dl:\n","                    input = input.to(device)\n","                    with torch.set_grad_enabled(is_train):\n","                        logits = model(input[:-1])\n","                        loss = F.cross_entropy(logits[-1], input[-1])\n","                        total_loss += loss.item() * input.shape[-1]\n","\n","                    if is_train:\n","                        model.zero_grad()\n","                        loss.backward()\n","\n","                        # Gradient filtering\n","                        trigger = i < 500 if args.two_stage else False\n","                        if args.filter == \"none\":\n","                            pass\n","                        elif args.filter == \"ma\":\n","                            grads = gradfilter_ma(\n","                                model, grads=grads, window_size=args.window_size, lamb=args.lamb, trigger=trigger\n","                            )\n","                        elif args.filter == \"ema\":\n","                            grads = gradfilter_ema(\n","                                model, grads=grads, alpha=args.alpha, lamb=args.lamb\n","                            )\n","                        elif args.filter == \"ema_depth\":\n","                            grads = gradfilter_with_depth_scaling(\n","                                model, grads=grads, alpha=args.alpha, lamb_min=0.5 * args.lamb, lamb_max=2 * args.lamb\n","                            )\n","                        else:\n","                            raise ValueError(f\"Invalid gradient filter type `{args.filter}`\")\n","\n","                        optimizer.step()\n","                        scheduler.step()\n","                        i += 1\n","\n","                    acc = (logits[-1].argmax(-1) == input[-1]).float().mean()\n","                    total_acc += acc.item() * input.shape[-1]\n","\n","                if is_train:\n","                    train_acc.append(total_acc / train_data.shape[-1])\n","                    train_loss.append(total_loss / train_data.shape[-1])\n","                    its.append(i)\n","                else:\n","                    val_acc.append(total_acc / valid_data.shape[-1])\n","                    val_loss.append(total_loss / valid_data.shape[-1])\n","\n","            # Early stopping\n","            if len(val_acc) > 0:\n","                avg_val_acc = val_acc[-1]\n","                if avg_val_acc >= stop_threshold:\n","                    patience_counter += 1\n","                    if patience_counter >= stop_patience:\n","                        print(f\"Stopping early for lambda={lamb}, alpha={alpha} at epoch {e + 1}.\")\n","                        stop_early = True\n","                        steps_to_achieve = i\n","                else:\n","                    patience_counter = 0\n","\n","            # Save weights and results\n","            if args.save_weights:\n","                do_save = (\n","                    e <= 500 or (e > 500 and (e + 1) % 100 == 0) or e == int(args.budget) // steps_per_epoch - 1\n","                )\n","            else:\n","                do_save = (e + 1) % 100 == 0\n","\n","            if do_save:\n","                net_its.append(e)\n","                nets.append(copy.deepcopy(model.state_dict()))\n","                results = {\n","                    \"its\": its,\n","                    \"train_acc\": train_acc,\n","                    \"train_loss\": train_loss,\n","                    \"val_acc\": val_acc,\n","                    \"val_loss\": val_loss,\n","                }\n","                torch.save(results, f\"{results_dir}/pt/res_{args.label}.pt\")\n","\n","            steps = torch.arange(len(train_acc)).numpy() * steps_per_epoch + 1  # Add 1 to avoid zero\n","\n","            plt.plot(steps, train_acc, label=\"train\")\n","            plt.plot(steps, val_acc, label=\"val\")\n","            plt.legend()\n","            plt.title(f\"Accuracy for Modular Multiplication (lambda={lamb}, alpha={alpha})\")\n","            plt.xlabel(\"Optimization Steps\")\n","            plt.ylabel(\"Accuracy\")\n","            plt.xscale(\"log\", base=10)\n","            plt.grid()\n","            plt.savefig(f\"{results_dir}/acc/acc_{args.label}_lambda_{lamb}_alpha_{alpha}.png\", dpi=150)\n","            plt.close()\n","\n","            plt.plot(steps, train_loss, label=\"train\")\n","            plt.plot(steps, val_loss, label=\"val\")\n","            plt.legend()\n","            plt.title(f\"Loss for Modular Multiplication (lambda={lamb}, alpha={alpha})\")\n","            plt.xlabel(\"Optimization Steps\")\n","            plt.ylabel(\"Loss\")\n","            plt.xscale(\"log\", base=10)\n","            plt.grid()\n","            plt.savefig(f\"{results_dir}/loss/loss_{args.label}_lambda_{lamb}_alpha_{alpha}.png\", dpi=150)\n","            plt.close()\n","\n","        # Update best parameters\n","        if len(val_acc) > 0 and val_acc[-1] > best_val_acc:\n","            best_val_acc = val_acc[-1]\n","            best_params = {\"lambda\": lamb, \"alpha\": alpha}\n","\n","    print(f\"Best parameters: {best_params} with validation accuracy {best_val_acc}\")"],"metadata":{"id":"ICwdM9A06JWF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(device)"],"metadata":{"id":"bCRXCUI7605m","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1737227855292,"user_tz":-120,"elapsed":431,"user":{"displayName":"Nikolas Xiros","userId":"00495869844002127525"}},"outputId":"7e16787b-2192-4d96-9f34-3ab408ae9399"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["cuda\n"]}]},{"cell_type":"code","source":["if __name__ == \"__main__\":\n","    parser = ArgumentParser()\n","    parser.add_argument(\"--label\", default=\"depth_algo_trial\")\n","    parser.add_argument(\"--seed\", type=int, default=0)\n","    parser.add_argument(\"--p\", type=int, default=97)\n","    parser.add_argument(\"--depth\", type=int, default=2)\n","    parser.add_argument(\"--budget\", type=int, default=3e5)\n","    parser.add_argument(\"--batch_size\", type=int, default=512)\n","    parser.add_argument(\"--lr\", type=float, default=1e-3)\n","    parser.add_argument(\"--beta1\", type=float, default=0.9)\n","    parser.add_argument(\"--beta2\", type=float, default=0.98)\n","    parser.add_argument(\"--weight_decay\", type=float, default=0.005)\n","    parser.add_argument(\"--optimizer\", default=\"Adam\")\n","    parser.add_argument(\"--filter\", type=str, choices=[\"none\", \"ma\", \"ema\", \"fir\",\"ema_depth\"], default=\"ema_depth\")\n","    parser.add_argument(\"--alpha\", type=float, default=0.98)\n","    parser.add_argument(\"--window_size\", type=int, default=100)\n","    parser.add_argument(\"--lamb\", type=float, default=2.0)\n","    parser.add_argument(\"--two_stage\", action='store_true')\n","    parser.add_argument(\"--save_weights\", action='store_true')\n","    parser.add_argument(\"--dataset_fraction\", type=float, default=1.0, help=\"Fraction of the dataset to use (0.0 to 1.0)\")\n","\n","    # Parse known arguments to handle Jupyter conflicts\n","    args, unknown = parser.parse_known_args()\n","\n","    # Modify label dynamically\n","    filter_str = ('_' if args.label != '' else '') + args.filter\n","    window_size_str = f'_w{args.window_size}'\n","    alpha_str = f'_a{args.alpha:.3f}'.replace('.', '')\n","    lamb_str = f'_l{int(args.lamb)}'\n","\n","    if args.filter == \"none\":\n","        filter_suffix = \"\"\n","    elif args.filter == \"ma\":\n","        filter_suffix = window_size_str + lamb_str\n","    elif args.filter == \"ema\":\n","        filter_suffix = alpha_str + lamb_str\n","    elif args.filter == \"ema_depth\":\n","        filter_suffix = alpha_str + lamb_str\n","    else:\n","        raise ValueError(f\"Unrecognized filter type {args.filter}\")\n","\n","    optim_suffix = \"\"\n","    if args.weight_decay != 0:\n","        optim_suffix = optim_suffix + f'_wd{args.weight_decay:.1e}'.replace('.', '')\n","    if args.lr != 1e-3:\n","        optim_suffix = optim_suffix + f'_lrx{int(args.lr / 1e-3)}'\n","\n","    args.label = args.label + filter_str + filter_suffix + optim_suffix\n","    print(f\"Experiment results saved under name: {args.label}\")\n","\n","\n","\n","   # Call main\n","    main(args)"],"metadata":{"id":"-HUehLhX61ag","colab":{"base_uri":"https://localhost:8080/","height":738},"executionInfo":{"status":"error","timestamp":1737230340176,"user_tz":-120,"elapsed":235404,"user":{"displayName":"Nikolas Xiros","userId":"00495869844002127525"}},"outputId":"a84a5f35-1db4-4afd-93a8-755355acdc23"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Experiment results saved under name: depth_algo_trial_ema_depth_a0980_l2_wd50e-03\n","Testing lambda=1.0, alpha=0.8\n","Decoder(\n","  (token_embeddings): Embedding(99, 128)\n","  (position_embeddings): Embedding(5, 128)\n","  (layers): ModuleList(\n","    (0-1): 2 x Block(\n","      (ln_1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n","      (ln_2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n","      (attn): MultiheadAttention(\n","        (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n","      )\n","      (mlp): Sequential(\n","        (0): Linear(in_features=128, out_features=512, bias=True)\n","        (1): GELU(approximate='none')\n","        (2): Linear(in_features=512, out_features=128, bias=True)\n","      )\n","    )\n","  )\n","  (ln_f): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n","  (head): Linear(in_features=128, out_features=99, bias=False)\n",")\n","Total number of parameters: 422784\n"]},{"output_type":"stream","name":"stderr","text":["  1%|          | 242/30000 [03:55<8:03:18,  1.03it/s]\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-41-e79015cbb10d>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m    \u001b[0;31m# Call main\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-39-715a1f236fe4>\u001b[0m in \u001b[0;36mmain\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m     89\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mis_train\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m                         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m                         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m                         \u001b[0;31m# Gradient filtering\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    579\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    580\u001b[0m             )\n\u001b[0;32m--> 581\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    582\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    583\u001b[0m         )\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    345\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 347\u001b[0;31m     _engine_run_backward(\n\u001b[0m\u001b[1;32m    348\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py\u001b[0m in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    823\u001b[0m         \u001b[0munregister_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_register_logging_hooks_on_whole_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    824\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 825\u001b[0;31m         return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    826\u001b[0m             \u001b[0mt_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m         )  # Calls into the C++ engine to run the backward pass\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","source":["args = parser.parse_args([\n","    \"--window_size\", \"100\",\n","    \"--lamb\", \"2.0\",\n","    \"--alpha\", \"0.98\",\n","    \"--weight_decay\",\"0.005\",\n","    \"--filter\",\"ema\",\n","    \"--batch_size\", \"512\",\n","    \"--label\", \"ema_same_as_paper\"\n","])\n","\n","print(f\"Experiment results saved under name: {args.label}\")\n","\n","print(f\"Alg: {args.filter}\")\n","\n","\n","# Call main\n","main(args)"],"metadata":{"id":"BCELfaDuQhJQ"},"execution_count":null,"outputs":[]}]}