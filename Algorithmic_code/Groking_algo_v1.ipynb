{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RLNMqt_y8y0J"
      },
      "outputs": [],
      "source": [
        "#Starting code for PatRec project\n",
        "#   Omada 2 -- Grokfast experiments"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f4s6HWPGPSBJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f099731b-fb77-431c-de12-da10af0b7f36"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gADYjdBHN1cg"
      },
      "outputs": [],
      "source": [
        "# from google.colab import files\n",
        "# files.upload()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pUw0ejsKP3sp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b7c20f72-7e66-4e90-a2ef-1ff00eea7633"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Algorithmic_code  MNIST_code\t  __pycache__  requirements.txt  results2_test_random_seed_12\n",
            "grokfast.py\t  _Presentations  QM9_code     results\n"
          ]
        }
      ],
      "source": [
        "!ls /content/drive/MyDrive/PatRec_Project_Shared_Folder/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qdXeIGW_QC3w"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "sys.path.append('/content/drive/MyDrive/PatRec_Project_Shared_Folder')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C13vv8V-KHUI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b660ab52-759c-4896-fc2c-4f41e0b9f989"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from -r /content/drive/MyDrive/PatRec_Project_Shared_Folder/requirements.txt (line 1)) (3.10.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from -r /content/drive/MyDrive/PatRec_Project_Shared_Folder/requirements.txt (line 2)) (2.5.1+cu124)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (from -r /content/drive/MyDrive/PatRec_Project_Shared_Folder/requirements.txt (line 3)) (0.20.1+cu124)\n",
            "Collecting torch_geometric (from -r /content/drive/MyDrive/PatRec_Project_Shared_Folder/requirements.txt (line 4))\n",
            "  Downloading torch_geometric-2.6.1-py3-none-any.whl.metadata (63 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/63.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.1/63.1 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from -r /content/drive/MyDrive/PatRec_Project_Shared_Folder/requirements.txt (line 5)) (2.2.2)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.11/dist-packages (from -r /content/drive/MyDrive/PatRec_Project_Shared_Folder/requirements.txt (line 6)) (0.13.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from -r /content/drive/MyDrive/PatRec_Project_Shared_Folder/requirements.txt (line 7)) (4.67.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from -r /content/drive/MyDrive/PatRec_Project_Shared_Folder/requirements.txt (line 8)) (1.13.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from -r /content/drive/MyDrive/PatRec_Project_Shared_Folder/requirements.txt (line 9)) (1.6.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->-r /content/drive/MyDrive/PatRec_Project_Shared_Folder/requirements.txt (line 1)) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->-r /content/drive/MyDrive/PatRec_Project_Shared_Folder/requirements.txt (line 1)) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->-r /content/drive/MyDrive/PatRec_Project_Shared_Folder/requirements.txt (line 1)) (4.55.8)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->-r /content/drive/MyDrive/PatRec_Project_Shared_Folder/requirements.txt (line 1)) (1.4.8)\n",
            "Requirement already satisfied: numpy>=1.23 in /usr/local/lib/python3.11/dist-packages (from matplotlib->-r /content/drive/MyDrive/PatRec_Project_Shared_Folder/requirements.txt (line 1)) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->-r /content/drive/MyDrive/PatRec_Project_Shared_Folder/requirements.txt (line 1)) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib->-r /content/drive/MyDrive/PatRec_Project_Shared_Folder/requirements.txt (line 1)) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->-r /content/drive/MyDrive/PatRec_Project_Shared_Folder/requirements.txt (line 1)) (3.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->-r /content/drive/MyDrive/PatRec_Project_Shared_Folder/requirements.txt (line 1)) (2.8.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->-r /content/drive/MyDrive/PatRec_Project_Shared_Folder/requirements.txt (line 2)) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch->-r /content/drive/MyDrive/PatRec_Project_Shared_Folder/requirements.txt (line 2)) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->-r /content/drive/MyDrive/PatRec_Project_Shared_Folder/requirements.txt (line 2)) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->-r /content/drive/MyDrive/PatRec_Project_Shared_Folder/requirements.txt (line 2)) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->-r /content/drive/MyDrive/PatRec_Project_Shared_Folder/requirements.txt (line 2)) (2024.10.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch->-r /content/drive/MyDrive/PatRec_Project_Shared_Folder/requirements.txt (line 2))\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch->-r /content/drive/MyDrive/PatRec_Project_Shared_Folder/requirements.txt (line 2))\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch->-r /content/drive/MyDrive/PatRec_Project_Shared_Folder/requirements.txt (line 2))\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch->-r /content/drive/MyDrive/PatRec_Project_Shared_Folder/requirements.txt (line 2))\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch->-r /content/drive/MyDrive/PatRec_Project_Shared_Folder/requirements.txt (line 2))\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch->-r /content/drive/MyDrive/PatRec_Project_Shared_Folder/requirements.txt (line 2))\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch->-r /content/drive/MyDrive/PatRec_Project_Shared_Folder/requirements.txt (line 2))\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch->-r /content/drive/MyDrive/PatRec_Project_Shared_Folder/requirements.txt (line 2))\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch->-r /content/drive/MyDrive/PatRec_Project_Shared_Folder/requirements.txt (line 2))\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->-r /content/drive/MyDrive/PatRec_Project_Shared_Folder/requirements.txt (line 2)) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->-r /content/drive/MyDrive/PatRec_Project_Shared_Folder/requirements.txt (line 2)) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch->-r /content/drive/MyDrive/PatRec_Project_Shared_Folder/requirements.txt (line 2))\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch->-r /content/drive/MyDrive/PatRec_Project_Shared_Folder/requirements.txt (line 2)) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->-r /content/drive/MyDrive/PatRec_Project_Shared_Folder/requirements.txt (line 2)) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->-r /content/drive/MyDrive/PatRec_Project_Shared_Folder/requirements.txt (line 2)) (1.3.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from torch_geometric->-r /content/drive/MyDrive/PatRec_Project_Shared_Folder/requirements.txt (line 4)) (3.11.12)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.11/dist-packages (from torch_geometric->-r /content/drive/MyDrive/PatRec_Project_Shared_Folder/requirements.txt (line 4)) (5.9.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from torch_geometric->-r /content/drive/MyDrive/PatRec_Project_Shared_Folder/requirements.txt (line 4)) (2.32.3)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->-r /content/drive/MyDrive/PatRec_Project_Shared_Folder/requirements.txt (line 5)) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->-r /content/drive/MyDrive/PatRec_Project_Shared_Folder/requirements.txt (line 5)) (2025.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->-r /content/drive/MyDrive/PatRec_Project_Shared_Folder/requirements.txt (line 9)) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->-r /content/drive/MyDrive/PatRec_Project_Shared_Folder/requirements.txt (line 9)) (3.5.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib->-r /content/drive/MyDrive/PatRec_Project_Shared_Folder/requirements.txt (line 1)) (1.17.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric->-r /content/drive/MyDrive/PatRec_Project_Shared_Folder/requirements.txt (line 4)) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric->-r /content/drive/MyDrive/PatRec_Project_Shared_Folder/requirements.txt (line 4)) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric->-r /content/drive/MyDrive/PatRec_Project_Shared_Folder/requirements.txt (line 4)) (25.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric->-r /content/drive/MyDrive/PatRec_Project_Shared_Folder/requirements.txt (line 4)) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric->-r /content/drive/MyDrive/PatRec_Project_Shared_Folder/requirements.txt (line 4)) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric->-r /content/drive/MyDrive/PatRec_Project_Shared_Folder/requirements.txt (line 4)) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric->-r /content/drive/MyDrive/PatRec_Project_Shared_Folder/requirements.txt (line 4)) (1.18.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->-r /content/drive/MyDrive/PatRec_Project_Shared_Folder/requirements.txt (line 2)) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->torch_geometric->-r /content/drive/MyDrive/PatRec_Project_Shared_Folder/requirements.txt (line 4)) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->torch_geometric->-r /content/drive/MyDrive/PatRec_Project_Shared_Folder/requirements.txt (line 4)) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->torch_geometric->-r /content/drive/MyDrive/PatRec_Project_Shared_Folder/requirements.txt (line 4)) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->torch_geometric->-r /content/drive/MyDrive/PatRec_Project_Shared_Folder/requirements.txt (line 4)) (2025.1.31)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m94.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m72.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m40.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m55.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torch_geometric-2.6.1-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m41.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, torch_geometric, nvidia-cusolver-cu12\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 torch_geometric-2.6.1\n"
          ]
        }
      ],
      "source": [
        "!pip install -r /content/drive/MyDrive/PatRec_Project_Shared_Folder/requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hrb9IxqrJeok"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "from argparse import ArgumentParser\n",
        "from itertools import permutations\n",
        "import copy\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UtT0IRac8_19"
      },
      "outputs": [],
      "source": [
        "from grokfast import gradfilter_ma, gradfilter_ema, gradfilter_with_depth_scaling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gw5pFYxWJbGL"
      },
      "outputs": [],
      "source": [
        "\n",
        "class Block(nn.Module):\n",
        "    \"\"\"Causal transformer block\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, dim, num_heads):\n",
        "        super().__init__()\n",
        "        self.ln_1 = nn.LayerNorm(dim)\n",
        "        self.ln_2 = nn.LayerNorm(dim)\n",
        "        self.attn = nn.MultiheadAttention(dim, num_heads)\n",
        "        self.mlp = nn.Sequential(\n",
        "            nn.Linear(dim, dim * 4),\n",
        "            nn.GELU(),\n",
        "            nn.Linear(dim * 4, dim),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        attn_mask = torch.full(\n",
        "            (len(x), len(x)), -float(\"Inf\"), device=x.device, dtype=x.dtype\n",
        "        )\n",
        "        attn_mask = torch.triu(attn_mask, diagonal=1)\n",
        "        attn_mask[torch.isnan(attn_mask)] = 0.0 # fixes all 'nan' on 'mps' device\n",
        "\n",
        "        x = self.ln_1(x)\n",
        "        a, _ = self.attn(x, x, x, attn_mask=attn_mask, need_weights=False)\n",
        "        x = x + a\n",
        "        m = self.mlp(self.ln_2(x))\n",
        "        x = x + m\n",
        "        return x\n",
        "\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    \"\"\"Causal Transformer decoder\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, dim=128, num_layers=2, num_heads=4, num_tokens=97, seq_len=5):\n",
        "        super().__init__()\n",
        "        self.token_embeddings = nn.Embedding(num_tokens, dim)\n",
        "        self.position_embeddings = nn.Embedding(seq_len, dim)\n",
        "        self.layers = nn.ModuleList()\n",
        "        for _ in range(num_layers):\n",
        "            self.layers.append(Block(dim, num_heads))\n",
        "\n",
        "        self.ln_f = nn.LayerNorm(dim)\n",
        "        self.head = nn.Linear(dim, num_tokens, bias=False)\n",
        "\n",
        "    def forward(self, x):\n",
        "        h = self.token_embeddings(x)\n",
        "        positions = torch.arange(x.shape[0], device=x.device).unsqueeze(-1)\n",
        "        h = h + self.position_embeddings(positions).expand_as(h)\n",
        "        for layer in self.layers:\n",
        "            h = layer(h)\n",
        "\n",
        "        h = self.ln_f(h)\n",
        "        logits = self.head(h)\n",
        "        return logits\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CjzP8njaJkJU"
      },
      "outputs": [],
      "source": [
        "def multiplication_mod_p_data(p, eq_token, op_token):\n",
        "    \"\"\"x◦y = x/y (mod p) for 0 ≤ x < p, 0 < y < p\n",
        "    \"\"\"\n",
        "    x = torch.arange(p)\n",
        "    y = torch.arange(1, p)\n",
        "    x, y = torch.cartesian_prod(x, y).T\n",
        "\n",
        "    eq = torch.ones_like(x) * eq_token\n",
        "    op = torch.ones_like(x) * op_token\n",
        "    result = x * y % p\n",
        "\n",
        "    # \"All of our experiments used a small transformer trained on datasets of\n",
        "    # equations of the form a◦b = c, where each of “a”, “◦”, “b”, “=”, and “c”\n",
        "    # is a seperate token\"\n",
        "    return torch.stack([x, op, y, eq, result])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Specify the path to save in Google Drive\n",
        "results_dir = \"/content/drive/MyDrive/PatRec_Project_Shared_Folder/results\"\n",
        "os.makedirs(results_dir, exist_ok=True)"
      ],
      "metadata": {
        "id": "fPwoxB0RIxv0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oWtMguE3JmpK"
      },
      "outputs": [],
      "source": [
        "def main(args):\n",
        "    torch.manual_seed(args.seed)\n",
        "\n",
        "\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    # tokens for <op> and <=>. It's not clear why <=> is needed at all since it\n",
        "    # has no effect on the output, but we'll leave it in to best follow the\n",
        "    # paper.\n",
        "    eq_token = args.p\n",
        "    op_token = args.p + 1\n",
        "\n",
        "    # \"We trained a standard decoder-only transformer (Vaswani et al., 2017)\n",
        "    # with causal attention masking, and calculated loss and accuracy only on\n",
        "    # the answer part of the equation. For all experiments we used a\n",
        "    # transformer with 2 layers, width 128, and 4 attention heads\"\n",
        "    model = Decoder(\n",
        "        dim=128, num_layers=2, num_heads=4, num_tokens=args.p + 2, seq_len=5\n",
        "    ).to(device)\n",
        "    nparams = sum([p.numel() for p in model.parameters() if p.requires_grad])\n",
        "    print(model)\n",
        "    print(f'Total number of parameters: {nparams}')\n",
        "\n",
        "    data = multiplication_mod_p_data(args.p, eq_token, op_token)\n",
        "\n",
        "    # Split the subset into training and validation sets\n",
        "    split_idx = data.shape[1] // 2\n",
        "    perm = torch.randperm(data.shape[1])\n",
        "    train_idx = perm[:split_idx]\n",
        "    valid_idx = perm[split_idx:]\n",
        "    train_data = data[:, train_idx]\n",
        "    valid_data = data[:, valid_idx]\n",
        "\n",
        "    # For most experiments we used AdamW optimizer with learning rate 10−3,\n",
        "    # weight decay 1, β1 = 0.9, β2 = 0.98\n",
        "    optimizer = getattr(torch.optim, args.optimizer)(\n",
        "        model.parameters(),\n",
        "        lr=args.lr,\n",
        "        weight_decay=args.weight_decay,\n",
        "        betas=(args.beta1, args.beta2),\n",
        "    )\n",
        "\n",
        "    #  linear learning rate warmup over the first 10 updates\n",
        "    scheduler = torch.optim.lr_scheduler.LambdaLR(\n",
        "        optimizer, lambda update: 1 if update > 10 else update / 10\n",
        "    )\n",
        "\n",
        "    steps_per_epoch = math.ceil(train_data.shape[1] / args.batch_size)\n",
        "\n",
        "    its, train_acc, val_acc, train_loss, val_loss = [], [], [], [], []\n",
        "    grads = None\n",
        "    i = 0\n",
        "\n",
        "    # For logging network weights.\n",
        "    net_its, nets = [], []\n",
        "\n",
        "    for e in tqdm(range(int(args.budget) // steps_per_epoch)):\n",
        "\n",
        "        # randomly shuffle train data\n",
        "        train_data = train_data[:, torch.randperm(train_data.shape[1])]\n",
        "\n",
        "        for data, is_train in [(train_data, True), (valid_data, False)]:\n",
        "\n",
        "            model.train(is_train)\n",
        "            total_loss = 0\n",
        "            total_acc = 0\n",
        "\n",
        "            # torch.split faster than dataloader with tensor\n",
        "            dl = torch.split(data, args.batch_size, dim=1)\n",
        "            for input in dl:\n",
        "                input = input.to(device)\n",
        "\n",
        "\n",
        "                with torch.set_grad_enabled(is_train):\n",
        "                    logits = model(input[:-1])\n",
        "                    # calculate loss only on the answer part of the equation (last element\n",
        "                    loss = F.cross_entropy(logits[-1], input[-1])\n",
        "                    total_loss += loss.item() * input.shape[-1]\n",
        "\n",
        "                if is_train:\n",
        "                    model.zero_grad()\n",
        "                    loss.backward()\n",
        "\n",
        "                    #######\n",
        "\n",
        "                    trigger = i < 500 if args.two_stage else False\n",
        "\n",
        "                    if args.filter == \"none\":\n",
        "                        pass\n",
        "                    elif args.filter == \"ma\":\n",
        "                        grads = gradfilter_ma(model, grads=grads, window_size=args.window_size, lamb=args.lamb, trigger=trigger)\n",
        "                    elif args.filter == \"ema\":\n",
        "                        grads = gradfilter_ema(model, grads=grads, alpha=args.alpha, lamb=args.lamb)\n",
        "                    else:\n",
        "                        raise ValueError(f\"Invalid gradient filter type `{args.filter}`\")\n",
        "\n",
        "                    #######\n",
        "\n",
        "                    optimizer.step()\n",
        "                    scheduler.step()\n",
        "                    i += 1\n",
        "\n",
        "                acc = (logits[-1].argmax(-1) == input[-1]).float().mean()\n",
        "                total_acc += acc.item() * input.shape[-1]\n",
        "\n",
        "            if is_train:\n",
        "                train_acc.append(total_acc / train_data.shape[-1])\n",
        "                train_loss.append(total_loss / train_data.shape[-1])\n",
        "                its.append(i)\n",
        "            else:\n",
        "                val_acc.append(total_acc / valid_data.shape[-1])\n",
        "                val_loss.append(total_loss / valid_data.shape[-1])\n",
        "\n",
        "        if args.save_weights:\n",
        "            do_save = e <= 500 or (e > 500 and (e + 1) % 100 == 0) or e == int(args.budget) // steps_per_epoch - 1\n",
        "        else:\n",
        "            do_save = (e + 1) % 100 == 0\n",
        "        if do_save:\n",
        "            steps = torch.arange(len(train_acc)).numpy() * steps_per_epoch\n",
        "            plt.plot(steps, train_acc, label=\"train\")\n",
        "            plt.plot(steps, val_acc, label=\"val\")\n",
        "            plt.legend()\n",
        "            plt.title(\"Modular Multiplication (training on 50% of data)\")\n",
        "            plt.xlabel(\"Optimization Steps\")\n",
        "            plt.ylabel(\"Accuracy\")\n",
        "            plt.xscale(\"log\", base=10)\n",
        "            plt.grid()\n",
        "            plt.savefig(f\"{results_dir}/acc_{args.label}.png\", dpi=150)\n",
        "            plt.close()\n",
        "\n",
        "            plt.plot(steps, train_loss, label=\"train\")\n",
        "            plt.plot(steps, val_loss, label=\"val\")\n",
        "            plt.legend()\n",
        "            plt.title(\"Modular Multiplication (training on 50% of data)\")\n",
        "            plt.xlabel(\"Optimization Steps\")\n",
        "            plt.ylabel(\"Loss\")\n",
        "            plt.xscale(\"log\", base=10)\n",
        "            plt.grid()\n",
        "            plt.savefig(f\"{results_dir}/loss_{args.label}.png\", dpi=150)\n",
        "            plt.close()\n",
        "\n",
        "            results = {\n",
        "                'its': its,\n",
        "                'train_acc': train_acc,\n",
        "                'train_loss': train_loss,\n",
        "                'val_acc': val_acc,\n",
        "                'val_loss': val_loss,\n",
        "            }\n",
        "\n",
        "            if args.save_weights:\n",
        "                net_its.append(e)\n",
        "                nets.append(copy.deepcopy(model.state_dict()))\n",
        "                results['net_its'] = net_its\n",
        "                results['net'] = nets\n",
        "\n",
        "            torch.save(results, f\"{results_dir}/res_{args.label}.pt\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ],
      "metadata": {
        "id": "Dne-ziHDdwNG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e1f45f30-654a-4ec3-aed2-88d5855cd988"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "chBCi5e6M0L9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 738
        },
        "outputId": "91ed287a-f459-4cc7-9917-a8937a7a1510"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Experiment results saved under name: none\n",
            "Dataset size: 1.0\n",
            "Decoder(\n",
            "  (token_embeddings): Embedding(99, 128)\n",
            "  (position_embeddings): Embedding(5, 128)\n",
            "  (layers): ModuleList(\n",
            "    (0-1): 2 x Block(\n",
            "      (ln_1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
            "      (ln_2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
            "      (attn): MultiheadAttention(\n",
            "        (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
            "      )\n",
            "      (mlp): Sequential(\n",
            "        (0): Linear(in_features=128, out_features=512, bias=True)\n",
            "        (1): GELU(approximate='none')\n",
            "        (2): Linear(in_features=512, out_features=128, bias=True)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (ln_f): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
            "  (head): Linear(in_features=128, out_features=99, bias=False)\n",
            ")\n",
            "Total number of parameters: 422784\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 7/15789 [00:10<6:36:07,  1.51s/it]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-0497422d51d5>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m    \u001b[0;31m# Call main\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-13-11a58f3cb4ea>\u001b[0m in \u001b[0;36mmain\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m     80\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mis_train\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m                     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m                     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m                     \u001b[0;31m#######\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    579\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    580\u001b[0m             )\n\u001b[0;32m--> 581\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    582\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    583\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    345\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 347\u001b[0;31m     _engine_run_backward(\n\u001b[0m\u001b[1;32m    348\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\u001b[0m in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    823\u001b[0m         \u001b[0munregister_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_register_logging_hooks_on_whole_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    824\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 825\u001b[0;31m         return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    826\u001b[0m             \u001b[0mt_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m         )  # Calls into the C++ engine to run the backward pass\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "if __name__ == \"__main__\":\n",
        "    parser = ArgumentParser()\n",
        "    parser.add_argument(\"--label\", default=\"\")\n",
        "    parser.add_argument(\"--seed\", type=int, default=0)\n",
        "    parser.add_argument(\"--p\", type=int, default=97)\n",
        "    parser.add_argument(\"--budget\", type=int, default=3e5)\n",
        "    parser.add_argument(\"--batch_size\", type=int, default=256)\n",
        "    parser.add_argument(\"--lr\", type=float, default=1e-3)\n",
        "    parser.add_argument(\"--beta1\", type=float, default=0.9)\n",
        "    parser.add_argument(\"--beta2\", type=float, default=0.98)\n",
        "    parser.add_argument(\"--weight_decay\", type=float, default=0)\n",
        "    parser.add_argument(\"--optimizer\", default=\"Adam\")\n",
        "    parser.add_argument(\"--filter\", type=str, choices=[\"none\", \"ma\", \"ema\", \"fir\"], default=\"none\")\n",
        "    parser.add_argument(\"--alpha\", type=float, default=0.99)\n",
        "    parser.add_argument(\"--window_size\", type=int, default=50)\n",
        "    parser.add_argument(\"--lamb\", type=float, default=5.0)\n",
        "    parser.add_argument(\"--two_stage\", action='store_true')\n",
        "    parser.add_argument(\"--save_weights\", action='store_true')\n",
        "    parser.add_argument(\"--dataset_fraction\", type=float, default=1.0, help=\"Fraction of the dataset to use (0.0 to 1.0)\")\n",
        "\n",
        "\n",
        "    # Parse known arguments to handle Jupyter conflicts\n",
        "    args, unknown = parser.parse_known_args()\n",
        "\n",
        "    # Modify label dynamically\n",
        "    filter_str = ('_' if args.label != '' else '') + args.filter\n",
        "    window_size_str = f'_w{args.window_size}'\n",
        "    alpha_str = f'_a{args.alpha:.3f}'.replace('.', '')\n",
        "    lamb_str = f'_l{int(args.lamb)}'\n",
        "\n",
        "    if args.filter == \"none\":\n",
        "        filter_suffix = \"\"\n",
        "    elif args.filter == \"ma\":\n",
        "        filter_suffix = window_size_str + lamb_str\n",
        "    elif args.filter == \"ema\":\n",
        "        filter_suffix = alpha_str + lamb_str\n",
        "    else:\n",
        "        raise ValueError(f\"Unrecognized filter type {args.filter}\")\n",
        "\n",
        "    optim_suffix = \"\"\n",
        "    if args.weight_decay != 0:\n",
        "        optim_suffix = optim_suffix + f'_wd{args.weight_decay:.1e}'.replace('.', '')\n",
        "    if args.lr != 1e-3:\n",
        "        optim_suffix = optim_suffix + f'_lrx{int(args.lr / 1e-3)}'\n",
        "\n",
        "    args.label = args.label + filter_str + filter_suffix + optim_suffix\n",
        "    print(f\"Experiment results saved under name: {args.label}\")\n",
        "\n",
        "    print(f\"Dataset size: {args.dataset_fraction}\")\n",
        "\n",
        "\n",
        "   # Call main\n",
        "    main(args)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Running EMA algoritmh with window=20 below"
      ],
      "metadata": {
        "id": "QKy1yxUci2h1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    parser = ArgumentParser()\n",
        "    parser.add_argument(\"--label\", default=\"\")\n",
        "    parser.add_argument(\"--seed\", type=int, default=0)\n",
        "    parser.add_argument(\"--p\", type=int, default=97)\n",
        "    parser.add_argument(\"--budget\", type=int, default=3e5)\n",
        "    parser.add_argument(\"--batch_size\", type=int, default=256)\n",
        "    parser.add_argument(\"--lr\", type=float, default=1e-3)\n",
        "    parser.add_argument(\"--beta1\", type=float, default=0.9)\n",
        "    parser.add_argument(\"--beta2\", type=float, default=0.98)\n",
        "    parser.add_argument(\"--weight_decay\", type=float, default=0.0001)\n",
        "    parser.add_argument(\"--optimizer\", default=\"Adam\")\n",
        "    parser.add_argument(\"--filter\", type=str, choices=[\"none\", \"ma\", \"ema\", \"fir\"], default=\"none\")\n",
        "    parser.add_argument(\"--alpha\", type=float, default=0.99)\n",
        "    parser.add_argument(\"--window_size\", type=int, default=50)\n",
        "    parser.add_argument(\"--lamb\", type=float, default=5.0)\n",
        "    parser.add_argument(\"--two_stage\", action='store_true')\n",
        "    parser.add_argument(\"--save_weights\", action='store_true')\n",
        "    parser.add_argument(\"--dataset_fraction\", type=float, default=1.0, help=\"Fraction of the dataset to use (0.0 to 1.0)\")\n",
        "\n",
        "\n",
        "    # Parse known arguments to handle Jupyter conflicts\n",
        "    args, unknown = parser.parse_known_args()\n",
        "\n",
        "    # Modify label dynamically\n",
        "    filter_str = ('_' if args.label != '' else '') + args.filter\n",
        "    window_size_str = f'_w{args.window_size}'\n",
        "    alpha_str = f'_a{args.alpha:.3f}'.replace('.', '')\n",
        "    lamb_str = f'_l{int(args.lamb)}'\n",
        "\n",
        "    if args.filter == \"none\":\n",
        "        filter_suffix = \"\"\n",
        "    elif args.filter == \"ma\":\n",
        "        filter_suffix = window_size_str + lamb_str\n",
        "    elif args.filter == \"ema\":\n",
        "        filter_suffix = alpha_str + lamb_str\n",
        "    else:\n",
        "        raise ValueError(f\"Unrecognized filter type {args.filter}\")\n",
        "\n",
        "    optim_suffix = \"\"\n",
        "    if args.weight_decay != 0:\n",
        "        optim_suffix = optim_suffix + f'_wd{args.weight_decay:.1e}'.replace('.', '')\n",
        "    if args.lr != 1e-3:\n",
        "        optim_suffix = optim_suffix + f'_lrx{int(args.lr / 1e-3)}'\n",
        "\n",
        "    args.label = args.label + filter_str + filter_suffix + optim_suffix\n",
        "    print(f\"Experiment results saved under name: {args.label}\")\n",
        "\n",
        "    print(f\"Dataset size: {args.dataset_fraction}\")\n",
        "\n",
        "\n",
        "   # Call main\n",
        "    main(args)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u1PV4D6EPtDl",
        "outputId": "1a5edb33-7a1c-454a-ab54-6938c71cd4cc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Experiment results saved under name: none_wd10e-04\n",
            "Dataset size: 1.0\n",
            "Decoder(\n",
            "  (token_embeddings): Embedding(99, 128)\n",
            "  (position_embeddings): Embedding(5, 128)\n",
            "  (layers): ModuleList(\n",
            "    (0-1): 2 x Block(\n",
            "      (ln_1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
            "      (ln_2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
            "      (attn): MultiheadAttention(\n",
            "        (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
            "      )\n",
            "      (mlp): Sequential(\n",
            "        (0): Linear(in_features=128, out_features=512, bias=True)\n",
            "        (1): GELU(approximate='none')\n",
            "        (2): Linear(in_features=512, out_features=128, bias=True)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (ln_f): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
            "  (head): Linear(in_features=128, out_features=99, bias=False)\n",
            ")\n",
            "Total number of parameters: 422784\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15789/15789 [42:59<00:00,  6.12it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    parser = ArgumentParser()\n",
        "    parser.add_argument(\"--label\", default=\"\")\n",
        "    parser.add_argument(\"--seed\", type=int, default=0)\n",
        "    parser.add_argument(\"--p\", type=int, default=97)\n",
        "    parser.add_argument(\"--budget\", type=int, default=3e5)\n",
        "    parser.add_argument(\"--batch_size\", type=int, default=256)\n",
        "    parser.add_argument(\"--lr\", type=float, default=1e-3)\n",
        "    parser.add_argument(\"--beta1\", type=float, default=0.9)\n",
        "    parser.add_argument(\"--beta2\", type=float, default=0.98)\n",
        "    parser.add_argument(\"--weight_decay\", type=float, default=0.0005)\n",
        "    parser.add_argument(\"--optimizer\", default=\"Adam\")\n",
        "    parser.add_argument(\"--filter\", type=str, choices=[\"none\", \"ma\", \"ema\", \"fir\"], default=\"none\")\n",
        "    parser.add_argument(\"--alpha\", type=float, default=0.99)\n",
        "    parser.add_argument(\"--window_size\", type=int, default=50)\n",
        "    parser.add_argument(\"--lamb\", type=float, default=5.0)\n",
        "    parser.add_argument(\"--two_stage\", action='store_true')\n",
        "    parser.add_argument(\"--save_weights\", action='store_true')\n",
        "    parser.add_argument(\"--dataset_fraction\", type=float, default=1.0, help=\"Fraction of the dataset to use (0.0 to 1.0)\")\n",
        "\n",
        "\n",
        "    # Parse known arguments to handle Jupyter conflicts\n",
        "    args, unknown = parser.parse_known_args()\n",
        "\n",
        "    # Modify label dynamically\n",
        "    filter_str = ('_' if args.label != '' else '') + args.filter\n",
        "    window_size_str = f'_w{args.window_size}'\n",
        "    alpha_str = f'_a{args.alpha:.3f}'.replace('.', '')\n",
        "    lamb_str = f'_l{int(args.lamb)}'\n",
        "\n",
        "    if args.filter == \"none\":\n",
        "        filter_suffix = \"\"\n",
        "    elif args.filter == \"ma\":\n",
        "        filter_suffix = window_size_str + lamb_str\n",
        "    elif args.filter == \"ema\":\n",
        "        filter_suffix = alpha_str + lamb_str\n",
        "    else:\n",
        "        raise ValueError(f\"Unrecognized filter type {args.filter}\")\n",
        "\n",
        "    optim_suffix = \"\"\n",
        "    if args.weight_decay != 0:\n",
        "        optim_suffix = optim_suffix + f'_wd{args.weight_decay:.1e}'.replace('.', '')\n",
        "    if args.lr != 1e-3:\n",
        "        optim_suffix = optim_suffix + f'_lrx{int(args.lr / 1e-3)}'\n",
        "\n",
        "    args.label = args.label + filter_str + filter_suffix + optim_suffix\n",
        "    print(f\"Experiment results saved under name: {args.label}\")\n",
        "\n",
        "    print(f\"Dataset size: {args.dataset_fraction}\")\n",
        "\n",
        "\n",
        "   # Call main\n",
        "    main(args)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SWu2ddzlQQKF",
        "outputId": "3991ed9e-0bd7-4f42-f634-48aea75338b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Experiment results saved under name: none_wd50e-04\n",
            "Dataset size: 1.0\n",
            "Decoder(\n",
            "  (token_embeddings): Embedding(99, 128)\n",
            "  (position_embeddings): Embedding(5, 128)\n",
            "  (layers): ModuleList(\n",
            "    (0-1): 2 x Block(\n",
            "      (ln_1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
            "      (ln_2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
            "      (attn): MultiheadAttention(\n",
            "        (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
            "      )\n",
            "      (mlp): Sequential(\n",
            "        (0): Linear(in_features=128, out_features=512, bias=True)\n",
            "        (1): GELU(approximate='none')\n",
            "        (2): Linear(in_features=512, out_features=128, bias=True)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (ln_f): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
            "  (head): Linear(in_features=128, out_features=99, bias=False)\n",
            ")\n",
            "Total number of parameters: 422784\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15789/15789 [43:20<00:00,  6.07it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    parser = ArgumentParser()\n",
        "    parser.add_argument(\"--label\", default=\"\")\n",
        "    parser.add_argument(\"--seed\", type=int, default=0)\n",
        "    parser.add_argument(\"--p\", type=int, default=97)\n",
        "    parser.add_argument(\"--budget\", type=int, default=3e5)\n",
        "    parser.add_argument(\"--batch_size\", type=int, default=256)\n",
        "    parser.add_argument(\"--lr\", type=float, default=1e-3)\n",
        "    parser.add_argument(\"--beta1\", type=float, default=0.9)\n",
        "    parser.add_argument(\"--beta2\", type=float, default=0.98)\n",
        "    parser.add_argument(\"--weight_decay\", type=float, default=0.001)\n",
        "    parser.add_argument(\"--optimizer\", default=\"Adam\")\n",
        "    parser.add_argument(\"--filter\", type=str, choices=[\"none\", \"ma\", \"ema\", \"fir\"], default=\"none\")\n",
        "    parser.add_argument(\"--alpha\", type=float, default=0.99)\n",
        "    parser.add_argument(\"--window_size\", type=int, default=50)\n",
        "    parser.add_argument(\"--lamb\", type=float, default=5.0)\n",
        "    parser.add_argument(\"--two_stage\", action='store_true')\n",
        "    parser.add_argument(\"--save_weights\", action='store_true')\n",
        "    parser.add_argument(\"--dataset_fraction\", type=float, default=1.0, help=\"Fraction of the dataset to use (0.0 to 1.0)\")\n",
        "\n",
        "\n",
        "    # Parse known arguments to handle Jupyter conflicts\n",
        "    args, unknown = parser.parse_known_args()\n",
        "\n",
        "    # Modify label dynamically\n",
        "    filter_str = ('_' if args.label != '' else '') + args.filter\n",
        "    window_size_str = f'_w{args.window_size}'\n",
        "    alpha_str = f'_a{args.alpha:.3f}'.replace('.', '')\n",
        "    lamb_str = f'_l{int(args.lamb)}'\n",
        "\n",
        "    if args.filter == \"none\":\n",
        "        filter_suffix = \"\"\n",
        "    elif args.filter == \"ma\":\n",
        "        filter_suffix = window_size_str + lamb_str\n",
        "    elif args.filter == \"ema\":\n",
        "        filter_suffix = alpha_str + lamb_str\n",
        "    else:\n",
        "        raise ValueError(f\"Unrecognized filter type {args.filter}\")\n",
        "\n",
        "    optim_suffix = \"\"\n",
        "    if args.weight_decay != 0:\n",
        "        optim_suffix = optim_suffix + f'_wd{args.weight_decay:.1e}'.replace('.', '')\n",
        "    if args.lr != 1e-3:\n",
        "        optim_suffix = optim_suffix + f'_lrx{int(args.lr / 1e-3)}'\n",
        "\n",
        "    args.label = args.label + filter_str + filter_suffix + optim_suffix\n",
        "    print(f\"Experiment results saved under name: {args.label}\")\n",
        "\n",
        "    print(f\"Dataset size: {args.dataset_fraction}\")\n",
        "\n",
        "\n",
        "   # Call main\n",
        "    main(args)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pp4PXec6QTie",
        "outputId": "51f48c75-4219-4520-eaca-e0da7c82bd9c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Experiment results saved under name: none_wd10e-03\n",
            "Dataset size: 1.0\n",
            "Decoder(\n",
            "  (token_embeddings): Embedding(99, 128)\n",
            "  (position_embeddings): Embedding(5, 128)\n",
            "  (layers): ModuleList(\n",
            "    (0-1): 2 x Block(\n",
            "      (ln_1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
            "      (ln_2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
            "      (attn): MultiheadAttention(\n",
            "        (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
            "      )\n",
            "      (mlp): Sequential(\n",
            "        (0): Linear(in_features=128, out_features=512, bias=True)\n",
            "        (1): GELU(approximate='none')\n",
            "        (2): Linear(in_features=512, out_features=128, bias=True)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (ln_f): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
            "  (head): Linear(in_features=128, out_features=99, bias=False)\n",
            ")\n",
            "Total number of parameters: 422784\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15789/15789 [42:52<00:00,  6.14it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    parser = ArgumentParser()\n",
        "    parser.add_argument(\"--label\", default=\"\")\n",
        "    parser.add_argument(\"--seed\", type=int, default=0)\n",
        "    parser.add_argument(\"--p\", type=int, default=97)\n",
        "    parser.add_argument(\"--budget\", type=int, default=3e5)\n",
        "    parser.add_argument(\"--batch_size\", type=int, default=256)\n",
        "    parser.add_argument(\"--lr\", type=float, default=1e-3)\n",
        "    parser.add_argument(\"--beta1\", type=float, default=0.9)\n",
        "    parser.add_argument(\"--beta2\", type=float, default=0.98)\n",
        "    parser.add_argument(\"--weight_decay\", type=float, default=0.01)\n",
        "    parser.add_argument(\"--optimizer\", default=\"Adam\")\n",
        "    parser.add_argument(\"--filter\", type=str, choices=[\"none\", \"ma\", \"ema\", \"fir\"], default=\"none\")\n",
        "    parser.add_argument(\"--alpha\", type=float, default=0.99)\n",
        "    parser.add_argument(\"--window_size\", type=int, default=50)\n",
        "    parser.add_argument(\"--lamb\", type=float, default=5.0)\n",
        "    parser.add_argument(\"--two_stage\", action='store_true')\n",
        "    parser.add_argument(\"--save_weights\", action='store_true')\n",
        "    parser.add_argument(\"--dataset_fraction\", type=float, default=1.0, help=\"Fraction of the dataset to use (0.0 to 1.0)\")\n",
        "\n",
        "\n",
        "    # Parse known arguments to handle Jupyter conflicts\n",
        "    args, unknown = parser.parse_known_args()\n",
        "\n",
        "    # Modify label dynamically\n",
        "    filter_str = ('_' if args.label != '' else '') + args.filter\n",
        "    window_size_str = f'_w{args.window_size}'\n",
        "    alpha_str = f'_a{args.alpha:.3f}'.replace('.', '')\n",
        "    lamb_str = f'_l{int(args.lamb)}'\n",
        "\n",
        "    if args.filter == \"none\":\n",
        "        filter_suffix = \"\"\n",
        "    elif args.filter == \"ma\":\n",
        "        filter_suffix = window_size_str + lamb_str\n",
        "    elif args.filter == \"ema\":\n",
        "        filter_suffix = alpha_str + lamb_str\n",
        "    else:\n",
        "        raise ValueError(f\"Unrecognized filter type {args.filter}\")\n",
        "\n",
        "    optim_suffix = \"\"\n",
        "    if args.weight_decay != 0:\n",
        "        optim_suffix = optim_suffix + f'_wd{args.weight_decay:.1e}'.replace('.', '')\n",
        "    if args.lr != 1e-3:\n",
        "        optim_suffix = optim_suffix + f'_lrx{int(args.lr / 1e-3)}'\n",
        "\n",
        "    args.label = args.label + filter_str + filter_suffix + optim_suffix\n",
        "    print(f\"Experiment results saved under name: {args.label}\")\n",
        "\n",
        "    print(f\"Dataset size: {args.dataset_fraction}\")\n",
        "\n",
        "\n",
        "   # Call main\n",
        "    main(args)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LXYa3yKfRPH2",
        "outputId": "038b54c4-7965-45e4-bb10-e6d94c02499e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Experiment results saved under name: none_wd10e-02\n",
            "Dataset size: 1.0\n",
            "Decoder(\n",
            "  (token_embeddings): Embedding(99, 128)\n",
            "  (position_embeddings): Embedding(5, 128)\n",
            "  (layers): ModuleList(\n",
            "    (0-1): 2 x Block(\n",
            "      (ln_1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
            "      (ln_2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
            "      (attn): MultiheadAttention(\n",
            "        (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
            "      )\n",
            "      (mlp): Sequential(\n",
            "        (0): Linear(in_features=128, out_features=512, bias=True)\n",
            "        (1): GELU(approximate='none')\n",
            "        (2): Linear(in_features=512, out_features=128, bias=True)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (ln_f): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
            "  (head): Linear(in_features=128, out_features=99, bias=False)\n",
            ")\n",
            "Total number of parameters: 422784\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15789/15789 [43:24<00:00,  6.06it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    parser = ArgumentParser()\n",
        "    parser.add_argument(\"--label\", default=\"\")\n",
        "    parser.add_argument(\"--seed\", type=int, default=0)\n",
        "    parser.add_argument(\"--p\", type=int, default=97)\n",
        "    parser.add_argument(\"--budget\", type=int, default=3e5)\n",
        "    parser.add_argument(\"--batch_size\", type=int, default=256)\n",
        "    parser.add_argument(\"--lr\", type=float, default=1e-3)\n",
        "    parser.add_argument(\"--beta1\", type=float, default=0.9)\n",
        "    parser.add_argument(\"--beta2\", type=float, default=0.98)\n",
        "    parser.add_argument(\"--weight_decay\", type=float, default=0.005)\n",
        "    parser.add_argument(\"--optimizer\", default=\"Adam\")\n",
        "    parser.add_argument(\"--filter\", type=str, choices=[\"none\", \"ma\", \"ema\", \"fir\"], default=\"none\")\n",
        "    parser.add_argument(\"--alpha\", type=float, default=0.99)\n",
        "    parser.add_argument(\"--window_size\", type=int, default=50)\n",
        "    parser.add_argument(\"--lamb\", type=float, default=5.0)\n",
        "    parser.add_argument(\"--two_stage\", action='store_true')\n",
        "    parser.add_argument(\"--save_weights\", action='store_true')\n",
        "    parser.add_argument(\"--dataset_fraction\", type=float, default=1.0, help=\"Fraction of the dataset to use (0.0 to 1.0)\")\n",
        "\n",
        "\n",
        "    # Parse known arguments to handle Jupyter conflicts\n",
        "    args, unknown = parser.parse_known_args()\n",
        "\n",
        "    # Modify label dynamically\n",
        "    filter_str = ('_' if args.label != '' else '') + args.filter\n",
        "    window_size_str = f'_w{args.window_size}'\n",
        "    alpha_str = f'_a{args.alpha:.3f}'.replace('.', '')\n",
        "    lamb_str = f'_l{int(args.lamb)}'\n",
        "\n",
        "    if args.filter == \"none\":\n",
        "        filter_suffix = \"\"\n",
        "    elif args.filter == \"ma\":\n",
        "        filter_suffix = window_size_str + lamb_str\n",
        "    elif args.filter == \"ema\":\n",
        "        filter_suffix = alpha_str + lamb_str\n",
        "    else:\n",
        "        raise ValueError(f\"Unrecognized filter type {args.filter}\")\n",
        "\n",
        "    optim_suffix = \"\"\n",
        "    if args.weight_decay != 0:\n",
        "        optim_suffix = optim_suffix + f'_wd{args.weight_decay:.1e}'.replace('.', '')\n",
        "    if args.lr != 1e-3:\n",
        "        optim_suffix = optim_suffix + f'_lrx{int(args.lr / 1e-3)}'\n",
        "\n",
        "    args.label = args.label + filter_str + filter_suffix + optim_suffix\n",
        "    print(f\"Experiment results saved under name: {args.label}\")\n",
        "\n",
        "    print(f\"Dataset size: {args.dataset_fraction}\")\n",
        "\n",
        "\n",
        "   # Call main\n",
        "    main(args)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 755
        },
        "id": "IK8ONedcVst7",
        "outputId": "22cf26a3-9917-4f9d-c605-4de3f46c50c6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Experiment results saved under name: none_wd50e-03\n",
            "Dataset size: 1.0\n",
            "Decoder(\n",
            "  (token_embeddings): Embedding(99, 128)\n",
            "  (position_embeddings): Embedding(5, 128)\n",
            "  (layers): ModuleList(\n",
            "    (0-1): 2 x Block(\n",
            "      (ln_1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
            "      (ln_2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
            "      (attn): MultiheadAttention(\n",
            "        (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
            "      )\n",
            "      (mlp): Sequential(\n",
            "        (0): Linear(in_features=128, out_features=512, bias=True)\n",
            "        (1): GELU(approximate='none')\n",
            "        (2): Linear(in_features=512, out_features=128, bias=True)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (ln_f): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
            "  (head): Linear(in_features=128, out_features=99, bias=False)\n",
            ")\n",
            "Total number of parameters: 422784\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  3%|▎         | 539/15789 [12:36<5:56:52,  1.40s/it]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-cfc60dc6e6b7>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m    \u001b[0;31m# Call main\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-13-11a58f3cb4ea>\u001b[0m in \u001b[0;36mmain\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_grad_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m                     \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m                     \u001b[0;31m# calculate loss only on the answer part of the equation (last element\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m                     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_entropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-10-95143f75131c>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m         \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mln_f\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m         \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlogits\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/normalization.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m         return F.layer_norm(\n\u001b[0m\u001b[1;32m    218\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalized_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlayer_norm\u001b[0;34m(input, normalized_shape, weight, bias, eps)\u001b[0m\n\u001b[1;32m   2898\u001b[0m             \u001b[0meps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2899\u001b[0m         )\n\u001b[0;32m-> 2900\u001b[0;31m     return torch.layer_norm(\n\u001b[0m\u001b[1;32m   2901\u001b[0m         \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnormalized_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackends\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcudnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menabled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2902\u001b[0m     )\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from argparse import ArgumentParser\n",
        "\n",
        "def main(args):\n",
        "    # Placeholder for the main function logic\n",
        "    print(f\"Running experiment with label: {args.label}\")\n",
        "    print(f\"Weight Decay: {args.weight_decay}, Learning Rate: {args.lr}, Filter: {args.filter}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    weight_decays = [0, 0.0001, 0.0005, 0.001, 0.01]\n",
        "\n",
        "    for wd in weight_decays:\n",
        "        parser = ArgumentParser()\n",
        "        parser.add_argument(\"--label\", default=\"\")\n",
        "        parser.add_argument(\"--seed\", type=int, default=0)\n",
        "        parser.add_argument(\"--p\", type=int, default=97)\n",
        "        parser.add_argument(\"--budget\", type=int, default=int(3e5))\n",
        "        parser.add_argument(\"--batch_size\", type=int, default=256)\n",
        "        parser.add_argument(\"--lr\", type=float, default=1e-3)\n",
        "        parser.add_argument(\"--beta1\", type=float, default=0.9)\n",
        "        parser.add_argument(\"--beta2\", type=float, default=0.98)\n",
        "        parser.add_argument(\"--weight_decay\", type=float, default=wd)\n",
        "        parser.add_argument(\"--optimizer\", default=\"Adam\")\n",
        "        parser.add_argument(\"--filter\", type=str, choices=[\"none\", \"ma\", \"ema\", \"fir\"], default=\"none\")\n",
        "        parser.add_argument(\"--alpha\", type=float, default=0.98)\n",
        "        parser.add_argument(\"--window_size\", type=int, default=50)\n",
        "        parser.add_argument(\"--lamb\", type=float, default=5.0)\n",
        "        parser.add_argument(\"--two_stage\", action='store_true')\n",
        "        parser.add_argument(\"--save_weights\", action='store_true')\n",
        "        parser.add_argument(\"--dataset_fraction\", type=float, default=1.0, help=\"Fraction of the dataset to use (0.0 to 1.0)\")\n",
        "\n",
        "        args, unknown = parser.parse_known_args()\n",
        "\n",
        "        filter_str = ('_' if args.label != '' else '') + args.filter\n",
        "        window_size_str = f'_w{args.window_size}'\n",
        "        alpha_str = f'_a{args.alpha:.3f}'.replace('.', '')\n",
        "        lamb_str = f'_l{int(args.lamb)}'\n",
        "\n",
        "        if args.filter == \"none\":\n",
        "            filter_suffix = \"\"\n",
        "        elif args.filter == \"ma\":\n",
        "            filter_suffix = window_size_str + lamb_str\n",
        "        elif args.filter == \"ema\":\n",
        "            filter_suffix = alpha_str + lamb_str\n",
        "        else:\n",
        "            raise ValueError(f\"Unrecognized filter type {args.filter}\")\n",
        "\n",
        "        optim_suffix = \"\"\n",
        "        if args.weight_decay != 0:\n",
        "            optim_suffix += f'_wd{args.weight_decay:.1e}'.replace('.', '')\n",
        "        if args.lr != 1e-3:\n",
        "            optim_suffix += f'_lrx{int(args.lr / 1e-3)}'\n",
        "\n",
        "        args.label = args.label + filter_str + filter_suffix + optim_suffix\n",
        "        print(f\"Experiment results saved under name: {args.label}\")\n",
        "        print(f\"Dataset size: {args.dataset_fraction}\")\n",
        "\n",
        "        main(args)\n"
      ],
      "metadata": {
        "id": "KxlnAH9Qitqx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2672f258-aa39-4d89-a90b-4d8ac7a6a9ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Experiment results saved under name: none\n",
            "Dataset size: 1.0\n",
            "Running experiment with label: none\n",
            "Weight Decay: 0, Learning Rate: 0.001, Filter: none\n",
            "Experiment results saved under name: none_wd10e-04\n",
            "Dataset size: 1.0\n",
            "Running experiment with label: none_wd10e-04\n",
            "Weight Decay: 0.0001, Learning Rate: 0.001, Filter: none\n",
            "Experiment results saved under name: none_wd50e-04\n",
            "Dataset size: 1.0\n",
            "Running experiment with label: none_wd50e-04\n",
            "Weight Decay: 0.0005, Learning Rate: 0.001, Filter: none\n",
            "Experiment results saved under name: none_wd10e-03\n",
            "Dataset size: 1.0\n",
            "Running experiment with label: none_wd10e-03\n",
            "Weight Decay: 0.001, Learning Rate: 0.001, Filter: none\n",
            "Experiment results saved under name: none_wd10e-02\n",
            "Dataset size: 1.0\n",
            "Running experiment with label: none_wd10e-02\n",
            "Weight Decay: 0.01, Learning Rate: 0.001, Filter: none\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "args = parser.parse_args([\n",
        "    \"--window_size\", \"100\",\n",
        "    \"--batch_size\", \"512\"\n",
        "])\n",
        "\n",
        "print(f\"Experiment results saved under name: {args.label}\")\n",
        "\n",
        "print(f\"Window: {args.window_size}\")\n",
        "\n",
        "print(f\"Batches: {args.batch_size}\")\n",
        "\n",
        "\n",
        "# Call main\n",
        "main(args)"
      ],
      "metadata": {
        "id": "nea6LSCWUrKY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "    parser = ArgumentParser()\n",
        "    parser.add_argument(\"--label\", default=\"\")\n",
        "    parser.add_argument(\"--seed\", type=int, default=0)\n",
        "    parser.add_argument(\"--p\", type=int, default=97)\n",
        "    parser.add_argument(\"--budget\", type=int, default=3e5)\n",
        "    parser.add_argument(\"--batch_size\", type=int, default=256)\n",
        "    parser.add_argument(\"--lr\", type=float, default=1e-3)\n",
        "    parser.add_argument(\"--beta1\", type=float, default=0.9)\n",
        "    parser.add_argument(\"--beta2\", type=float, default=0.98)\n",
        "    parser.add_argument(\"--weight_decay\", type=float, default=0)\n",
        "    parser.add_argument(\"--optimizer\", default=\"Adam\")\n",
        "    parser.add_argument(\"--filter\", type=str, choices=[\"none\", \"ma\", \"ema\", \"fir\"], default=\"none\")\n",
        "    parser.add_argument(\"--alpha\", type=float, default=0.99)\n",
        "    parser.add_argument(\"--window_size\", type=int, default=50)\n",
        "    parser.add_argument(\"--lamb\", type=float, default=5.0)\n",
        "    parser.add_argument(\"--two_stage\", action='store_true')\n",
        "    parser.add_argument(\"--save_weights\", action='store_true')\n",
        "    parser.add_argument(\"--dataset_fraction\", type=float, default=1.0, help=\"Fraction of the dataset to use (0.0 to 1.0)\")"
      ],
      "metadata": {
        "id": "ypF_G-4GpD-q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "    parser = ArgumentParser()\n",
        "    parser.add_argument(\"--label\", default=\"\")\n",
        "    parser.add_argument(\"--seed\", type=int, default=0)\n",
        "    parser.add_argument(\"--p\", type=int, default=97)\n",
        "    parser.add_argument(\"--budget\", type=int, default=3e5)\n",
        "    parser.add_argument(\"--batch_size\", type=int, default=256)\n",
        "    parser.add_argument(\"--lr\", type=float, default=1e-3)\n",
        "    parser.add_argument(\"--beta1\", type=float, default=0.9)\n",
        "    parser.add_argument(\"--beta2\", type=float, default=0.98)\n",
        "    parser.add_argument(\"--weight_decay\", type=float, default=0)\n",
        "    parser.add_argument(\"--optimizer\", default=\"Adam\")\n",
        "    parser.add_argument(\"--filter\", type=str, choices=[\"none\", \"ma\", \"ema\", \"fir\"], default=\"none\")\n",
        "    parser.add_argument(\"--alpha\", type=float, default=0.99)\n",
        "    parser.add_argument(\"--window_size\", type=int, default=50)\n",
        "    parser.add_argument(\"--lamb\", type=float, default=5.0)\n",
        "    parser.add_argument(\"--two_stage\", action='store_true')\n",
        "    parser.add_argument(\"--save_weights\", action='store_true')\n",
        "    parser.add_argument(\"--dataset_fraction\", type=float, default=1.0, help=\"Fraction of the dataset to use (0.0 to 1.0)\")"
      ],
      "metadata": {
        "id": "OfIlZGa8pYq7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "args = parser.parse_args([\n",
        "    \"--window_size\", \"100\",\n",
        "    \"--lamb\", \"2.0\",\n",
        "    \"--alpha\", \"0.98\",\n",
        "    \"--weight_decay\",\"0.005\",\n",
        "    \"--filter\",\"ema\",\n",
        "    \"--batch_size\", \"512\",\n",
        "    \"--label\", \"ema_same_as_paper\"\n",
        "])\n",
        "\n",
        "print(f\"Experiment results saved under name: {args.label}\")\n",
        "\n",
        "print(f\"Alg: {args.filter}\")\n",
        "\n",
        "\n",
        "# Call main\n",
        "main(args)"
      ],
      "metadata": {
        "id": "yoDNKEN6Zsb1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "\n",
        "\n",
        "# Weight decay values and corresponding .pt file names\n",
        "file_names = {\n",
        "    0: \"res_none.pt\",\n",
        "    0.0001: \"res_none_wd10e-04.pt\",\n",
        "    0.0005: \"res_none_wd50e-04.pt\",\n",
        "    0.001: \"res_none_wd10e-03.pt\"\n",
        "}\n",
        "\n",
        "# Initialize lists to store accuracies\n",
        "weight_decays = []\n",
        "train_accuracies = []\n",
        "val_accuracies = []\n",
        "\n",
        "# Load each model and extract accuracies\n",
        "for wd, file_name in file_names.items():\n",
        "    file_path = os.path.join(results_dir, file_name)\n",
        "    if os.path.exists(file_path):\n",
        "        # Use weights_only=True for security\n",
        "        checkpoint = torch.load(file_path, weights_only=True)\n",
        "        train_acc = checkpoint.get('train_accuracy', None)\n",
        "        val_acc = checkpoint.get('val_accuracy', None)\n",
        "\n",
        "        if train_acc is not None and val_acc is not None:\n",
        "            weight_decays.append(wd)\n",
        "            train_accuracies.append(train_acc)\n",
        "            val_accuracies.append(val_acc)\n",
        "    else:\n",
        "        print(f\"File {file_path} does not exist.\")\n",
        "\n",
        "# Plotting the accuracies\n",
        "plt.figure(figsize=(10, 6))\n",
        "\n",
        "# Plot training accuracies\n",
        "plt.plot(weight_decays, train_accuracies, 'o-', label='Training Accuracy')\n",
        "\n",
        "# Plot validation accuracies\n",
        "plt.plot(weight_decays, val_accuracies, 's-', label='Validation Accuracy')\n",
        "\n",
        "# Add labels and title\n",
        "plt.xlabel('Weight Decay')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('Training and Validation Accuracies vs Weight Decay')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "\n",
        "# Show the plot\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "lAZhz7PXZSYg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "outputId": "87dc82bf-7829-468c-c43a-08098796dc96"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}