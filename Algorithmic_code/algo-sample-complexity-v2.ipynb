{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30887,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false},"colab":{"authorship_tag":"ABX9TyMSJa3XxLl7rvVV5eF0x78J","gpuType":"T4","provenance":[]},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"064bec9d457349bb9fa6a559339e9263":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_c9bf43e30b5a499a8de4604dc3f10ee2","IPY_MODEL_17166645b0b14019a9f5fe3d70b6caa5","IPY_MODEL_e451f4ad11bc44f8ab881eed658a8ee3"],"layout":"IPY_MODEL_ceb7ec9cff0049c098ac4b5fc5b6bd3c"}},"07c3736f38804f78bea83bb64c695cac":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"0ff27ff9889744e6af586debee44669c":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":"inline-flex","flex":null,"flex_flow":"row wrap","grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"100%"}},"17166645b0b14019a9f5fe3d70b6caa5":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_1776d91874314cd0ab3df42e1b77bd5d","max":100,"min":0,"orientation":"horizontal","style":"IPY_MODEL_915f46f7e6694bf0b14a91ced2256596","value":100}},"1776d91874314cd0ab3df42e1b77bd5d":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":"2","flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2c00be62ed5f48868daac8e39944ba63":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_740bfc3868e947e68c87f28690b96945","placeholder":"​","style":"IPY_MODEL_73b20e21e4394b6c9326c75594d6f062","value":"Loss: 7.6e+00|1.2e+01. Acc: 11.7%|12.5%: 100%"}},"30e1fcaaa18c40fcbb2182e33df28ea1":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5c0b6a5234ea48e3bf8fa9fb04e7442d","placeholder":"​","style":"IPY_MODEL_ccfc9ef4719e4aef9379f11160003ce1","value":" 100/100 [04:53&lt;00:00,  3.31s/it]"}},"328beb9c29ed4dc094b6e476734a725f":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"36d9e94b822a4a5bb069cd474608bdb6":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"37733b27dcd64ffaafd07959bc847f26":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3a3e587d4127443eb3bbae84621d4d06":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4eb47dc8d09747718044ca73cfadc307":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_936aa9172b2d4e0aa2f0cb84c0dabfad","max":100,"min":0,"orientation":"horizontal","style":"IPY_MODEL_07c3736f38804f78bea83bb64c695cac","value":100}},"5c0b6a5234ea48e3bf8fa9fb04e7442d":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"73b20e21e4394b6c9326c75594d6f062":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"740bfc3868e947e68c87f28690b96945":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"915f46f7e6694bf0b14a91ced2256596":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"936aa9172b2d4e0aa2f0cb84c0dabfad":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":"2","flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c9bf43e30b5a499a8de4604dc3f10ee2":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3a3e587d4127443eb3bbae84621d4d06","placeholder":"​","style":"IPY_MODEL_37733b27dcd64ffaafd07959bc847f26","value":"Loss: 7.6e+00|1.2e+01. Acc: 11.7%|12.5%: 100%"}},"ccfc9ef4719e4aef9379f11160003ce1":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ceb7ec9cff0049c098ac4b5fc5b6bd3c":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":"inline-flex","flex":null,"flex_flow":"row wrap","grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"100%"}},"e451f4ad11bc44f8ab881eed658a8ee3":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_328beb9c29ed4dc094b6e476734a725f","placeholder":"​","style":"IPY_MODEL_36d9e94b822a4a5bb069cd474608bdb6","value":" 100/100 [04:51&lt;00:00,  3.11s/it]"}},"fe873b542e0243ebbf591f5bc21ccd2c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_2c00be62ed5f48868daac8e39944ba63","IPY_MODEL_4eb47dc8d09747718044ca73cfadc307","IPY_MODEL_30e1fcaaa18c40fcbb2182e33df28ea1"],"layout":"IPY_MODEL_0ff27ff9889744e6af586debee44669c"}}}}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Idea 4: Samples fitering - online\n\n## Περιγραφή του αλγορίθμου\n- Γίνεται εκπαίδευση με grokfast - EMA. Όταν **appl_sampl_filter** is False έχω μόνο αυτό, ενώ για True εφαρμόζω επιπλέον και την ιδέα 4 για πιο έξυπνη επιλογή δειγμάτων.\n- Ο Dataloader έχει έναν custom sampler (WeightedRandomSampler) ο οποίος κάθε φορά διαλέγει ένα δείγμα με βάση κάποιο βάρος/πιθανότητα.\n- Στην αρχή τα βάρη είναι όλα ίδια (ομοιόμορφη κατανομή) οπότε ο Dataloader λειτουργεί όπως συνήθως διαλέγοντας τυχαία ένα sample.\n- Σε κάθε επανάληψη φτιάχνεται ένα ranking των δειγμάτων (με βάση του πόσο high frequency περιέχει το καθένα) το οποίο χρησιμοποιείται για να αποφασιστεί τι βάρος/πιθανότητα θα δοθεί σε κάθε δείγμα να επιλεγεί για εκπαίδευση. Το διάνυσμα βαρών/πιθανοτήτων ανανεώνεται κάθε **sampling_distr_upd_freq** επαναλήψεις.\n- Στην κατασκευή του διανύσματος βαρών από την συνολική πιθανότητα 1 δίνουμε στα **top_k** δείγματα συνολικά **top_k_sampling_prob** (και στα υπόλοιπα length(dataset) - **top_k** δείγματα δίνουμε συνολικά το υπόλοιπο 1 - **top_k_sampling_prob**).\n- Με **high_freq_better** is True ακολουθούμε την αρχική μας υπόθεση ότι τα δείγματα με high frequency είναι αυτά που θα πρέπει να ταΐσουμε το δίκτυο περισσότερο για να μάθει γρηγορότερα, για False γίνεται το αντίθετο.\n\n## Οδηγίες χρήσης για τρέξιμο\nΠήγαινε στον τίτλο **Execute training (by running main funciton)**. Πήγαινε στο parser.parse_args και όρισε τις τιμές που θες να δοκιμάσεις για grid search. Οι υπερπαράμετροι που σχετίζονται με την ιδέα 4 online είναι:\n\n- **top_k**\n- **top_k_sampling_prob**\n- **high_freq_better**\n- **sampling_distr_upd_freq**: Μάλλον είναι οκ στο 1 γιατί ακόμα και έτσι η εκπαίδευση δεν είναι αργή οπότε δεν έχω λόγο να το αυξήσω.\n\nΑν κάποιος θέλει να τρέξει κάποιες τιμές για το grid search, έχω βάλει στον φάκελο και ένα αρχείο για να σημειώνουμε τις τιμές των υπερπαραμέτρων που δοκίμασε ο καθένας για να μην τρέχουμε όλοι τα ίδια. Βάλτε GPU P100 (νομίζω είναι ελαφρώς καλύτερη), εμένα για τα 100.000 βήματα που έχω βάλει να είναι το default ένα τρέξιμο που κάνω μόνο με grokfast (δηλαδή **appl_sampl_filter** is False) παίρνει περίπου **7 λεπτά** οπότε καλά είμαστε από χρόνο.\n\n","metadata":{}},{"cell_type":"code","source":"import kagglehub\n\n# Maybe this is needed if you want to import private datasets\n# kagglehub.login()\n","metadata":{"executionInfo":{"elapsed":24569,"status":"ok","timestamp":1737367419894,"user":{"displayName":"Nikolas Xiros","userId":"00495869844002127525"},"user_tz":-120},"id":"f4s6HWPGPSBJ","outputId":"be8dc80d-eeb5-492c-f36e-15ba319dec89","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES,\n# THEN FEEL FREE TO DELETE THIS CELL.\n# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n# NOTEBOOK.\n\n# hojjatk_mnist_dataset_path = kagglehub.dataset_download(\"hojjatk/mnist-dataset\")\n\n# The dataset was uploaded from me but I made it public so you too can probably load it with this line\n# _ = kagglehub.dataset_download(\"konstantinosbarkas/mnist-dataset-processed-from-local\")\n\n# print(\"Data source import complete.\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import sys, os\n# Install the Grokfast library\n!wget https://raw.githubusercontent.com/ironjr/grokfast/main/grokfast.py\n\nsys.path.append(\"/kaggle/working\")\nos.makedirs('/kaggle/working/results/algo_online', exist_ok=True)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# import argparse\n# import gzip\nimport math\nimport random\n# import struct\nimport time\nfrom argparse import ArgumentParser\n# from collections import Counter, defaultdict, deque\nimport itertools\nfrom itertools import islice\n# from pathlib import Path\n# from typing import Dict, List, Literal, Optional\n\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torchvision\nimport torchvision.transforms as transforms\nfrom functorch import grad, vmap\nfrom sklearn.model_selection import train_test_split\nfrom torch.autograd import grad\n\n# from torch.nn.utils.stateless import functional_call, # This is deprecated, use the next one instead\nfrom torch.func import functional_call\nfrom torch.utils.data import DataLoader, Subset, WeightedRandomSampler, Dataset\nfrom tqdm.auto import tqdm\nfrom torch.utils.data import DataLoader\nfrom itertools import islice\nimport torch.nn.functional as F\n\nfrom grokfast import gradfilter_ema,gradfilter_ma\n","metadata":{"executionInfo":{"elapsed":36273,"status":"ok","timestamp":1737367466050,"user":{"displayName":"Nikolas Xiros","userId":"00495869844002127525"},"user_tz":-120},"id":"QLUi9XZMRpId","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nos.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\"  # Enables detailed CUDA error messages\n\nresults_dir = \"/kaggle/working/results/algo_online\"\nos.makedirs(results_dir, exist_ok=True)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"optimizer_dict = {\"AdamW\": torch.optim.AdamW, \"Adam\": torch.optim.Adam, \"SGD\": torch.optim.SGD}\n\nactivation_dict = {\"ReLU\": nn.ReLU, \"Tanh\": nn.Tanh, \"Sigmoid\": nn.Sigmoid, \"GELU\": nn.GELU}\n\nloss_function_dict = {\"MSE\": nn.MSELoss, \"CrossEntropy\": nn.CrossEntropyLoss}\n","metadata":{"executionInfo":{"elapsed":10,"status":"ok","timestamp":1737367466051,"user":{"displayName":"Nikolas Xiros","userId":"00495869844002127525"},"user_tz":-120},"id":"8hhZpMIuSC4q","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class Block(nn.Module):\n    \"\"\"Causal transformer block\"\"\"\n\n    def __init__(self, dim, num_heads):\n        super().__init__()\n        self.ln_1 = nn.LayerNorm(dim)\n        self.ln_2 = nn.LayerNorm(dim)\n        self.attn = nn.MultiheadAttention(dim, num_heads)\n        self.mlp = nn.Sequential(\n            nn.Linear(dim, dim * 4),\n            nn.GELU(),\n            nn.Linear(dim * 4, dim),\n        )\n\n    def forward(self, x):\n        attn_mask = torch.full(\n            (len(x), len(x)), -float(\"Inf\"), device=x.device, dtype=x.dtype\n        )\n        attn_mask = torch.triu(attn_mask, diagonal=1)\n        attn_mask[torch.isnan(attn_mask)] = 0.0  # Fixes all 'nan' on 'mps' device\n\n        x = self.ln_1(x)\n        a, _ = self.attn(x, x, x, attn_mask=attn_mask, need_weights=False)\n        x = x + a\n        m = self.mlp(self.ln_2(x))\n        x = x + m\n        return x\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class Decoder(nn.Module):\n    \"\"\"Causal Transformer decoder\"\"\"\n\n    def __init__(self, dim=128, num_layers=2, num_heads=4, num_tokens=97, seq_len=5):\n        super().__init__()\n        self.token_embeddings = nn.Embedding(num_tokens, dim)\n        self.position_embeddings = nn.Embedding(seq_len, dim)\n        self.layers = nn.ModuleList()\n        for _ in range(num_layers):\n            self.layers.append(Block(dim, num_heads))\n\n        self.ln_f = nn.LayerNorm(dim)\n        self.head = nn.Linear(dim, num_tokens, bias=False)\n\n    def forward(self, x):\n        # Ensure input tensor x contains valid token IDs\n        x = torch.clamp(x, 0, self.token_embeddings.num_embeddings - 1)\n\n        h = self.token_embeddings(x)\n        positions = torch.arange(x.shape[0], device=x.device).unsqueeze(-1)\n        positions = torch.clamp(positions, 0, self.position_embeddings.num_embeddings - 1)\n\n        h = h + self.position_embeddings(positions).expand_as(h)\n        for layer in self.layers:\n            h = layer(h)\n\n        h = self.ln_f(h)\n        logits = self.head(h)\n        return logits\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def multiplication_mod_p_data(p, eq_token, op_token):\n    \"\"\"x◦y = x/y (mod p) for 0 ≤ x < p, 0 < y < p\"\"\"\n    x = torch.arange(p)\n    y = torch.arange(1, p)\n    x, y = torch.cartesian_prod(x, y).T\n\n    eq = torch.ones_like(x) * eq_token\n    op = torch.ones_like(x) * op_token\n    result = x * y % p\n\n    return torch.stack([x, op, y, eq, result])","metadata":{"executionInfo":{"elapsed":11,"status":"ok","timestamp":1737367466051,"user":{"displayName":"Nikolas Xiros","userId":"00495869844002127525"},"user_tz":-120},"id":"RIifrNowR89e","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# def cycle(iterable):\n#     while True:\n#         for x in iterable:\n#             yield x\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# # Not used anymore\n# def custom_collate_fn_2(batch):\n#     \"\"\"Custom collate function to handle extra fields in the dataset.\"\"\"\n#     images, labels, _, _ = zip(*batch)  # Ignore the indices and extra_fields for loss computation\n#     images = torch.stack(images)  # Stack images into a single tensor\n#     labels = torch.tensor(labels)  # Convert labels to a tensor\n#     return images, labels\n","metadata":{"executionInfo":{"elapsed":212,"status":"ok","timestamp":1737367551771,"user":{"displayName":"Nikolas Xiros","userId":"00495869844002127525"},"user_tz":-120},"id":"zlciE-2nKkLg","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def custom_collate_fn(batch):\n    samples, labels, indices, extra_fields = zip(*batch)\n    samples = torch.stack(samples)  # Stack samples into a single tensor\n    labels = torch.tensor(labels)  # Convert labels to a tensor\n\n    return samples, labels, indices, extra_fields\n","metadata":{"executionInfo":{"elapsed":215,"status":"ok","timestamp":1737367559166,"user":{"displayName":"Nikolas Xiros","userId":"00495869844002127525"},"user_tz":-120},"id":"zif6Q-IEjFJ7","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Needed for per sample gradient computations\ndef select_random_subset(tensor, percentage, seed=42):\n    \"\"\"\n    Flatten the parameter dimensions for each batch sample, select a percentage of elements,\n    and return a tensor with shape [batch_size, selected_elements].\n\n    Args:\n        tensor (torch.Tensor): The gradient tensor of shape [batch_size, *parameter_dims].\n        percentage (float): The percentage of elements to select.\n        seed (int): Random seed for reproducibility.\n\n    Returns:\n        torch.Tensor: A tensor of shape [batch_size, selected_elements].\n    \"\"\"\n    batch_size, *param_dims = tensor.shape  # Extract batch and parameter dimensions\n    total_params = torch.prod(torch.tensor(param_dims))  # Total parameters per sample\n    subset_size = int(total_params * percentage)  # 20% of parameters\n\n    # Set seed for reproducibility\n    random.seed(seed)\n    indices = random.sample(range(total_params), subset_size)  # Random indices for selection\n\n    # Flatten parameter dimensions and select elements for each batch\n    flat_tensor = tensor.view(batch_size, -1)  # Flatten parameter dimensions for each sample\n    selected_subset = flat_tensor[:, indices]  # Select the same random indices across the batch\n\n    return selected_subset\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Needed for online sample filtering\ndef rank_to_sampling_weights(my_dataset, top_k, top_k_sampling_prob, high_freq_better):\n    \"\"\"\n    Rank samples by variance_metric and assign sampling weights.\n\n    Parameters:\n    - my_dataset: MyMNIST object.\n    - top_k: Fraction of top samples to assign higher sampling probability.\n    - top_k_sampling_prob: Probability assigned to the top_k fraction of samples.\n\n    Returns:\n    - new_weights: List of sampling weights for each sample.\n    \"\"\"\n    # Calculate the number of top_k samples\n    num_samples = len(my_dataset)\n    top_k_count = int(top_k * num_samples)\n\n    # Sort indices by variance_metric in descending order\n    sorted_indices = sorted(\n        range(num_samples),\n        key=lambda idx: my_dataset.dataset.extra_fields[idx][\"variance_metric\"],\n        reverse=high_freq_better,\n    )\n\n    # Initialize new_weights with zeros\n    new_weights = [0.0] * num_samples\n\n    # Assign weights to the top_k samples\n    for idx in sorted_indices[:top_k_count]:\n        new_weights[idx] = top_k_sampling_prob / top_k_count\n\n    # Assign weights to the rest of the samples\n    for idx in sorted_indices[top_k_count:]:\n        new_weights[idx] = (1 - top_k_sampling_prob) / (num_samples - top_k_count)\n\n    return new_weights\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class AlgoDataset(torch.utils.data.Dataset):\n    def __init__(self, data, targets):\n        \"\"\"\n        Custom dataset to store dataset + extra fields for each sample.\n        Insert data as a tensor of shape [num_samples, num_features] and targets as a tensor of shape [num_samples].\n        \"\"\"\n\n        self.data = data\n        self.targets = targets\n\n        # Initialize extra fields\n        self.extra_fields = [\n            {\n                \"ema_grad\": 0.0,\n                \"num_updates\": 0,\n                \"variance_metric\": 0.0,\n            }\n            for _ in range(len(self.data))\n        ]\n\n    def __getitem__(self, index):\n        \"\"\"Returns a single data sample with extra fields.\"\"\"\n\n        sample, target = self.data[index], self.targets[index]\n\n        extra_field = self.extra_fields[index]\n        return sample, target, int(index), extra_field\n\n    def __len__(self):\n        return len(self.data)\n\n    def update_fields(self, indices, grad_stats, ema_alpha=0.9):\n        \"\"\"\n        Update the extra fields for specified dataset indices.\n        \"\"\"\n\n        for idx, grad in zip(indices, grad_stats):\n            # Update EMA\n            sample_field = self.extra_fields[idx]\n\n            current_ema = sample_field[\"ema_grad\"]\n            updated_ema = ema_alpha * current_ema + (1 - ema_alpha) * grad\n            sample_field[\"ema_grad\"] = updated_ema\n\n            deviation = abs(grad - current_ema)\n\n            num_updates = sample_field[\"num_updates\"] + 1  # Increment the update count\n\n            current_avg_deviation = sample_field[\"variance_metric\"] ** 0.5\n            new_avg_deviation = ((current_avg_deviation * (num_updates - 1)) + deviation) / num_updates\n\n            sample_field[\"num_updates\"] = num_updates\n\n            # Variance estimate (for higher sensitivity to fast changes)\n            sample_field[\"variance_metric\"] = new_avg_deviation**2\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## def main","metadata":{}},{"cell_type":"code","source":"def main(args):\n    torch.manual_seed(args.seed)\n\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n    eq_token = args.p\n    op_token = args.p + 1\n\n    # Create model\n    model = Decoder(\n        dim=128, num_layers=2, num_heads=4, num_tokens=args.p + 2, seq_len=5\n    ).to(device)\n    print(model)\n    nparams = sum([p.numel() for p in model.parameters() if p.requires_grad])\n    print(f'Total number of parameters: {nparams}')\n\n    # Create dataset\n    data = multiplication_mod_p_data(args.p, eq_token, op_token)\n    \n    # Print dataset distribution (Check for class imbalance)\n    print(f\"Training targets distribution: {torch.bincount(data[4])}\")\n    \n    # Split the dataset into training and validation sets\n    train_idx, valid_idx = torch.randperm(data.shape[1]).split(data.shape[1] // 2)\n    train_data, valid_data = data[:, train_idx], data[:, valid_idx]\n    \n    # Create initial weights for uniform sampling\n    weights = [1.0] * len(train_data)\n    sampler = WeightedRandomSampler(weights, len(weights))\n\n    # DataLoader\n    train_dataset = AlgoDataset(train_data[:4].T, train_data[4])\n    valid_dataset = AlgoDataset(valid_data[:4].T, valid_data[4])\n\n    train_dataloader = DataLoader(train_dataset, batch_size=args.batch_size, sampler=sampler, collate_fn=custom_collate_fn)\n    valid_dataloader = DataLoader(valid_dataset, batch_size=args.batch_size, collate_fn=custom_collate_fn)\n    # data_iter = cycle(train_loader)\n\n    # Optimizer\n    optimizer = getattr(torch.optim, args.optimizer)(\n        model.parameters(),\n        lr=args.lr,\n        weight_decay=args.weight_decay,\n        betas=(args.beta1, args.beta2),\n    )\n\n    # Scheduler\n    scheduler = torch.optim.lr_scheduler.LambdaLR(\n        optimizer, lambda update: 1 if update > 10 else update / 10\n    )\n\n    steps_per_epoch = math.ceil(data.shape[1] / args.batch_size)\n\n    # ----------------------------------------------------------------------------------\n    # Needed for per sample gradient computations\n    if args.appl_sampl_filter:\n        # Define a function for forward + loss computation\n        def compute_loss_vmap(params, buffers, model, x, y):\n            logits = functional_call(model, {**params, **buffers}, x.unsqueeze(0))\n            loss = loss_fn(logits[-1], y.unsqueeze(0))  # Single output\n            return loss.mean()\n\n        # Prepare model parameters and buffers\n        params_and_buffers = {**dict(model.named_parameters()), **dict(model.named_buffers())}\n\n        params = {k: v for k, v in params_and_buffers.items() if v.requires_grad}\n        buffers = {k: v for k, v in params_and_buffers.items() if not v.requires_grad}\n\n        # Create the gradient function\n        gradient_fn = grad(compute_loss_vmap)\n    # ----------------------------------------------------------------------------------\n\n    # Start Training below\n    its, train_acc, val_acc, train_loss, val_loss = [], [], [], [], []\n    grads = None\n    i = 0\n\n    # For logging network weights.\n    net_its, nets = [], []\n\n    optim_steps = int(args.budget) // steps_per_epoch\n    log_tqdm_freq = math.ceil(optim_steps / 150)\n\n    with tqdm(total=(optim_steps), dynamic_ncols=True) as pbar:\n\n        stable_steps = 0\n        stable_threshold = 1000\n        reached_early_stop = False\n        steps_to_reach_val_acc = None\n\n        for e in range(optim_steps):\n            if reached_early_stop: break\n\n            for dataloader, is_train in [(train_dataloader, True), (valid_dataloader, False)]:\n\n                # Update sampling distribution periodically\n                if args.appl_sampl_filter and i > args.start and i % args.sampling_distr_upd_freq == 0:\n                    new_weights = rank_to_sampling_weights(train_dataset, args.top_k, args.top_k_sampling_prob, args.high_freq_better)\n                    new_sampler = WeightedRandomSampler(new_weights, num_samples=len(train_data), replacement=True)\n                    train_dataloader = DataLoader(\n                        train_data,\n                        batch_size=args.batch_size,\n                        sampler=new_sampler,\n                        collate_fn=custom_collate_fn\n                    )\n\n                model.train(is_train)\n                total_loss = 0\n                total_acc = 0\n\n                for samples, targets, indices, _, in dataloader:\n                    samples, targets = samples.to(device), targets.to(device)\n                                        \n                    with torch.set_grad_enabled(is_train):\n                        logits = model(samples.T)\n                        \n                        # calculate loss only on the answer part of the equation (last element\n                        loss = F.cross_entropy(logits[-1], targets)\n                        total_loss += loss.item()\n                        # total_loss += loss.item() * samples.shape[0]\n                        print(f\"Loss: {loss.item()}\")\n\n                        if is_train:\n                            optimizer.zero_grad()\n                            loss.backward()\n\n\n                        # Identify the last two layers dynamically \n                        if args.appl_sampl_filter:\n                            # Prepare model parameters and buffers\n                            params_and_buffers = {**dict(model.named_parameters()), **dict(model.named_buffers())}\n                        \n                            # Extract the last two layers' weights\n                            last_layer_name = None\n                            second_last_layer_name = None\n                            for name, _ in model.named_parameters():\n                                if \"layers\" in name and \"attn.out_proj.weight\" in name:\n                                    last_layer_name = name\n                                elif \"layers\" in name and \"mlp.2.weight\" in name:\n                                    second_last_layer_name = name\n                        \n                            # Ensure the layers are found\n                            if last_layer_name is None or second_last_layer_name is None:\n                                raise ValueError(\"Could not identify the last two layers in the Transformer.\")\n                        \n                            # Create the gradient function\n                            gradient_fn = grad(compute_loss_vmap)\n                        \n                            # Compute per-sample gradients\n                            with torch.no_grad():\n                                per_sample_grads = vmap(gradient_fn, in_dims=(None, None, None, 0, 0))(\n                                    params_and_buffers, {}, model, samples, targets\n                                )\n                        \n                                # Extract gradients for the target layers\n                                last_layer_grad = per_sample_grads[last_layer_name]\n                                second_last_layer_grad = per_sample_grads[second_last_layer_name]\n                        \n                                # Select a subset of gradients (optional)\n                                percentage_s_l = 0.2\n                                percentage_l = 1\n                                selected_last = select_random_subset(last_layer_grad, percentage_l, seed=42)\n                                selected_second_last = select_random_subset(second_last_layer_grad, percentage_s_l, seed=42)\n                        \n                                # Compute the average and detach\n                                selected_last_avg = selected_last.mean(dim=-1).detach().cpu()\n                                selected_second_last_avg = selected_second_last.mean(dim=-1).detach().cpu()\n                                total_avg = (selected_last_avg + selected_second_last_avg) / 2\n                        \n                            # Update sampling weights\n                            train_dataset.update_fields(indices, total_avg, args.ema_alpha_sampl_rank)\n                        # # -----------------------------------------------------------------\n                        # # -----------------------------------------------------------------\n\n\n                        #######\n                        # Grokfast\n\n                        trigger = i < 500 if args.two_stage else False\n\n                        if args.filter == \"none\":\n                            pass\n                        elif args.filter == \"ma\":\n                            grads = gradfilter_ma(model, grads=grads, window_size=args.window_size, lamb=args.lamb, trigger=trigger)\n                        elif args.filter == \"ema\":\n                            grads = gradfilter_ema(model, grads=grads, alpha=args.alpha, lamb=args.lamb)\n                        else:\n                            raise ValueError(f\"Invalid gradient filter type `{args.filter}`\")\n\n                        #######\n\n                        optimizer.step()\n                        scheduler.step()\n                        i += 1\n                        \n                        # Compute accuracy\n                        predictions = logits[-1].argmax(-1)\n\n                        acc = (predictions == targets).float().mean()\n                        total_acc += acc.item()\n                        # total_acc += acc.item() * samples.shape[0]\n\n                        # Debug: Check unique predictions\n                        unique_preds = predictions.unique()\n\n                    if is_train:\n                        train_acc.append(total_acc / len(train_dataloader))\n                        train_loss.append(total_loss / len(train_dataloader))\n                        its.append(i)\n                    else:\n                        val_acc.append(total_acc / len(valid_dataloader))\n                        val_loss.append(total_loss / len(valid_dataloader))\n\n                    do_log_tqdm = (i < 150 and i % 10 == 0) or i % log_tqdm_freq == 0\n                    if do_log_tqdm and (not is_train):\n                        pbar.set_description(\n                        \"Loss: {0:1.1e}|{1:1.1e}. Acc: {2:2.1f}%|{3:2.1f}%\".format(\n                            train_loss[-1],\n                            val_loss[-1],\n                            train_acc[-1] * 100,\n                            val_acc[-1] * 100,))\n\n\n                    # Early Stopping Logic\n                    val_acc_last = val_acc[-1] if len(val_acc) > 0 else 0\n                    if val_acc_last >= 0.92 and steps_to_reach_val_acc is None:\n                        steps_to_reach_val_acc = i\n\n                    # Check for stable performance\n                    if val_acc_last > 0.9:\n                        stable_steps += 1\n                    else:\n                        stable_steps = 0  # Reset counter if accuracy drops below 0.85\n\n                    if stable_steps >= stable_threshold and val_acc_last >= 0.9 and steps_to_reach_val_acc is not None:\n                        reached_early_stop = True\n                        print(f\"Validation accuracy of 0.92 reached and remained > 0.9 for {stable_threshold} steps at step {i}\")\n\n            pbar.update(1)\n\n    # Save results\n    specific_result_dir = f\"algo_{args.label}.pt\"\n    results_filename = os.path.join(results_dir, specific_result_dir)\n    torch.save(\n        {\n            \"its\": its,\n            \"train_acc\": train_acc,\n            \"train_loss\": train_loss,\n            \"val_acc\": val_acc,\n            \"val_loss\": val_loss,\n            \"steps_to_reach\": steps_to_reach_val_acc,\n            \"model_state_dict\": model.state_dict(),\n        },\n        results_filename,\n    )\n    print(f\"Saving to {results_filename}\")\n    print(f\"\\nTraining complete!\")\n    print(f\"Steps to reach 0.92 validation accuracy: {steps_to_reach_val_acc}\")\n","metadata":{"executionInfo":{"elapsed":221,"status":"ok","timestamp":1737370352760,"user":{"displayName":"Nikolas Xiros","userId":"00495869844002127525"},"user_tz":-120},"id":"LWPwaBWpSF52","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import sys\n# Remove the extra arguments passed by the Jupyter Notebook kernel\nsys.argv = [\"\"]\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport torch\nimport numpy as np\nimport matplotlib.pyplot as plt\n\ndef analyze_results(label, results_dir=\"/kaggle/working/results/algo_online\"):\n    \"\"\"\n    Loads model results, extracts accuracy/loss data, and generates plots.\n\n    Args:\n        label (str): Label identifier for the results file.\n        results_dir (str): Directory where results are stored.\n\n    Returns:\n        None\n    \"\"\"\n\n    # Define file paths\n    filename = f\"algo_{label}.pt\"  # Adjusted filename format\n    results_filename = os.path.join(results_dir, filename)\n\n    filename_plot_acc = f\"algo_{label}_acc.png\"\n    results_filename_plot_acc = os.path.join(results_dir, filename_plot_acc)\n\n    filename_plot_loss = f\"algo_{label}_loss.png\"\n    results_filename_plot_loss = os.path.join(results_dir, filename_plot_loss)\n\n    try:\n        # Load results\n        results = torch.load(results_filename)  # Removed invalid weights_only=True\n\n        # Extract data\n        its = results[\"its\"]  # Optimization steps\n        train_acc = results[\"train_acc\"]  # Training accuracy\n        val_acc = results[\"val_acc\"]  # Validation accuracy\n        train_loss = results[\"train_loss\"]  # Training loss\n        val_loss = results[\"val_loss\"]  # Validation loss\n        steps_to_reach = results.get(\"steps_to_reach\", None)  # Handle missing key\n\n        if steps_to_reach:\n            print(f\"Steps needed to reach 0.9 validation accuracy: {steps_to_reach}\")\n\n        # Plot Accuracy\n        plt.figure()\n        plt.plot(its, train_acc, label=\"Train Accuracy\", color=\"blue\")\n        plt.plot(its, val_acc, label=\"Validation Accuracy\", color=\"red\")\n\n        # Find and annotate the maximum validation accuracy\n        max_val_acc = max(val_acc)\n        max_val_idx = val_acc.index(max_val_acc)\n        plt.annotate(f\"Max Val Acc: {max_val_acc:.4f}\",\n                     (its[max_val_idx], max_val_acc),\n                     textcoords=\"offset points\",\n                     xytext=(0, 10),\n                     ha='center',\n                     fontsize=10,\n                     color='red')\n\n        plt.legend()\n        plt.title(f\"Accuracy - {label}\")\n        plt.xlabel(\"Optimization Steps\")\n        plt.ylabel(\"Accuracy\")\n        plt.xscale(\"log\")\n        plt.grid()\n        if steps_to_reach:\n            plt.figtext(0.5, -0.1, f\"Steps to reach val=0.9 = {steps_to_reach}\",\n                        ha=\"center\", fontsize=10, style=\"italic\")\n\n        plt.savefig(results_filename_plot_acc, dpi=150)\n        plt.show()\n        plt.close()\n\n        print(f\"Plots saved successfully at {results_filename_plot_acc}\")\n\n    except FileNotFoundError:\n        print(f\"Error: Results file {results_filename} not found.\")\n    except Exception as e:\n        print(f\"Error while processing {label}: {e}\")\n\ndef plot_all_experiments_together(labels, results_dir=\"/kaggle/working/results/algo_online\", show_only_val=False):\n    \"\"\"\n    Plots train and validation accuracy for multiple experiments in a single graph.\n    Allows showing only validation accuracy if `show_only_val=True`.\n\n    Args:\n        labels (list of str): List of labels corresponding to result files.\n        results_dir (str): Directory where results are stored.\n        show_only_val (bool): If True, only plots validation accuracy.\n\n    Returns:\n        None\n    \"\"\"\n    plt.figure(figsize=(10, 6))  # Set figure size\n\n    # Generate distinct colors for each experiment\n    base_colors = plt.cm.viridis(np.linspace(0, 1, len(labels)))\n\n    for i, label in enumerate(labels):\n        results_filename = os.path.join(results_dir, f\"algo_{label}.pt\")\n\n        try:\n            # Load results\n            results = torch.load(results_filename)\n            its = results[\"its\"]\n            train_acc = results[\"train_acc\"]\n            val_acc = results[\"val_acc\"]\n            steps_to_reach = results.get(\"steps_to_reach\", None)  # Handle missing key\n\n            # Assign colors for train and validation curves\n            val_color = base_colors[i]  # Primary color for validation\n            train_color = tuple(c * 0.7 for c in base_colors[i])  # Slightly darker shade for train\n\n            # Plot validation accuracy (always shown)\n            plt.plot(its, val_acc, label=f\"Validation ({label})\", color=val_color, linestyle=\"solid\")\n\n            if steps_to_reach:\n                plt.figtext(0.5, -0.1, f\"Steps to reach val=0.9 = {steps_to_reach}\",\n                            ha=\"center\", fontsize=10, style=\"italic\")\n\n            # Plot train accuracy if `show_only_val` is False\n            if not show_only_val:\n                plt.plot(its, train_acc, label=f\"Train ({label})\", color=train_color, linestyle=\"dashed\")\n\n        except FileNotFoundError:\n            print(f\"Warning: Results file {results_filename} not found.\")\n        except Exception as e:\n            print(f\"Error while processing {label}: {e}\")\n\n    plt.legend()\n    plt.title(\"Train & Validation Accuracy for Multiple Experiments\" if not show_only_val else \"Validation Accuracy for Multiple Experiments\")\n    plt.xlabel(\"Optimization Steps\")\n    plt.ylabel(\"Accuracy\")\n    plt.xscale(\"log\")\n    plt.grid()\n\n    # Save and show the plot\n    filename = \"combined_train_val_plot.png\" if not show_only_val else \"combined_val_plot.png\"\n    plot_path = os.path.join(results_dir, filename)\n    plt.savefig(plot_path, dpi=150)\n    plt.show()\n\n    print(f\"Combined plot saved at {plot_path}\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Execute training (by running main function)","metadata":{}},{"cell_type":"markdown","source":"From now on i just train networks with different configurations every timeand then I print their results after.","metadata":{}},{"cell_type":"markdown","source":"### Simple training:\n\n    * no grokfast applied\n    * no filtering\n    * wd = 0\n\n\n\n            ","metadata":{}},{"cell_type":"code","source":"if __name__ == \"__main__\":\n    # Same as used in paper of Grokfast\n    parser = ArgumentParser(description=\"Train a model on Algorithmic Dataset without custom sampling\")\n\n    parser.add_argument(\"--label\", type=str, default=\"\")\n    parser.add_argument(\"--seed\", type=int, default=0)\n    parser.add_argument(\"--p\", type=int, default=97)\n    parser.add_argument(\"--budget\", type=int, default=3e5)\n    parser.add_argument(\"--batch_size\", type=int, default=512)\n    parser.add_argument(\"--optimizer\", type=str, default=\"Adam\")\n    parser.add_argument(\"--beta1\", type=float, default=0.9)\n    parser.add_argument(\"--beta2\", type=float, default=0.98)\n    parser.add_argument(\"--weight_decay\", type=float, default=0)\n    parser.add_argument(\"--lr\", type=float, default=1e-3)\n\n\n    # Grokfast\n    parser.add_argument(\"--filter\", type=str, choices=[\"none\", \"ma\", \"ema\", \"fir\"], default=\"none\")\n    parser.add_argument(\"--alpha\", type=float, default=0.99)\n    parser.add_argument(\"--window_size\", type=int, default=100)\n    parser.add_argument(\"--lamb\", type=float, default=5.0)\n\n    # Ablation studies\n    parser.add_argument(\"--two_stage\", action='store_true')\n    parser.add_argument(\"--save_weights\", action='store_true')\n\n    # Samples ranking\n    parser.add_argument(\"--ema_alpha_sampl_rank\", type=float, default=0.9)\n\n    # Boolean arguements need this due to bad behavior of parser.parse_args\n    def boolean_string(s):\n        if s not in {\"False\", \"True\"}:\n            raise ValueError(\"Not a valid boolean string\")\n        return s == \"True\"\n\n    # These are the hyperparameters related to our online sampling filtering algorithm\n    parser.add_argument(\"--appl_sampl_filter\", type=boolean_string, default=True)  # If False, perform regular training\n    parser.add_argument(\"--start\", type=int, default=1000) # When to start the sample filtering\n    parser.add_argument(\"--sampling_distr_upd_freq\", type=int, default=1)  # How often to update the sampling distribution\n    parser.add_argument(\"--top_k\", type=float, default=0.1)  # Fraction of samples to select more frequently\n    parser.add_argument(\"--top_k_sampling_prob\", type=float, default=0.7)  # Probability of selecting a sample from the top-k\n    parser.add_argument(\"--high_freq_better\", type=boolean_string, default=True)  # If True, samples with higher frequency gradient content are considered better for training\n\n\n    # -----------------------------------------------------------------\n    # Try different hyperparameter values for your grid search here\n    # -----------------------------------------------------------------\n    args = parser.parse_args(\n        [\n            \"--appl_sampl_filter\", \"False\",\n            \"--sampling_distr_upd_freq\", \"1\",\n            \"--top_k\", \"0.1\",\n            \"--top_k_sampling_prob\", \"0.7\",\n            \"--high_freq_better\", \"True\",\n            \"--filter\", \"none\",\n        ]\n    )\n    # -----------------------------------------------------------------\n    # -----------------------------------------------------------------\n\n    # Create arg.label for the filename of the saved results\n    if not args.appl_sampl_filter:\n        args.label = f\"filter{args.filter}_sampling_{args.appl_sampl_filter}\"\n    else:\n        args.label = f\"high_freq_{args.high_freq_better}_top_k_{args.top_k}_top_k_prob_{args.top_k_sampling_prob}_upd_freq_{args.sampling_distr_upd_freq}\"\n\n    # Training with time recording\n\n    # Start the timer\n    start_time = time.time()\n\n    # Call your training function\n    main(args)\n\n    # End the timer\n    end_time = time.time()\n\n    # Calculate elapsed time\n    elapsed_time = end_time - start_time\n\n    # Convert to minutes and seconds (optional)\n    minutes, seconds = divmod(elapsed_time, 60)\n\n    print(f\"Training completed in {int(minutes)} minutes and {int(seconds)} seconds.\")\n    print(f\"label:{args.label}\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# results_filename = \"/kaggle/working/results/algo_online/algo_filternone_sampling_False.pt\" # Not needed because analyze_results has it inside","metadata":{"trusted":true,"execution":{"execution_failed":"2025-02-12T16:48:36.465Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"results = torch.load(\"/kaggle/working/results/algo_online/algo_filternone_sampling_False.pt\")\n\nprint(\"Iterations shape:\", torch.tensor(results[\"its\"]).shape)\nprint(\"Train Acc shape:\", torch.tensor(results[\"train_acc\"]).shape)\nprint(\"Val Acc shape:\", torch.tensor(results[\"val_acc\"]).shape)\nprint(\"Train Loss shape:\", torch.tensor(results[\"train_loss\"]).shape)\nprint(\"Val Loss shape:\", torch.tensor(results[\"val_loss\"]).shape)\n","metadata":{"trusted":true,"execution":{"execution_failed":"2025-02-12T16:48:36.465Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# args.label = \"filternone_sampling_False\" # Not needed because we already have args.label from above\nanalyze_results(args.label)\n","metadata":{"trusted":true,"execution":{"execution_failed":"2025-02-12T16:48:36.465Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Only Grokfast\n    * grokfast applied\n    * no filtering\n    * wd = 0","metadata":{}},{"cell_type":"code","source":"if __name__ == \"__main__\":\n    # Same as used in paper of Grokfast\n    parser = ArgumentParser(description=\"Train a model on MNIST without custom sampling\")\n\n    parser.add_argument(\"--label\", type=str, default=\"\")\n    parser.add_argument(\"--seed\", type=int, default=0)\n    parser.add_argument(\"--p\", type=int, default=97)\n    parser.add_argument(\"--budget\", type=int, default=3e5)\n    parser.add_argument(\"--batch_size\", type=int, default=512)\n    parser.add_argument(\"--optimizer\", type=str, default=\"Adam\")\n    parser.add_argument(\"--beta1\", type=float, default=0.9)\n    parser.add_argument(\"--beta2\", type=float, default=0.98)\n    parser.add_argument(\"--weight_decay\", type=float, default=0)\n    parser.add_argument(\"--lr\", type=float, default=1e-3)\n\n    # Grokfast\n    parser.add_argument(\"--filter\", type=str, choices=[\"none\", \"ma\", \"ema\", \"fir\"], default=\"ema\")\n    parser.add_argument(\"--alpha\", type=float, default=0.8)\n    parser.add_argument(\"--lamb\", type=float, default=0.1)\n\n    # Samples ranking\n    parser.add_argument(\"--ema_alpha_sampl_rank\", type=float, default=0.9)\n\n    # Boolean arguements need this due to bad behavior of parser.parse_args\n    def boolean_string(s):\n        if s not in {\"False\", \"True\"}:\n            raise ValueError(\"Not a valid boolean string\")\n        return s == \"True\"\n\n    # These are the hyperparameters related to our online sampling filtering algorithm\n    parser.add_argument(\"--appl_sampl_filter\", type=boolean_string, default=True)  # If False, perform regular training\n    parser.add_argument(\"--start\", type=int, default=1000) # When to start the sample filtering\n    parser.add_argument(\"--sampling_distr_upd_freq\", type=int, default=1)  # How often to update the sampling distribution\n    parser.add_argument(\"--top_k\", type=float, default=0.1)  # Fraction of samples to select more frequently\n    parser.add_argument(\"--top_k_sampling_prob\", type=float, default=0.7)  # Probability of selecting a sample from the top-k\n    parser.add_argument(\"--high_freq_better\", type=boolean_string, default=True)  # If True, samples with higher frequency gradient content are considered better for training\n\n    # -----------------------------------------------------------------\n    # Try different hyperparameter values for your grid search here\n    # -----------------------------------------------------------------\n    args = parser.parse_args(\n        [\n            \"--appl_sampl_filter\", \"False\",\n            \"--sampling_distr_upd_freq\", \"1\",\n            \"--top_k\", \"0.1\",\n            \"--top_k_sampling_prob\", \"0.7\",\n            \"--high_freq_better\", \"True\",\n        ]\n    )\n    # -----------------------------------------------------------------\n    # -----------------------------------------------------------------\n\n    # Create arg.label for the filename of the saved results\n    if not args.appl_sampl_filter:\n        args.label = f\"filter{args.filter}_sampling_{args.appl_sampl_filter}\"\n    else:\n        args.label = f\"high_freq_{args.high_freq_better}_top_k_{args.top_k}_top_k_prob_{args.top_k_sampling_prob}_upd_freq_{args.sampling_distr_upd_freq}\"\n\n    # Training with time recording\n\n    # Start the timer\n    start_time = time.time()\n\n    # Call your training function\n    main(args)\n\n    # End the timer\n    end_time = time.time()\n\n    # Calculate elapsed time\n    elapsed_time = end_time - start_time\n\n    # Convert to minutes and seconds (optional)\n    minutes, seconds = divmod(elapsed_time, 60)\n\n    print(f\"Training completed in {int(minutes)} minutes and {int(seconds)} seconds.\")\n    print(f\"label:{args.label}\")\n","metadata":{"trusted":true,"execution":{"execution_failed":"2025-02-12T16:48:36.465Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# args.label=\"filterema_sampling_False\" # Not needed because we already have args.label from above\nanalyze_results(args.label)\n","metadata":{"trusted":true,"execution":{"execution_failed":"2025-02-12T16:48:36.465Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Grid Search","metadata":{}},{"cell_type":"code","source":"# Define possible values for each parameter\nparam_grid = {\n    \"top_k\": [0.2],  # Convert to float\n    \"top_k_sampling_prob\": [0.7],  # Convert to float\n    \"sampling_distr_upd_freq\": [10],  # Convert to int\n    \"high_freq_better\": [True]  # Boolean parameter\n}\n\n# Generate all combinations of parameters\nparam_combinations = list(itertools.product(*param_grid.values()))\n\n# Run main in a loop for each combination\nfor param_values in param_combinations:\n    # Extract parameter values\n    top_k = param_values[0]\n    top_k_sampling_prob = param_values[1]\n    sampling_distr_upd_freq = param_values[2]\n    high_freq_better = param_values[3]  # Boolean value\n\n    # Ensure boolean values are correctly formatted as strings for argparse\n    high_freq_better_str = \"True\" if high_freq_better else \"False\"\n\n    # Create args dynamically\n    args_list = [\n        \"--appl_sampl_filter\" , \"True\",\n        \"--top_k\", str(top_k),\n        \"--top_k_sampling_prob\", str(top_k_sampling_prob),\n        \"--sampling_distr_upd_freq\", str(sampling_distr_upd_freq),\n        \"--high_freq_better\", high_freq_better_str,\n        \"--label\", f\"{top_k}_{top_k_sampling_prob}_{sampling_distr_upd_freq}_{high_freq_better}\"\n    ]\n\n    # Debug print statement\n    print(f\"\\nRunning with parameters: {args_list}\")\n\n    # Parse the arguments dynamically\n    args = parser.parse_args(args_list)\n\n    # Call main() with the updated args\n    main(args)\n","metadata":{"trusted":true,"execution":{"execution_failed":"2025-02-12T16:48:36.465Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#/kaggle/working/results/mnist_online/mnist_high_freq_True_top_k_0.2_top_k_prob_0.9_upd_freq_1.pt\n# args.label=\"high_freq_True_top_k_0.2_top_k_prob_0.9_upd_freq_1\" # Not needed because we already have args.label from above\nanalyze_results(args.label)\n","metadata":{"trusted":true,"execution":{"execution_failed":"2025-02-12T16:48:36.465Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Grid search for high_freq_better=False\nno sure if the code is ok","metadata":{}},{"cell_type":"code","source":"args_list = [\n    \"--appl_sampl_filter\" , \"False\",\n]\n\n# Parse the arguments dynamically\nargs = parser.parse_args(args_list)\n\n# Call main() with the updated args\nmain(args)\n","metadata":{"trusted":true,"execution":{"execution_failed":"2025-02-12T16:48:36.465Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"analyze_results(args.label)\n","metadata":{"trusted":true,"execution":{"execution_failed":"2025-02-12T16:48:36.465Z"}},"outputs":[],"execution_count":null}]}