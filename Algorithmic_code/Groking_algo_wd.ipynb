{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RLNMqt_y8y0J"
      },
      "outputs": [],
      "source": [
        "#Starting code for PatRec project\n",
        "#   Omada 2 -- Grokfast experiments"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f4s6HWPGPSBJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f099731b-fb77-431c-de12-da10af0b7f36"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gADYjdBHN1cg"
      },
      "outputs": [],
      "source": [
        "# from google.colab import files\n",
        "# files.upload()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pUw0ejsKP3sp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b7c20f72-7e66-4e90-a2ef-1ff00eea7633"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Algorithmic_code  MNIST_code\t  __pycache__  requirements.txt  results2_test_random_seed_12\n",
            "grokfast.py\t  _Presentations  QM9_code     results\n"
          ]
        }
      ],
      "source": [
        "!ls /content/drive/MyDrive/PatRec_Project_Shared_Folder/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qdXeIGW_QC3w"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "sys.path.append('/content/drive/MyDrive/PatRec_Project_Shared_Folder')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C13vv8V-KHUI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b660ab52-759c-4896-fc2c-4f41e0b9f989"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from -r /content/drive/MyDrive/PatRec_Project_Shared_Folder/requirements.txt (line 1)) (3.10.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from -r /content/drive/MyDrive/PatRec_Project_Shared_Folder/requirements.txt (line 2)) (2.5.1+cu124)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (from -r /content/drive/MyDrive/PatRec_Project_Shared_Folder/requirements.txt (line 3)) (0.20.1+cu124)\n",
            "Collecting torch_geometric (from -r /content/drive/MyDrive/PatRec_Project_Shared_Folder/requirements.txt (line 4))\n",
            "  Downloading torch_geometric-2.6.1-py3-none-any.whl.metadata (63 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/63.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.1/63.1 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from -r /content/drive/MyDrive/PatRec_Project_Shared_Folder/requirements.txt (line 5)) (2.2.2)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.11/dist-packages (from -r /content/drive/MyDrive/PatRec_Project_Shared_Folder/requirements.txt (line 6)) (0.13.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from -r /content/drive/MyDrive/PatRec_Project_Shared_Folder/requirements.txt (line 7)) (4.67.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from -r /content/drive/MyDrive/PatRec_Project_Shared_Folder/requirements.txt (line 8)) (1.13.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from -r /content/drive/MyDrive/PatRec_Project_Shared_Folder/requirements.txt (line 9)) (1.6.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->-r /content/drive/MyDrive/PatRec_Project_Shared_Folder/requirements.txt (line 1)) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->-r /content/drive/MyDrive/PatRec_Project_Shared_Folder/requirements.txt (line 1)) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->-r /content/drive/MyDrive/PatRec_Project_Shared_Folder/requirements.txt (line 1)) (4.55.8)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->-r /content/drive/MyDrive/PatRec_Project_Shared_Folder/requirements.txt (line 1)) (1.4.8)\n",
            "Requirement already satisfied: numpy>=1.23 in /usr/local/lib/python3.11/dist-packages (from matplotlib->-r /content/drive/MyDrive/PatRec_Project_Shared_Folder/requirements.txt (line 1)) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->-r /content/drive/MyDrive/PatRec_Project_Shared_Folder/requirements.txt (line 1)) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib->-r /content/drive/MyDrive/PatRec_Project_Shared_Folder/requirements.txt (line 1)) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->-r /content/drive/MyDrive/PatRec_Project_Shared_Folder/requirements.txt (line 1)) (3.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->-r /content/drive/MyDrive/PatRec_Project_Shared_Folder/requirements.txt (line 1)) (2.8.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->-r /content/drive/MyDrive/PatRec_Project_Shared_Folder/requirements.txt (line 2)) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch->-r /content/drive/MyDrive/PatRec_Project_Shared_Folder/requirements.txt (line 2)) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->-r /content/drive/MyDrive/PatRec_Project_Shared_Folder/requirements.txt (line 2)) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->-r /content/drive/MyDrive/PatRec_Project_Shared_Folder/requirements.txt (line 2)) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->-r /content/drive/MyDrive/PatRec_Project_Shared_Folder/requirements.txt (line 2)) (2024.10.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch->-r /content/drive/MyDrive/PatRec_Project_Shared_Folder/requirements.txt (line 2))\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch->-r /content/drive/MyDrive/PatRec_Project_Shared_Folder/requirements.txt (line 2))\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch->-r /content/drive/MyDrive/PatRec_Project_Shared_Folder/requirements.txt (line 2))\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch->-r /content/drive/MyDrive/PatRec_Project_Shared_Folder/requirements.txt (line 2))\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch->-r /content/drive/MyDrive/PatRec_Project_Shared_Folder/requirements.txt (line 2))\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch->-r /content/drive/MyDrive/PatRec_Project_Shared_Folder/requirements.txt (line 2))\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch->-r /content/drive/MyDrive/PatRec_Project_Shared_Folder/requirements.txt (line 2))\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch->-r /content/drive/MyDrive/PatRec_Project_Shared_Folder/requirements.txt (line 2))\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch->-r /content/drive/MyDrive/PatRec_Project_Shared_Folder/requirements.txt (line 2))\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->-r /content/drive/MyDrive/PatRec_Project_Shared_Folder/requirements.txt (line 2)) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->-r /content/drive/MyDrive/PatRec_Project_Shared_Folder/requirements.txt (line 2)) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch->-r /content/drive/MyDrive/PatRec_Project_Shared_Folder/requirements.txt (line 2))\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch->-r /content/drive/MyDrive/PatRec_Project_Shared_Folder/requirements.txt (line 2)) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->-r /content/drive/MyDrive/PatRec_Project_Shared_Folder/requirements.txt (line 2)) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->-r /content/drive/MyDrive/PatRec_Project_Shared_Folder/requirements.txt (line 2)) (1.3.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from torch_geometric->-r /content/drive/MyDrive/PatRec_Project_Shared_Folder/requirements.txt (line 4)) (3.11.12)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.11/dist-packages (from torch_geometric->-r /content/drive/MyDrive/PatRec_Project_Shared_Folder/requirements.txt (line 4)) (5.9.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from torch_geometric->-r /content/drive/MyDrive/PatRec_Project_Shared_Folder/requirements.txt (line 4)) (2.32.3)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->-r /content/drive/MyDrive/PatRec_Project_Shared_Folder/requirements.txt (line 5)) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->-r /content/drive/MyDrive/PatRec_Project_Shared_Folder/requirements.txt (line 5)) (2025.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->-r /content/drive/MyDrive/PatRec_Project_Shared_Folder/requirements.txt (line 9)) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->-r /content/drive/MyDrive/PatRec_Project_Shared_Folder/requirements.txt (line 9)) (3.5.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib->-r /content/drive/MyDrive/PatRec_Project_Shared_Folder/requirements.txt (line 1)) (1.17.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric->-r /content/drive/MyDrive/PatRec_Project_Shared_Folder/requirements.txt (line 4)) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric->-r /content/drive/MyDrive/PatRec_Project_Shared_Folder/requirements.txt (line 4)) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric->-r /content/drive/MyDrive/PatRec_Project_Shared_Folder/requirements.txt (line 4)) (25.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric->-r /content/drive/MyDrive/PatRec_Project_Shared_Folder/requirements.txt (line 4)) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric->-r /content/drive/MyDrive/PatRec_Project_Shared_Folder/requirements.txt (line 4)) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric->-r /content/drive/MyDrive/PatRec_Project_Shared_Folder/requirements.txt (line 4)) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric->-r /content/drive/MyDrive/PatRec_Project_Shared_Folder/requirements.txt (line 4)) (1.18.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->-r /content/drive/MyDrive/PatRec_Project_Shared_Folder/requirements.txt (line 2)) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->torch_geometric->-r /content/drive/MyDrive/PatRec_Project_Shared_Folder/requirements.txt (line 4)) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->torch_geometric->-r /content/drive/MyDrive/PatRec_Project_Shared_Folder/requirements.txt (line 4)) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->torch_geometric->-r /content/drive/MyDrive/PatRec_Project_Shared_Folder/requirements.txt (line 4)) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->torch_geometric->-r /content/drive/MyDrive/PatRec_Project_Shared_Folder/requirements.txt (line 4)) (2025.1.31)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m94.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m72.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m40.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m55.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torch_geometric-2.6.1-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m41.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, torch_geometric, nvidia-cusolver-cu12\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 torch_geometric-2.6.1\n"
          ]
        }
      ],
      "source": [
        "!pip install -r /content/drive/MyDrive/PatRec_Project_Shared_Folder/requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hrb9IxqrJeok"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "from argparse import ArgumentParser\n",
        "from itertools import permutations\n",
        "import copy\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UtT0IRac8_19"
      },
      "outputs": [],
      "source": [
        "from grokfast import gradfilter_ma, gradfilter_ema, gradfilter_with_depth_scaling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gw5pFYxWJbGL"
      },
      "outputs": [],
      "source": [
        "\n",
        "class Block(nn.Module):\n",
        "    \"\"\"Causal transformer block\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, dim, num_heads):\n",
        "        super().__init__()\n",
        "        self.ln_1 = nn.LayerNorm(dim)\n",
        "        self.ln_2 = nn.LayerNorm(dim)\n",
        "        self.attn = nn.MultiheadAttention(dim, num_heads)\n",
        "        self.mlp = nn.Sequential(\n",
        "            nn.Linear(dim, dim * 4),\n",
        "            nn.GELU(),\n",
        "            nn.Linear(dim * 4, dim),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        attn_mask = torch.full(\n",
        "            (len(x), len(x)), -float(\"Inf\"), device=x.device, dtype=x.dtype\n",
        "        )\n",
        "        attn_mask = torch.triu(attn_mask, diagonal=1)\n",
        "        attn_mask[torch.isnan(attn_mask)] = 0.0 # fixes all 'nan' on 'mps' device\n",
        "\n",
        "        x = self.ln_1(x)\n",
        "        a, _ = self.attn(x, x, x, attn_mask=attn_mask, need_weights=False)\n",
        "        x = x + a\n",
        "        m = self.mlp(self.ln_2(x))\n",
        "        x = x + m\n",
        "        return x\n",
        "\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    \"\"\"Causal Transformer decoder\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, dim=128, num_layers=2, num_heads=4, num_tokens=97, seq_len=5):\n",
        "        super().__init__()\n",
        "        self.token_embeddings = nn.Embedding(num_tokens, dim)\n",
        "        self.position_embeddings = nn.Embedding(seq_len, dim)\n",
        "        self.layers = nn.ModuleList()\n",
        "        for _ in range(num_layers):\n",
        "            self.layers.append(Block(dim, num_heads))\n",
        "\n",
        "        self.ln_f = nn.LayerNorm(dim)\n",
        "        self.head = nn.Linear(dim, num_tokens, bias=False)\n",
        "\n",
        "    def forward(self, x):\n",
        "        h = self.token_embeddings(x)\n",
        "        positions = torch.arange(x.shape[0], device=x.device).unsqueeze(-1)\n",
        "        h = h + self.position_embeddings(positions).expand_as(h)\n",
        "        for layer in self.layers:\n",
        "            h = layer(h)\n",
        "\n",
        "        h = self.ln_f(h)\n",
        "        logits = self.head(h)\n",
        "        return logits\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CjzP8njaJkJU"
      },
      "outputs": [],
      "source": [
        "def multiplication_mod_p_data(p, eq_token, op_token):\n",
        "    \"\"\"x◦y = x/y (mod p) for 0 ≤ x < p, 0 < y < p\n",
        "    \"\"\"\n",
        "    x = torch.arange(p)\n",
        "    y = torch.arange(1, p)\n",
        "    x, y = torch.cartesian_prod(x, y).T\n",
        "\n",
        "    eq = torch.ones_like(x) * eq_token\n",
        "    op = torch.ones_like(x) * op_token\n",
        "    result = x * y % p\n",
        "\n",
        "    # \"All of our experiments used a small transformer trained on datasets of\n",
        "    # equations of the form a◦b = c, where each of “a”, “◦”, “b”, “=”, and “c”\n",
        "    # is a seperate token\"\n",
        "    return torch.stack([x, op, y, eq, result])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Specify the path to save in Google Drive\n",
        "results_dir = \"/content/drive/MyDrive/PatRec_Project_Shared_Folder/results\"\n",
        "os.makedirs(results_dir, exist_ok=True)"
      ],
      "metadata": {
        "id": "fPwoxB0RIxv0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oWtMguE3JmpK"
      },
      "outputs": [],
      "source": [
        "def main(args):\n",
        "    torch.manual_seed(args.seed)\n",
        "\n",
        "\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    # tokens for <op> and <=>. It's not clear why <=> is needed at all since it\n",
        "    # has no effect on the output, but we'll leave it in to best follow the\n",
        "    # paper.\n",
        "    eq_token = args.p\n",
        "    op_token = args.p + 1\n",
        "\n",
        "    # \"We trained a standard decoder-only transformer (Vaswani et al., 2017)\n",
        "    # with causal attention masking, and calculated loss and accuracy only on\n",
        "    # the answer part of the equation. For all experiments we used a\n",
        "    # transformer with 2 layers, width 128, and 4 attention heads\"\n",
        "    model = Decoder(\n",
        "        dim=128, num_layers=2, num_heads=4, num_tokens=args.p + 2, seq_len=5\n",
        "    ).to(device)\n",
        "    nparams = sum([p.numel() for p in model.parameters() if p.requires_grad])\n",
        "    print(model)\n",
        "    print(f'Total number of parameters: {nparams}')\n",
        "\n",
        "    data = multiplication_mod_p_data(args.p, eq_token, op_token)\n",
        "\n",
        "    # Split the subset into training and validation sets\n",
        "    split_idx = data.shape[1] // 2\n",
        "    perm = torch.randperm(data.shape[1])\n",
        "    train_idx = perm[:split_idx]\n",
        "    valid_idx = perm[split_idx:]\n",
        "    train_data = data[:, train_idx]\n",
        "    valid_data = data[:, valid_idx]\n",
        "\n",
        "    # For most experiments we used AdamW optimizer with learning rate 10−3,\n",
        "    # weight decay 1, β1 = 0.9, β2 = 0.98\n",
        "    optimizer = getattr(torch.optim, args.optimizer)(\n",
        "        model.parameters(),\n",
        "        lr=args.lr,\n",
        "        weight_decay=args.weight_decay,\n",
        "        betas=(args.beta1, args.beta2),\n",
        "    )\n",
        "\n",
        "    #  linear learning rate warmup over the first 10 updates\n",
        "    scheduler = torch.optim.lr_scheduler.LambdaLR(\n",
        "        optimizer, lambda update: 1 if update > 10 else update / 10\n",
        "    )\n",
        "\n",
        "    steps_per_epoch = math.ceil(train_data.shape[1] / args.batch_size)\n",
        "\n",
        "    its, train_acc, val_acc, train_loss, val_loss = [], [], [], [], []\n",
        "    grads = None\n",
        "    i = 0\n",
        "\n",
        "    # For logging network weights.\n",
        "    net_its, nets = [], []\n",
        "\n",
        "    for e in tqdm(range(int(args.budget) // steps_per_epoch)):\n",
        "\n",
        "        # randomly shuffle train data\n",
        "        train_data = train_data[:, torch.randperm(train_data.shape[1])]\n",
        "\n",
        "        for data, is_train in [(train_data, True), (valid_data, False)]:\n",
        "\n",
        "            model.train(is_train)\n",
        "            total_loss = 0\n",
        "            total_acc = 0\n",
        "\n",
        "            # torch.split faster than dataloader with tensor\n",
        "            dl = torch.split(data, args.batch_size, dim=1)\n",
        "            for input in dl:\n",
        "                input = input.to(device)\n",
        "\n",
        "\n",
        "                with torch.set_grad_enabled(is_train):\n",
        "                    logits = model(input[:-1])\n",
        "                    # calculate loss only on the answer part of the equation (last element\n",
        "                    loss = F.cross_entropy(logits[-1], input[-1])\n",
        "                    total_loss += loss.item() * input.shape[-1]\n",
        "\n",
        "                if is_train:\n",
        "                    model.zero_grad()\n",
        "                    loss.backward()\n",
        "\n",
        "                    #######\n",
        "\n",
        "                    trigger = i < 500 if args.two_stage else False\n",
        "\n",
        "                    if args.filter == \"none\":\n",
        "                        pass\n",
        "                    elif args.filter == \"ma\":\n",
        "                        grads = gradfilter_ma(model, grads=grads, window_size=args.window_size, lamb=args.lamb, trigger=trigger)\n",
        "                    elif args.filter == \"ema\":\n",
        "                        grads = gradfilter_ema(model, grads=grads, alpha=args.alpha, lamb=args.lamb)\n",
        "                    else:\n",
        "                        raise ValueError(f\"Invalid gradient filter type `{args.filter}`\")\n",
        "\n",
        "                    #######\n",
        "\n",
        "                    optimizer.step()\n",
        "                    scheduler.step()\n",
        "                    i += 1\n",
        "\n",
        "                acc = (logits[-1].argmax(-1) == input[-1]).float().mean()\n",
        "                total_acc += acc.item() * input.shape[-1]\n",
        "\n",
        "            if is_train:\n",
        "                train_acc.append(total_acc / train_data.shape[-1])\n",
        "                train_loss.append(total_loss / train_data.shape[-1])\n",
        "                its.append(i)\n",
        "            else:\n",
        "                val_acc.append(total_acc / valid_data.shape[-1])\n",
        "                val_loss.append(total_loss / valid_data.shape[-1])\n",
        "\n",
        "        if args.save_weights:\n",
        "            do_save = e <= 500 or (e > 500 and (e + 1) % 100 == 0) or e == int(args.budget) // steps_per_epoch - 1\n",
        "        else:\n",
        "            do_save = (e + 1) % 100 == 0\n",
        "        if do_save:\n",
        "            steps = torch.arange(len(train_acc)).numpy() * steps_per_epoch\n",
        "            plt.plot(steps, train_acc, label=\"train\")\n",
        "            plt.plot(steps, val_acc, label=\"val\")\n",
        "            plt.legend()\n",
        "            plt.title(\"Modular Multiplication (training on 50% of data)\")\n",
        "            plt.xlabel(\"Optimization Steps\")\n",
        "            plt.ylabel(\"Accuracy\")\n",
        "            plt.xscale(\"log\", base=10)\n",
        "            plt.grid()\n",
        "            plt.savefig(f\"{results_dir}/acc_{args.label}.png\", dpi=150)\n",
        "            plt.close()\n",
        "\n",
        "            plt.plot(steps, train_loss, label=\"train\")\n",
        "            plt.plot(steps, val_loss, label=\"val\")\n",
        "            plt.legend()\n",
        "            plt.title(\"Modular Multiplication (training on 50% of data)\")\n",
        "            plt.xlabel(\"Optimization Steps\")\n",
        "            plt.ylabel(\"Loss\")\n",
        "            plt.xscale(\"log\", base=10)\n",
        "            plt.grid()\n",
        "            plt.savefig(f\"{results_dir}/loss_{args.label}.png\", dpi=150)\n",
        "            plt.close()\n",
        "\n",
        "            results = {\n",
        "                'its': its,\n",
        "                'train_acc': train_acc,\n",
        "                'train_loss': train_loss,\n",
        "                'val_acc': val_acc,\n",
        "                'val_loss': val_loss,\n",
        "            }\n",
        "\n",
        "            if args.save_weights:\n",
        "                net_its.append(e)\n",
        "                nets.append(copy.deepcopy(model.state_dict()))\n",
        "                results['net_its'] = net_its\n",
        "                results['net'] = nets\n",
        "\n",
        "            torch.save(results, f\"{results_dir}/res_{args.label}.pt\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ],
      "metadata": {
        "id": "Dne-ziHDdwNG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e1f45f30-654a-4ec3-aed2-88d5855cd988"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "chBCi5e6M0L9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 738
        },
        "outputId": "91ed287a-f459-4cc7-9917-a8937a7a1510"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Experiment results saved under name: none\n",
            "Dataset size: 1.0\n",
            "Decoder(\n",
            "  (token_embeddings): Embedding(99, 128)\n",
            "  (position_embeddings): Embedding(5, 128)\n",
            "  (layers): ModuleList(\n",
            "    (0-1): 2 x Block(\n",
            "      (ln_1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
            "      (ln_2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
            "      (attn): MultiheadAttention(\n",
            "        (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
            "      )\n",
            "      (mlp): Sequential(\n",
            "        (0): Linear(in_features=128, out_features=512, bias=True)\n",
            "        (1): GELU(approximate='none')\n",
            "        (2): Linear(in_features=512, out_features=128, bias=True)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (ln_f): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
            "  (head): Linear(in_features=128, out_features=99, bias=False)\n",
            ")\n",
            "Total number of parameters: 422784\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 7/15789 [00:10<6:36:07,  1.51s/it]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-0497422d51d5>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m    \u001b[0;31m# Call main\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-13-11a58f3cb4ea>\u001b[0m in \u001b[0;36mmain\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m     80\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mis_train\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m                     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m                     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m                     \u001b[0;31m#######\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    579\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    580\u001b[0m             )\n\u001b[0;32m--> 581\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    582\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    583\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    345\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 347\u001b[0;31m     _engine_run_backward(\n\u001b[0m\u001b[1;32m    348\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\u001b[0m in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    823\u001b[0m         \u001b[0munregister_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_register_logging_hooks_on_whole_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    824\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 825\u001b[0;31m         return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    826\u001b[0m             \u001b[0mt_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m         )  # Calls into the C++ engine to run the backward pass\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "if __name__ == \"__main__\":\n",
        "    parser = ArgumentParser()\n",
        "    parser.add_argument(\"--label\", default=\"\")\n",
        "    parser.add_argument(\"--seed\", type=int, default=0)\n",
        "    parser.add_argument(\"--p\", type=int, default=97)\n",
        "    parser.add_argument(\"--budget\", type=int, default=3e5)\n",
        "    parser.add_argument(\"--batch_size\", type=int, default=256)\n",
        "    parser.add_argument(\"--lr\", type=float, default=1e-3)\n",
        "    parser.add_argument(\"--beta1\", type=float, default=0.9)\n",
        "    parser.add_argument(\"--beta2\", type=float, default=0.98)\n",
        "    parser.add_argument(\"--weight_decay\", type=float, default=0)\n",
        "    parser.add_argument(\"--optimizer\", default=\"Adam\")\n",
        "    parser.add_argument(\"--filter\", type=str, choices=[\"none\", \"ma\", \"ema\", \"fir\"], default=\"none\")\n",
        "    parser.add_argument(\"--alpha\", type=float, default=0.99)\n",
        "    parser.add_argument(\"--window_size\", type=int, default=50)\n",
        "    parser.add_argument(\"--lamb\", type=float, default=5.0)\n",
        "    parser.add_argument(\"--two_stage\", action='store_true')\n",
        "    parser.add_argument(\"--save_weights\", action='store_true')\n",
        "    parser.add_argument(\"--dataset_fraction\", type=float, default=1.0, help=\"Fraction of the dataset to use (0.0 to 1.0)\")\n",
        "\n",
        "\n",
        "    # Parse known arguments to handle Jupyter conflicts\n",
        "    args, unknown = parser.parse_known_args()\n",
        "\n",
        "    # Modify label dynamically\n",
        "    filter_str = ('_' if args.label != '' else '') + args.filter\n",
        "    window_size_str = f'_w{args.window_size}'\n",
        "    alpha_str = f'_a{args.alpha:.3f}'.replace('.', '')\n",
        "    lamb_str = f'_l{int(args.lamb)}'\n",
        "\n",
        "    if args.filter == \"none\":\n",
        "        filter_suffix = \"\"\n",
        "    elif args.filter == \"ma\":\n",
        "        filter_suffix = window_size_str + lamb_str\n",
        "    elif args.filter == \"ema\":\n",
        "        filter_suffix = alpha_str + lamb_str\n",
        "    else:\n",
        "        raise ValueError(f\"Unrecognized filter type {args.filter}\")\n",
        "\n",
        "    optim_suffix = \"\"\n",
        "    if args.weight_decay != 0:\n",
        "        optim_suffix = optim_suffix + f'_wd{args.weight_decay:.1e}'.replace('.', '')\n",
        "    if args.lr != 1e-3:\n",
        "        optim_suffix = optim_suffix + f'_lrx{int(args.lr / 1e-3)}'\n",
        "\n",
        "    args.label = args.label + filter_str + filter_suffix + optim_suffix\n",
        "    print(f\"Experiment results saved under name: {args.label}\")\n",
        "\n",
        "    print(f\"Dataset size: {args.dataset_fraction}\")\n",
        "\n",
        "\n",
        "   # Call main\n",
        "    main(args)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Running EMA algoritmh with window=20 below"
      ],
      "metadata": {
        "id": "QKy1yxUci2h1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    parser = ArgumentParser()\n",
        "    parser.add_argument(\"--label\", default=\"\")\n",
        "    parser.add_argument(\"--seed\", type=int, default=0)\n",
        "    parser.add_argument(\"--p\", type=int, default=97)\n",
        "    parser.add_argument(\"--budget\", type=int, default=3e5)\n",
        "    parser.add_argument(\"--batch_size\", type=int, default=256)\n",
        "    parser.add_argument(\"--lr\", type=float, default=1e-3)\n",
        "    parser.add_argument(\"--beta1\", type=float, default=0.9)\n",
        "    parser.add_argument(\"--beta2\", type=float, default=0.98)\n",
        "    parser.add_argument(\"--weight_decay\", type=float, default=0.0001)\n",
        "    parser.add_argument(\"--optimizer\", default=\"Adam\")\n",
        "    parser.add_argument(\"--filter\", type=str, choices=[\"none\", \"ma\", \"ema\", \"fir\"], default=\"none\")\n",
        "    parser.add_argument(\"--alpha\", type=float, default=0.99)\n",
        "    parser.add_argument(\"--window_size\", type=int, default=50)\n",
        "    parser.add_argument(\"--lamb\", type=float, default=5.0)\n",
        "    parser.add_argument(\"--two_stage\", action='store_true')\n",
        "    parser.add_argument(\"--save_weights\", action='store_true')\n",
        "    parser.add_argument(\"--dataset_fraction\", type=float, default=1.0, help=\"Fraction of the dataset to use (0.0 to 1.0)\")\n",
        "\n",
        "\n",
        "    # Parse known arguments to handle Jupyter conflicts\n",
        "    args, unknown = parser.parse_known_args()\n",
        "\n",
        "    # Modify label dynamically\n",
        "    filter_str = ('_' if args.label != '' else '') + args.filter\n",
        "    window_size_str = f'_w{args.window_size}'\n",
        "    alpha_str = f'_a{args.alpha:.3f}'.replace('.', '')\n",
        "    lamb_str = f'_l{int(args.lamb)}'\n",
        "\n",
        "    if args.filter == \"none\":\n",
        "        filter_suffix = \"\"\n",
        "    elif args.filter == \"ma\":\n",
        "        filter_suffix = window_size_str + lamb_str\n",
        "    elif args.filter == \"ema\":\n",
        "        filter_suffix = alpha_str + lamb_str\n",
        "    else:\n",
        "        raise ValueError(f\"Unrecognized filter type {args.filter}\")\n",
        "\n",
        "    optim_suffix = \"\"\n",
        "    if args.weight_decay != 0:\n",
        "        optim_suffix = optim_suffix + f'_wd{args.weight_decay:.1e}'.replace('.', '')\n",
        "    if args.lr != 1e-3:\n",
        "        optim_suffix = optim_suffix + f'_lrx{int(args.lr / 1e-3)}'\n",
        "\n",
        "    args.label = args.label + filter_str + filter_suffix + optim_suffix\n",
        "    print(f\"Experiment results saved under name: {args.label}\")\n",
        "\n",
        "    print(f\"Dataset size: {args.dataset_fraction}\")\n",
        "\n",
        "\n",
        "   # Call main\n",
        "    main(args)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u1PV4D6EPtDl",
        "outputId": "1a5edb33-7a1c-454a-ab54-6938c71cd4cc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Experiment results saved under name: none_wd10e-04\n",
            "Dataset size: 1.0\n",
            "Decoder(\n",
            "  (token_embeddings): Embedding(99, 128)\n",
            "  (position_embeddings): Embedding(5, 128)\n",
            "  (layers): ModuleList(\n",
            "    (0-1): 2 x Block(\n",
            "      (ln_1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
            "      (ln_2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
            "      (attn): MultiheadAttention(\n",
            "        (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
            "      )\n",
            "      (mlp): Sequential(\n",
            "        (0): Linear(in_features=128, out_features=512, bias=True)\n",
            "        (1): GELU(approximate='none')\n",
            "        (2): Linear(in_features=512, out_features=128, bias=True)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (ln_f): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
            "  (head): Linear(in_features=128, out_features=99, bias=False)\n",
            ")\n",
            "Total number of parameters: 422784\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15789/15789 [42:59<00:00,  6.12it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    parser = ArgumentParser()\n",
        "    parser.add_argument(\"--label\", default=\"\")\n",
        "    parser.add_argument(\"--seed\", type=int, default=0)\n",
        "    parser.add_argument(\"--p\", type=int, default=97)\n",
        "    parser.add_argument(\"--budget\", type=int, default=3e5)\n",
        "    parser.add_argument(\"--batch_size\", type=int, default=256)\n",
        "    parser.add_argument(\"--lr\", type=float, default=1e-3)\n",
        "    parser.add_argument(\"--beta1\", type=float, default=0.9)\n",
        "    parser.add_argument(\"--beta2\", type=float, default=0.98)\n",
        "    parser.add_argument(\"--weight_decay\", type=float, default=0.0005)\n",
        "    parser.add_argument(\"--optimizer\", default=\"Adam\")\n",
        "    parser.add_argument(\"--filter\", type=str, choices=[\"none\", \"ma\", \"ema\", \"fir\"], default=\"none\")\n",
        "    parser.add_argument(\"--alpha\", type=float, default=0.99)\n",
        "    parser.add_argument(\"--window_size\", type=int, default=50)\n",
        "    parser.add_argument(\"--lamb\", type=float, default=5.0)\n",
        "    parser.add_argument(\"--two_stage\", action='store_true')\n",
        "    parser.add_argument(\"--save_weights\", action='store_true')\n",
        "    parser.add_argument(\"--dataset_fraction\", type=float, default=1.0, help=\"Fraction of the dataset to use (0.0 to 1.0)\")\n",
        "\n",
        "\n",
        "    # Parse known arguments to handle Jupyter conflicts\n",
        "    args, unknown = parser.parse_known_args()\n",
        "\n",
        "    # Modify label dynamically\n",
        "    filter_str = ('_' if args.label != '' else '') + args.filter\n",
        "    window_size_str = f'_w{args.window_size}'\n",
        "    alpha_str = f'_a{args.alpha:.3f}'.replace('.', '')\n",
        "    lamb_str = f'_l{int(args.lamb)}'\n",
        "\n",
        "    if args.filter == \"none\":\n",
        "        filter_suffix = \"\"\n",
        "    elif args.filter == \"ma\":\n",
        "        filter_suffix = window_size_str + lamb_str\n",
        "    elif args.filter == \"ema\":\n",
        "        filter_suffix = alpha_str + lamb_str\n",
        "    else:\n",
        "        raise ValueError(f\"Unrecognized filter type {args.filter}\")\n",
        "\n",
        "    optim_suffix = \"\"\n",
        "    if args.weight_decay != 0:\n",
        "        optim_suffix = optim_suffix + f'_wd{args.weight_decay:.1e}'.replace('.', '')\n",
        "    if args.lr != 1e-3:\n",
        "        optim_suffix = optim_suffix + f'_lrx{int(args.lr / 1e-3)}'\n",
        "\n",
        "    args.label = args.label + filter_str + filter_suffix + optim_suffix\n",
        "    print(f\"Experiment results saved under name: {args.label}\")\n",
        "\n",
        "    print(f\"Dataset size: {args.dataset_fraction}\")\n",
        "\n",
        "\n",
        "   # Call main\n",
        "    main(args)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SWu2ddzlQQKF",
        "outputId": "3991ed9e-0bd7-4f42-f634-48aea75338b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Experiment results saved under name: none_wd50e-04\n",
            "Dataset size: 1.0\n",
            "Decoder(\n",
            "  (token_embeddings): Embedding(99, 128)\n",
            "  (position_embeddings): Embedding(5, 128)\n",
            "  (layers): ModuleList(\n",
            "    (0-1): 2 x Block(\n",
            "      (ln_1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
            "      (ln_2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
            "      (attn): MultiheadAttention(\n",
            "        (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
            "      )\n",
            "      (mlp): Sequential(\n",
            "        (0): Linear(in_features=128, out_features=512, bias=True)\n",
            "        (1): GELU(approximate='none')\n",
            "        (2): Linear(in_features=512, out_features=128, bias=True)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (ln_f): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
            "  (head): Linear(in_features=128, out_features=99, bias=False)\n",
            ")\n",
            "Total number of parameters: 422784\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15789/15789 [43:20<00:00,  6.07it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    parser = ArgumentParser()\n",
        "    parser.add_argument(\"--label\", default=\"\")\n",
        "    parser.add_argument(\"--seed\", type=int, default=0)\n",
        "    parser.add_argument(\"--p\", type=int, default=97)\n",
        "    parser.add_argument(\"--budget\", type=int, default=3e5)\n",
        "    parser.add_argument(\"--batch_size\", type=int, default=256)\n",
        "    parser.add_argument(\"--lr\", type=float, default=1e-3)\n",
        "    parser.add_argument(\"--beta1\", type=float, default=0.9)\n",
        "    parser.add_argument(\"--beta2\", type=float, default=0.98)\n",
        "    parser.add_argument(\"--weight_decay\", type=float, default=0.001)\n",
        "    parser.add_argument(\"--optimizer\", default=\"Adam\")\n",
        "    parser.add_argument(\"--filter\", type=str, choices=[\"none\", \"ma\", \"ema\", \"fir\"], default=\"none\")\n",
        "    parser.add_argument(\"--alpha\", type=float, default=0.99)\n",
        "    parser.add_argument(\"--window_size\", type=int, default=50)\n",
        "    parser.add_argument(\"--lamb\", type=float, default=5.0)\n",
        "    parser.add_argument(\"--two_stage\", action='store_true')\n",
        "    parser.add_argument(\"--save_weights\", action='store_true')\n",
        "    parser.add_argument(\"--dataset_fraction\", type=float, default=1.0, help=\"Fraction of the dataset to use (0.0 to 1.0)\")\n",
        "\n",
        "\n",
        "    # Parse known arguments to handle Jupyter conflicts\n",
        "    args, unknown = parser.parse_known_args()\n",
        "\n",
        "    # Modify label dynamically\n",
        "    filter_str = ('_' if args.label != '' else '') + args.filter\n",
        "    window_size_str = f'_w{args.window_size}'\n",
        "    alpha_str = f'_a{args.alpha:.3f}'.replace('.', '')\n",
        "    lamb_str = f'_l{int(args.lamb)}'\n",
        "\n",
        "    if args.filter == \"none\":\n",
        "        filter_suffix = \"\"\n",
        "    elif args.filter == \"ma\":\n",
        "        filter_suffix = window_size_str + lamb_str\n",
        "    elif args.filter == \"ema\":\n",
        "        filter_suffix = alpha_str + lamb_str\n",
        "    else:\n",
        "        raise ValueError(f\"Unrecognized filter type {args.filter}\")\n",
        "\n",
        "    optim_suffix = \"\"\n",
        "    if args.weight_decay != 0:\n",
        "        optim_suffix = optim_suffix + f'_wd{args.weight_decay:.1e}'.replace('.', '')\n",
        "    if args.lr != 1e-3:\n",
        "        optim_suffix = optim_suffix + f'_lrx{int(args.lr / 1e-3)}'\n",
        "\n",
        "    args.label = args.label + filter_str + filter_suffix + optim_suffix\n",
        "    print(f\"Experiment results saved under name: {args.label}\")\n",
        "\n",
        "    print(f\"Dataset size: {args.dataset_fraction}\")\n",
        "\n",
        "\n",
        "   # Call main\n",
        "    main(args)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pp4PXec6QTie",
        "outputId": "51f48c75-4219-4520-eaca-e0da7c82bd9c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Experiment results saved under name: none_wd10e-03\n",
            "Dataset size: 1.0\n",
            "Decoder(\n",
            "  (token_embeddings): Embedding(99, 128)\n",
            "  (position_embeddings): Embedding(5, 128)\n",
            "  (layers): ModuleList(\n",
            "    (0-1): 2 x Block(\n",
            "      (ln_1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
            "      (ln_2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
            "      (attn): MultiheadAttention(\n",
            "        (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
            "      )\n",
            "      (mlp): Sequential(\n",
            "        (0): Linear(in_features=128, out_features=512, bias=True)\n",
            "        (1): GELU(approximate='none')\n",
            "        (2): Linear(in_features=512, out_features=128, bias=True)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (ln_f): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
            "  (head): Linear(in_features=128, out_features=99, bias=False)\n",
            ")\n",
            "Total number of parameters: 422784\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15789/15789 [42:52<00:00,  6.14it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    parser = ArgumentParser()\n",
        "    parser.add_argument(\"--label\", default=\"\")\n",
        "    parser.add_argument(\"--seed\", type=int, default=0)\n",
        "    parser.add_argument(\"--p\", type=int, default=97)\n",
        "    parser.add_argument(\"--budget\", type=int, default=3e5)\n",
        "    parser.add_argument(\"--batch_size\", type=int, default=256)\n",
        "    parser.add_argument(\"--lr\", type=float, default=1e-3)\n",
        "    parser.add_argument(\"--beta1\", type=float, default=0.9)\n",
        "    parser.add_argument(\"--beta2\", type=float, default=0.98)\n",
        "    parser.add_argument(\"--weight_decay\", type=float, default=0.01)\n",
        "    parser.add_argument(\"--optimizer\", default=\"Adam\")\n",
        "    parser.add_argument(\"--filter\", type=str, choices=[\"none\", \"ma\", \"ema\", \"fir\"], default=\"none\")\n",
        "    parser.add_argument(\"--alpha\", type=float, default=0.99)\n",
        "    parser.add_argument(\"--window_size\", type=int, default=50)\n",
        "    parser.add_argument(\"--lamb\", type=float, default=5.0)\n",
        "    parser.add_argument(\"--two_stage\", action='store_true')\n",
        "    parser.add_argument(\"--save_weights\", action='store_true')\n",
        "    parser.add_argument(\"--dataset_fraction\", type=float, default=1.0, help=\"Fraction of the dataset to use (0.0 to 1.0)\")\n",
        "\n",
        "\n",
        "    # Parse known arguments to handle Jupyter conflicts\n",
        "    args, unknown = parser.parse_known_args()\n",
        "\n",
        "    # Modify label dynamically\n",
        "    filter_str = ('_' if args.label != '' else '') + args.filter\n",
        "    window_size_str = f'_w{args.window_size}'\n",
        "    alpha_str = f'_a{args.alpha:.3f}'.replace('.', '')\n",
        "    lamb_str = f'_l{int(args.lamb)}'\n",
        "\n",
        "    if args.filter == \"none\":\n",
        "        filter_suffix = \"\"\n",
        "    elif args.filter == \"ma\":\n",
        "        filter_suffix = window_size_str + lamb_str\n",
        "    elif args.filter == \"ema\":\n",
        "        filter_suffix = alpha_str + lamb_str\n",
        "    else:\n",
        "        raise ValueError(f\"Unrecognized filter type {args.filter}\")\n",
        "\n",
        "    optim_suffix = \"\"\n",
        "    if args.weight_decay != 0:\n",
        "        optim_suffix = optim_suffix + f'_wd{args.weight_decay:.1e}'.replace('.', '')\n",
        "    if args.lr != 1e-3:\n",
        "        optim_suffix = optim_suffix + f'_lrx{int(args.lr / 1e-3)}'\n",
        "\n",
        "    args.label = args.label + filter_str + filter_suffix + optim_suffix\n",
        "    print(f\"Experiment results saved under name: {args.label}\")\n",
        "\n",
        "    print(f\"Dataset size: {args.dataset_fraction}\")\n",
        "\n",
        "\n",
        "   # Call main\n",
        "    main(args)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LXYa3yKfRPH2",
        "outputId": "038b54c4-7965-45e4-bb10-e6d94c02499e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Experiment results saved under name: none_wd10e-02\n",
            "Dataset size: 1.0\n",
            "Decoder(\n",
            "  (token_embeddings): Embedding(99, 128)\n",
            "  (position_embeddings): Embedding(5, 128)\n",
            "  (layers): ModuleList(\n",
            "    (0-1): 2 x Block(\n",
            "      (ln_1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
            "      (ln_2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
            "      (attn): MultiheadAttention(\n",
            "        (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
            "      )\n",
            "      (mlp): Sequential(\n",
            "        (0): Linear(in_features=128, out_features=512, bias=True)\n",
            "        (1): GELU(approximate='none')\n",
            "        (2): Linear(in_features=512, out_features=128, bias=True)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (ln_f): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
            "  (head): Linear(in_features=128, out_features=99, bias=False)\n",
            ")\n",
            "Total number of parameters: 422784\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15789/15789 [43:24<00:00,  6.06it/s]\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}