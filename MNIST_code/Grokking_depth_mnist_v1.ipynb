{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyP1Y26QnNc5dTokMuv8IpYO"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{}}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"HtT_FnObQxFF"},"outputs":[],"source":["#Experimenting with depth - filtering  code for MNIST dataset\n","#   Omada 2 -- Grokfast experiments"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"f4s6HWPGPSBJ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1737285421071,"user_tz":-120,"elapsed":69901,"user":{"displayName":"Nikolas Xiros","userId":"00495869844002127525"}},"outputId":"a475fd9a-6a04-4ed6-f06a-e25d948f5105"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gADYjdBHN1cg"},"outputs":[],"source":["# from google.colab import files\n","# files.upload()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":298,"status":"ok","timestamp":1737285434132,"user":{"displayName":"Nikolas Xiros","userId":"00495869844002127525"},"user_tz":-120},"id":"pUw0ejsKP3sp","outputId":"5cb4a241-da5e-4267-a57b-7370a4bf9a63"},"outputs":[{"output_type":"stream","name":"stdout","text":["Algorithmic_code  MNIST_code\t  __pycache__  requirements.txt\n","grokfast.py\t  _Presentations  QM9_code     results\n"]}],"source":["!ls /content/drive/MyDrive/PatRec_Project_Shared_Folder/"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wHJ2F3QuKau3","executionInfo":{"status":"ok","timestamp":1737285437164,"user_tz":-120,"elapsed":1905,"user":{"displayName":"Nikolas Xiros","userId":"00495869844002127525"}},"outputId":"4a703113-5196-403b-e247-f29daa77c7aa"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qdXeIGW_QC3w"},"outputs":[],"source":["import sys\n","sys.path.append('/content/drive/MyDrive/PatRec_Project_Shared_Folder')"]},{"cell_type":"markdown","source":[],"metadata":{"id":"PVYkDchkRCiQ"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4389,"status":"ok","timestamp":1737285449828,"user":{"displayName":"Nikolas Xiros","userId":"00495869844002127525"},"user_tz":-120},"id":"C13vv8V-KHUI","outputId":"7f547dc6-0987-42a8-ddb7-a220b7ed58e3"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from -r /content/drive/MyDrive/PatRec_Project_Shared_Folder/requirements.txt (line 1)) (3.10.0)\n","Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from -r /content/drive/MyDrive/PatRec_Project_Shared_Folder/requirements.txt (line 2)) (2.5.1+cu121)\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (from -r /content/drive/MyDrive/PatRec_Project_Shared_Folder/requirements.txt (line 3)) (0.20.1+cu121)\n","Collecting torch_geometric (from -r /content/drive/MyDrive/PatRec_Project_Shared_Folder/requirements.txt (line 4))\n","  Downloading torch_geometric-2.6.1-py3-none-any.whl.metadata (63 kB)\n","\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/63.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.1/63.1 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from -r /content/drive/MyDrive/PatRec_Project_Shared_Folder/requirements.txt (line 5)) (2.2.2)\n","Requirement already satisfied: seaborn in /usr/local/lib/python3.11/dist-packages (from -r /content/drive/MyDrive/PatRec_Project_Shared_Folder/requirements.txt (line 6)) (0.13.2)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from -r /content/drive/MyDrive/PatRec_Project_Shared_Folder/requirements.txt (line 7)) (4.67.1)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from -r /content/drive/MyDrive/PatRec_Project_Shared_Folder/requirements.txt (line 8)) (1.13.1)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->-r /content/drive/MyDrive/PatRec_Project_Shared_Folder/requirements.txt (line 1)) (1.3.1)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->-r /content/drive/MyDrive/PatRec_Project_Shared_Folder/requirements.txt (line 1)) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->-r /content/drive/MyDrive/PatRec_Project_Shared_Folder/requirements.txt (line 1)) (4.55.3)\n","Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->-r /content/drive/MyDrive/PatRec_Project_Shared_Folder/requirements.txt (line 1)) (1.4.8)\n","Requirement already satisfied: numpy>=1.23 in /usr/local/lib/python3.11/dist-packages (from matplotlib->-r /content/drive/MyDrive/PatRec_Project_Shared_Folder/requirements.txt (line 1)) (1.26.4)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->-r /content/drive/MyDrive/PatRec_Project_Shared_Folder/requirements.txt (line 1)) (24.2)\n","Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib->-r /content/drive/MyDrive/PatRec_Project_Shared_Folder/requirements.txt (line 1)) (11.1.0)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->-r /content/drive/MyDrive/PatRec_Project_Shared_Folder/requirements.txt (line 1)) (3.2.1)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->-r /content/drive/MyDrive/PatRec_Project_Shared_Folder/requirements.txt (line 1)) (2.8.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->-r /content/drive/MyDrive/PatRec_Project_Shared_Folder/requirements.txt (line 2)) (3.16.1)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch->-r /content/drive/MyDrive/PatRec_Project_Shared_Folder/requirements.txt (line 2)) (4.12.2)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->-r /content/drive/MyDrive/PatRec_Project_Shared_Folder/requirements.txt (line 2)) (3.4.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->-r /content/drive/MyDrive/PatRec_Project_Shared_Folder/requirements.txt (line 2)) (3.1.5)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->-r /content/drive/MyDrive/PatRec_Project_Shared_Folder/requirements.txt (line 2)) (2024.10.0)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch->-r /content/drive/MyDrive/PatRec_Project_Shared_Folder/requirements.txt (line 2)) (12.1.105)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch->-r /content/drive/MyDrive/PatRec_Project_Shared_Folder/requirements.txt (line 2)) (12.1.105)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch->-r /content/drive/MyDrive/PatRec_Project_Shared_Folder/requirements.txt (line 2)) (12.1.105)\n","Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch->-r /content/drive/MyDrive/PatRec_Project_Shared_Folder/requirements.txt (line 2)) (9.1.0.70)\n","Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.11/dist-packages (from torch->-r /content/drive/MyDrive/PatRec_Project_Shared_Folder/requirements.txt (line 2)) (12.1.3.1)\n","Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.11/dist-packages (from torch->-r /content/drive/MyDrive/PatRec_Project_Shared_Folder/requirements.txt (line 2)) (11.0.2.54)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.11/dist-packages (from torch->-r /content/drive/MyDrive/PatRec_Project_Shared_Folder/requirements.txt (line 2)) (10.3.2.106)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.11/dist-packages (from torch->-r /content/drive/MyDrive/PatRec_Project_Shared_Folder/requirements.txt (line 2)) (11.4.5.107)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.11/dist-packages (from torch->-r /content/drive/MyDrive/PatRec_Project_Shared_Folder/requirements.txt (line 2)) (12.1.0.106)\n","Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->-r /content/drive/MyDrive/PatRec_Project_Shared_Folder/requirements.txt (line 2)) (2.21.5)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch->-r /content/drive/MyDrive/PatRec_Project_Shared_Folder/requirements.txt (line 2)) (12.1.105)\n","Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch->-r /content/drive/MyDrive/PatRec_Project_Shared_Folder/requirements.txt (line 2)) (3.1.0)\n","Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->-r /content/drive/MyDrive/PatRec_Project_Shared_Folder/requirements.txt (line 2)) (1.13.1)\n","Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.11/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->-r /content/drive/MyDrive/PatRec_Project_Shared_Folder/requirements.txt (line 2)) (12.6.85)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->-r /content/drive/MyDrive/PatRec_Project_Shared_Folder/requirements.txt (line 2)) (1.3.0)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from torch_geometric->-r /content/drive/MyDrive/PatRec_Project_Shared_Folder/requirements.txt (line 4)) (3.11.11)\n","Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.11/dist-packages (from torch_geometric->-r /content/drive/MyDrive/PatRec_Project_Shared_Folder/requirements.txt (line 4)) (5.9.5)\n","Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from torch_geometric->-r /content/drive/MyDrive/PatRec_Project_Shared_Folder/requirements.txt (line 4)) (2.32.3)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->-r /content/drive/MyDrive/PatRec_Project_Shared_Folder/requirements.txt (line 5)) (2024.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->-r /content/drive/MyDrive/PatRec_Project_Shared_Folder/requirements.txt (line 5)) (2024.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib->-r /content/drive/MyDrive/PatRec_Project_Shared_Folder/requirements.txt (line 1)) (1.17.0)\n","Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric->-r /content/drive/MyDrive/PatRec_Project_Shared_Folder/requirements.txt (line 4)) (2.4.4)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric->-r /content/drive/MyDrive/PatRec_Project_Shared_Folder/requirements.txt (line 4)) (1.3.2)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric->-r /content/drive/MyDrive/PatRec_Project_Shared_Folder/requirements.txt (line 4)) (24.3.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric->-r /content/drive/MyDrive/PatRec_Project_Shared_Folder/requirements.txt (line 4)) (1.5.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric->-r /content/drive/MyDrive/PatRec_Project_Shared_Folder/requirements.txt (line 4)) (6.1.0)\n","Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric->-r /content/drive/MyDrive/PatRec_Project_Shared_Folder/requirements.txt (line 4)) (0.2.1)\n","Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric->-r /content/drive/MyDrive/PatRec_Project_Shared_Folder/requirements.txt (line 4)) (1.18.3)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->-r /content/drive/MyDrive/PatRec_Project_Shared_Folder/requirements.txt (line 2)) (3.0.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->torch_geometric->-r /content/drive/MyDrive/PatRec_Project_Shared_Folder/requirements.txt (line 4)) (3.4.1)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->torch_geometric->-r /content/drive/MyDrive/PatRec_Project_Shared_Folder/requirements.txt (line 4)) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->torch_geometric->-r /content/drive/MyDrive/PatRec_Project_Shared_Folder/requirements.txt (line 4)) (2.3.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->torch_geometric->-r /content/drive/MyDrive/PatRec_Project_Shared_Folder/requirements.txt (line 4)) (2024.12.14)\n","Downloading torch_geometric-2.6.1-py3-none-any.whl (1.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m30.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: torch_geometric\n","Successfully installed torch_geometric-2.6.1\n"]}],"source":["!pip install -r /content/drive/MyDrive/PatRec_Project_Shared_Folder/requirements.txt"]},{"cell_type":"code","source":["import random\n","import time\n","import math\n","import argparse\n","from argparse import ArgumentParser\n","from collections import defaultdict\n","from itertools import islice\n","from pathlib import Path\n","\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from tqdm.auto import tqdm\n","\n","import torch\n","import torch.nn as nn\n","import torchvision\n","from typing import List, Optional, Dict, Literal\n","from collections import deque\n"],"metadata":{"id":"QLUi9XZMRpId"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from grokfast import gradfilter_ma, gradfilter_ema"],"metadata":{"id":"0N3mHr5fQx7a"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def cycle(iterable):\n","    while True:\n","        for x in iterable:\n","            yield x"],"metadata":{"id":"RIifrNowR89e"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def compute_accuracy(network, dataset, device, N=2000, batch_size=50):\n","    \"\"\"Computes accuracy of `network` on `dataset`.\n","    \"\"\"\n","    with torch.no_grad():\n","        N = min(len(dataset), N)\n","        batch_size = min(batch_size, N)\n","        dataset_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True)\n","        correct = 0\n","        total = 0\n","        for x, labels in islice(dataset_loader, N // batch_size):\n","            logits = network(x.to(device))\n","            predicted_labels = torch.argmax(logits, dim=1)\n","            correct += torch.sum(predicted_labels == labels.to(device))\n","            total += x.size(0)\n","        return (correct / total).item()\n","\n","\n","def compute_loss(network, dataset, loss_function, device, N=2000, batch_size=50):\n","    \"\"\"Computes mean loss of `network` on `dataset`.\n","    \"\"\"\n","    with torch.no_grad():\n","        N = min(len(dataset), N)\n","        batch_size = min(batch_size, N)\n","        dataset_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True)\n","        loss_fn = loss_function_dict[loss_function](reduction='sum')\n","        one_hots = torch.eye(10, 10).to(device)\n","        total = 0\n","        points = 0\n","        for x, labels in islice(dataset_loader, N // batch_size):\n","            y = network(x.to(device))\n","            if loss_function == 'CrossEntropy':\n","                total += loss_fn(y, labels.to(device)).item()\n","            elif loss_function == 'MSE':\n","                total += loss_fn(y, one_hots[labels]).item()\n","            points += len(labels)\n","        return total / points\n","\n"],"metadata":{"id":"jrly4HA7SBob"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["optimizer_dict = {\n","    'AdamW': torch.optim.AdamW,\n","    'Adam': torch.optim.Adam,\n","    'SGD': torch.optim.SGD\n","}\n","\n","activation_dict = {\n","    'ReLU': nn.ReLU,\n","    'Tanh': nn.Tanh,\n","    'Sigmoid': nn.Sigmoid,\n","    'GELU': nn.GELU\n","}\n","\n","loss_function_dict = {\n","    'MSE': nn.MSELoss,\n","    'CrossEntropy': nn.CrossEntropyLoss\n","}"],"metadata":{"id":"8hhZpMIuSC4q"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import os\n","# Ensure the 'results' directory exists\n","results_dir = \"/content/drive/MyDrive/PatRec_Project_Shared_Folder/results/MNIST\"\n"],"metadata":{"id":"qoYeFeeSb6YH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","def gradfilter_with_depth_scaling(\n","    m: nn.Module,\n","    grads: Optional[Dict[str, deque]] = None,\n","    window_size: int = 100,\n","    alpha: float = 0.98,\n","    lamb_max: float = 3.0,\n","    lamb_min: float = 1.0,\n","    d_max: int = 12,  # Total number of transformer layers\n","    filter_type: Literal['mean', 'sum'] = 'mean',\n","    warmup: bool = True,\n","    trigger: bool = False,\n","    embedding_layer_name: str = \"embedding\",\n","    final_and_output_layer_names: List[str] = [\"ln_f\", \"head\"],  # Default final and output layer names\n",") -> Dict[str, deque]:\n","    \"\"\"\n","    Applies gradient filtering with dynamic depth-based lambda scaling.\n","\n","    Args:\n","        m (nn.Module): The model containing the parameters.\n","        grads (Optional[Dict[str, deque]]): Dictionary for storing past gradients.\n","        window_size (int): Number of past gradients to consider.\n","        lamb_max (float): Maximum lambda value for scaling.\n","        lamb_min (float): Minimum lambda value for scaling.\n","        d_max (int): Total depth (number of transformer layers).\n","        filter_type (Literal['mean', 'sum']): Filtering strategy ('mean' or 'sum').\n","        warmup (bool): Whether to enable warmup for gradient filtering.\n","        trigger (bool): Optional trigger condition for gradient filtering.\n","        embedding_layer_name (str): Substring identifying embedding layer parameters.\n","        final_and_output_layer_names (List[str]): List of substrings identifying final/output layer parameters.\n","\n","    Returns:\n","        Dict[str, deque]: Updated gradient storage for the model parameters.\n","     \"\"\"\n","    if grads is None:\n","        grads = {n: p.grad.data.clone() for n, p in m.named_parameters() if p.requires_grad and p.grad is not None}\n","\n","    for n, p in m.named_parameters():\n","        if p.requires_grad and p.grad is not None:\n","            # Determine depth or position\n","            if embedding_layer_name in n:\n","                depth = 0  # Embedding layers are assigned depth 0\n","            elif \"layers\" in n:\n","                # Extract depth information from name, e.g., \"layers.0\", \"layers.1\"\n","                depth = int(n.split(\".\")[1]) + 1  # Increment depth for transformer layers\n","            elif final_and_output_layer_names and any(layer_name in n for layer_name in final_and_output_layer_names):\n","                depth = d_max + 1  # Final and output layers are d_max + 1\n","            else:\n","                depth = d_max  # Default depth for unclassified layers\n","\n","            # Adjust lambda based on depth\n","            lambda_d = lamb_max - (depth / (d_max + 1)) * (lamb_max - lamb_min)\n","\n","            # Apply EMA update\n","            if n not in grads:\n","                grads[n] = p.grad.data.clone()  # Initialize EMA\n","            else:\n","                grads[n] = grads[n] * alpha + p.grad.data.clone() * (1 - alpha)\n","\n","            # Scale gradient by depth-aware lambda\n","            p.grad.data = p.grad.data + grads[n] * lambda_d\n","\n","    return grads"],"metadata":{"id":"L4xvhgZOUrjP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#        Comment after first time\n","# Download dataset\n","\n","import torchvision\n","\n","dataset_path = '/content/drive/MyDrive/PatRec_Project_Shared_Folder/MNIST_code/MNIST_data'\n","train_dataset = torchvision.datasets.MNIST(\n","    root=dataset_path, train=True, transform=torchvision.transforms.ToTensor(), download=True\n",")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QGxS-YusWw39","executionInfo":{"status":"ok","timestamp":1737287321609,"user_tz":-120,"elapsed":526180,"user":{"displayName":"Nikolas Xiros","userId":"00495869844002127525"}},"outputId":"b8ba36aa-744c-4f41-c095-4bde42077ef1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n","Failed to download (trying next):\n","<urlopen error [Errno 110] Connection timed out>\n","\n","Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n","Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to /content/drive/MyDrive/PatRec_Project_Shared_Folder/MNIST_code/MNIST_data/MNIST/raw/train-images-idx3-ubyte.gz\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 9.91M/9.91M [00:00<00:00, 14.7MB/s]\n"]},{"output_type":"stream","name":"stdout","text":["Extracting /content/drive/MyDrive/PatRec_Project_Shared_Folder/MNIST_code/MNIST_data/MNIST/raw/train-images-idx3-ubyte.gz to /content/drive/MyDrive/PatRec_Project_Shared_Folder/MNIST_code/MNIST_data/MNIST/raw\n","\n","Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n","Failed to download (trying next):\n","<urlopen error [Errno 110] Connection timed out>\n","\n","Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n","Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to /content/drive/MyDrive/PatRec_Project_Shared_Folder/MNIST_code/MNIST_data/MNIST/raw/train-labels-idx1-ubyte.gz\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 28.9k/28.9k [00:00<00:00, 484kB/s]\n"]},{"output_type":"stream","name":"stdout","text":["Extracting /content/drive/MyDrive/PatRec_Project_Shared_Folder/MNIST_code/MNIST_data/MNIST/raw/train-labels-idx1-ubyte.gz to /content/drive/MyDrive/PatRec_Project_Shared_Folder/MNIST_code/MNIST_data/MNIST/raw\n","\n","Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n","Failed to download (trying next):\n","<urlopen error [Errno 110] Connection timed out>\n","\n","Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n","Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to /content/drive/MyDrive/PatRec_Project_Shared_Folder/MNIST_code/MNIST_data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1.65M/1.65M [00:00<00:00, 4.19MB/s]\n"]},{"output_type":"stream","name":"stdout","text":["Extracting /content/drive/MyDrive/PatRec_Project_Shared_Folder/MNIST_code/MNIST_data/MNIST/raw/t10k-images-idx3-ubyte.gz to /content/drive/MyDrive/PatRec_Project_Shared_Folder/MNIST_code/MNIST_data/MNIST/raw\n","\n","Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n","Failed to download (trying next):\n","<urlopen error [Errno 110] Connection timed out>\n","\n","Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n","Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to /content/drive/MyDrive/PatRec_Project_Shared_Folder/MNIST_code/MNIST_data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 4.54k/4.54k [00:00<00:00, 5.70MB/s]"]},{"output_type":"stream","name":"stdout","text":["Extracting /content/drive/MyDrive/PatRec_Project_Shared_Folder/MNIST_code/MNIST_data/MNIST/raw/t10k-labels-idx1-ubyte.gz to /content/drive/MyDrive/PatRec_Project_Shared_Folder/MNIST_code/MNIST_data/MNIST/raw\n","\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}]},{"cell_type":"code","source":["from collections import Counter\n","from sklearn.model_selection import train_test_split\n","\n","\n","def main(args):\n","    log_freq = math.ceil(args.optimization_steps / 150)\n","\n","    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","    dtype = torch.float32\n","\n","    torch.set_default_dtype(dtype)\n","    torch.manual_seed(args.seed)\n","    torch.cuda.manual_seed_all(args.seed)\n","    random.seed(args.seed)\n","    np.random.seed(args.seed)\n","\n","    # load dataset\n","    train_dataset = torchvision.datasets.MNIST(\n","        root=dataset_path, train=True, transform=torchvision.transforms.ToTensor(), download=True\n","    )\n","\n","    # Create indices stratified by digit labels\n","    train_indices = list(range(len(train_dataset)))\n","    train_labels = [train_dataset.targets[i].item() for i in train_indices]\n","\n","    args.train_points = 1000\n","    # Use train_test_split with stratification to randomly select a specified number of samples (args.train_points)\n","    stratified_indices, _ = train_test_split(\n","        train_indices,\n","        train_size=args.train_points,\n","        stratify=train_labels,\n","        random_state=args.seed\n","    )\n","\n","    # Create a subset with the stratified indices\n","    train_subset = torch.utils.data.Subset(train_dataset, stratified_indices)\n","    train_loader = torch.utils.data.DataLoader(train_subset, batch_size=args.batch_size, shuffle=True)\n","\n","    test = torchvision.datasets.MNIST(root=args.download_directory, train=False,\n","        transform=torchvision.transforms.ToTensor(), download=True)\n","\n","    assert args.activation in activation_dict, f\"Unsupported activation function: {args.activation}\"\n","    activation_fn = activation_dict[args.activation]\n","\n","    print(f\"Stratified train subset created with {len(stratified_indices)} samples.\")\n","\n","    # Create model\n","    layers = [nn.Flatten()]\n","    for i in range(args.depth):\n","        if i == 0:\n","            layers.append(nn.Linear(784, args.width))\n","            layers.append(activation_fn())\n","        elif i == args.depth - 1:\n","            layers.append(nn.Linear(args.width, 10))\n","        else:\n","            layers.append(nn.Linear(args.width, args.width))\n","            layers.append(activation_fn())\n","    mlp = nn.Sequential(*layers).to(device)\n","    with torch.no_grad():\n","        for p in mlp.parameters():\n","            p.data = args.initialization_scale * p.data\n","    nparams = sum([p.numel() for p in mlp.parameters() if p.requires_grad])\n","    print(f'Number of parameters: {nparams}')\n","\n","    # create optimizer\n","    assert args.optimizer in optimizer_dict, f\"Unsupported optimizer choice: {args.optimizer}\"\n","    optimizer = optimizer_dict[args.optimizer](mlp.parameters(), lr=args.lr, weight_decay=args.weight_decay)\n","\n","    # define loss function\n","    assert args.loss_function in loss_function_dict\n","    loss_fn = loss_function_dict[args.loss_function]()\n","\n","\n","    #     Start Training below\n","    train_losses, test_losses, train_accuracies, test_accuracies = [], [], [], []\n","    norms, last_layer_norms, log_steps = [], [], []\n","    grads = None\n","\n","    steps = 0\n","    one_hots = torch.eye(10, 10).to(device)\n","    with tqdm(total=args.optimization_steps, dynamic_ncols=True) as pbar:\n","        for x, labels in islice(cycle(train_loader), args.optimization_steps):\n","            do_log = (steps < 30) or (steps < 150 and steps % 10 == 0) or steps % log_freq == 0\n","            if do_log:\n","                train_losses.append(compute_loss(mlp, train_subset, args.loss_function, device, N=len(train_subset)))\n","                train_accuracies.append(compute_accuracy(mlp, train_subset, device, N=len(train_subset)))\n","                test_losses.append(compute_loss(mlp, test, args.loss_function, device, N=len(test)))\n","                test_accuracies.append(compute_accuracy(mlp, test, device, N=len(test)))\n","                log_steps.append(steps)\n","\n","                pbar.set_description(\n","                    \"L: {0:1.1e}|{1:1.1e}. A: {2:2.1f}%|{3:2.1f}%\".format(\n","                        train_losses[-1],\n","                        test_losses[-1],\n","                        train_accuracies[-1] * 100,\n","                        test_accuracies[-1] * 100,\n","                    )\n","                )\n","\n","            y = mlp(x.to(device))\n","            if args.loss_function == 'CrossEntropy':\n","                loss = loss_fn(y, labels.to(device))\n","            elif args.loss_function == 'MSE':\n","                loss = loss_fn(y, one_hots[labels])\n","\n","            optimizer.zero_grad()\n","            loss.backward()\n","\n","            #######\n","\n","            trigger = False\n","\n","            if args.filter == \"none\":\n","                pass\n","            elif args.filter == \"ma\":\n","                grads = gradfilter_ma(mlp, grads=grads, window_size=args.window_size, lamb=args.lamb, trigger=trigger)\n","            elif args.filter == \"ema\":\n","                grads = gradfilter_ema(mlp, grads=grads, alpha=args.alpha, lamb=args.lamb)\n","            else:\n","                raise ValueError(f\"Invalid gradient filter type `{args.filter}`\")\n","\n","            #######\n","\n","            optimizer.step()\n","\n","            steps += 1\n","            pbar.update(1)\n","\n","            if do_log:\n","                title = (f\"MNIST Image Classification\")\n","\n","                plt.plot(log_steps, train_accuracies, label=\"train\")\n","                plt.plot(log_steps, test_accuracies, label=\"val\")\n","                plt.legend()\n","                plt.title(title)\n","                plt.xlabel(\"Optimization Steps\")\n","                plt.ylabel(\"Accuracy\")\n","                plt.xscale(\"log\", base=10)\n","                plt.grid()\n","                plt.savefig(f\"{results_dir}/mnist_acc_{args.label}.png\", dpi=150)\n","                plt.close()\n","\n","                plt.plot(log_steps, train_losses, label=\"train\")\n","                plt.plot(log_steps, test_losses, label=\"val\")\n","                plt.legend()\n","                plt.title(title)\n","                plt.xlabel(\"Optimization Steps\")\n","                plt.ylabel(f\"{args.loss_function} Loss\")\n","                plt.xscale(\"log\", base=10)\n","                plt.yscale(\"log\", base=10)\n","                plt.grid()\n","                plt.savefig(f\"{results_dir}/mnist_loss_{args.label}.png\", dpi=150)\n","                plt.close()\n","\n","                # Save results\n","                results_filename = os.path.join(results_dir, f\"mnist_{args.label}.pt\")\n","                torch.save({\n","                    'its': log_steps,\n","                    'train_acc': train_accuracies,\n","                    'train_loss': train_losses,\n","                    'val_acc': test_accuracies,\n","                    'val_loss': test_losses,\n","                }, results_filename)\n"],"metadata":{"id":"LWPwaBWpSF52"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import sys\n","from argparse import ArgumentParser\n","\n","# Remove the extra arguments passed by the Jupyter Notebook kernel\n","sys.argv = ['']"],"metadata":{"id":"M9cU5duNrG1k"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Load the saved results file in prder to use them for plots\n","\n","results_filename = os.path.join(results_dir, \"mnist_none_wd10e-02.pt\")  # Replace with your actual filename\n","if os.path.exists(results_filename):\n","    data = torch.load(results_filename)\n","else:\n","    print(f\"File {results_filename} not found!\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"C7IBsnXw5StN","executionInfo":{"status":"ok","timestamp":1736289199151,"user_tz":-120,"elapsed":559,"user":{"displayName":"Μαρια Σαμπανη","userId":"00480416348673556380"}},"outputId":"db5ef7f6-a5ac-41f5-8a79-7e4ce0cd56bc"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-68-13dd32348ee0>:4: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  data = torch.load(results_filename)\n"]}]},{"cell_type":"code","source":["accuracy_plot_path = os.path.join(results_dir, \"mnist_accuracy_none.png\")\n","loss_plot_path = os.path.join(results_dir, \"mnist_loss_none.png\")"],"metadata":{"id":"0i9LgZLo-gf-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Plot Accuracy\n","plt.plot(data['its'], data['train_acc'], label=\"Train Accuracy\")\n","plt.plot(data['its'], data['val_acc'], label=\"Validation Accuracy\")\n","plt.title(\"Accuracy over Optimization Steps\")\n","plt.xlabel(\"Optimization Steps\")\n","plt.ylabel(\"Accuracy\")\n","plt.xscale(\"log\")\n","plt.legend()\n","plt.grid()\n","plt.savefig(accuracy_plot_path, dpi=150)\n","plt.close()  # Close to avoid conflicts with the next plot\n","print(f\"Accuracy plot saved to {accuracy_plot_path}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"N2g-00D35tk1","executionInfo":{"status":"ok","timestamp":1736290474393,"user_tz":-120,"elapsed":883,"user":{"displayName":"Μαρια Σαμπανη","userId":"00480416348673556380"}},"outputId":"2cf315d6-fc8a-4c20-d0df-b6996ba69bb5"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy plot saved to /content/drive/MyDrive/PatRec_Project_Shared_Folder/results/mnist_accuracy_none.png\n"]}]},{"cell_type":"code","source":["# Plot Loss\n","plt.plot(data['its'], data['train_loss'], label=\"Train Loss\")\n","plt.plot(data['its'], data['val_loss'], label=\"Validation Loss\")\n","plt.title(\"Loss over Optimization Steps\")\n","plt.xlabel(\"Optimization Steps\")\n","plt.ylabel(\"Loss\")\n","plt.xscale(\"log\")\n","plt.yscale(\"log\")\n","plt.legend()\n","plt.grid()\n","plt.savefig(loss_plot_path, dpi=150)\n","plt.close()\n","print(f\"Loss plot saved to {loss_plot_path}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EOyJRF7w5vl3","executionInfo":{"status":"ok","timestamp":1736290508858,"user_tz":-120,"elapsed":816,"user":{"displayName":"Μαρια Σαμπανη","userId":"00480416348673556380"}},"outputId":"5d3da153-8a5b-49dc-e0b7-ffda1e1501af"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Loss plot saved to /content/drive/MyDrive/PatRec_Project_Shared_Folder/results/mnist_loss_none.png\n"]}]},{"cell_type":"code","source":["#Running MA algoritmh with alpha = 0.98 lamb = 0.1 weight_decay = 2.0 as recommended in github"],"metadata":{"id":"ai7aiM1x7a2w"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["if __name__ == '__main__':\n","    parser = ArgumentParser()\n","    parser.add_argument(\"--label\", default=\"\")\n","    parser.add_argument(\"--seed\", type=int, default=0)\n","\n","    parser.add_argument(\"--train_points\", type=int, default=1000)\n","    parser.add_argument(\"--optimization_steps\", type=int, default=100000)\n","    parser.add_argument(\"--batch_size\", type=int, default=200)\n","    parser.add_argument(\"--loss_function\", type=str, default=\"MSE\")\n","    parser.add_argument(\"--optimizer\", type=str, default=\"AdamW\")\n","    parser.add_argument(\"--weight_decay\", type=float, default=0.01)\n","    parser.add_argument(\"--lr\", type=float, default=1e-3)\n","    parser.add_argument(\"--initialization_scale\", type=float, default=8.0)\n","    parser.add_argument(\"--download_directory\", type=str, default=\".\")\n","    parser.add_argument(\"--depth\", type=int, default=3)\n","    parser.add_argument(\"--width\", type=int, default=200)\n","    parser.add_argument(\"--activation\", type=str, default=\"ReLU\")\n","\n","    # Grokfast\n","    parser.add_argument(\"--filter\", type=str, choices=[\"none\", \"ma\", \"ema\", \"fir\"], default=\"ma\")\n","    parser.add_argument(\"--alpha\", type=float, default=0.99)\n","    parser.add_argument(\"--window_size\", type=int, default=100)\n","    parser.add_argument(\"--lamb\", type=float, default=5.0)\n","    args = parser.parse_args([\n","    \"--alpha\" , \"0.98\",\n","    \"--weight_decay\", \"2.0\",\n","    \"--lamb\" , \"0.1\",\n","    ])\n","\n","    filter_str = ('_' if args.label != '' else '') + args.filter\n","    window_size_str = f'_w{args.window_size}'\n","    alpha_str = f'_a{args.alpha:.3f}'.replace('.', '')\n","    lamb_str = f'_l{args.lamb:.2f}'.replace('.', '')\n","\n","    if args.filter == 'none':\n","        filter_suffix = ''\n","    elif args.filter == 'ma':\n","        filter_suffix = window_size_str + lamb_str\n","    elif args.filter == 'ema':\n","        filter_suffix = alpha_str + lamb_str\n","    else:\n","        raise ValueError(f\"Unrecognized filter type {args.filter}\")\n","\n","    optim_suffix = ''\n","    if args.weight_decay != 0:\n","        optim_suffix = optim_suffix + f'_wd{args.weight_decay:.1e}'.replace('.', '')\n","    if args.lr != 1e-3:\n","        optim_suffix = optim_suffix + f'_lrx{int(args.lr / 1e-3)}'\n","\n","    args.label = args.label + filter_str + filter_suffix + optim_suffix\n","    print(f'Experiment results saved under name: {args.label}')\n","\n","    main(args)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":171,"referenced_widgets":["5267a3ad2d4f4e2894aeb99c24b754d9","01923172a9c547afbf7ad65549c2669a","de391ffce6c74d1089c9f82b716adf78","14f51e94e89f452fba3f2e4a0859611f","917570c63bac4c19aafb5c54b2b5fc18","51ef34c4b7404efcb3edf79b6c5fbffb","e587499941d94c40bbe67166df8f0ada","6eb6a248dea042449630c603fdd08930","73eb5d9db83c40bb8e4a060eb950f218","ebc1d631561d4990a3b3cb6e4dd52333","45d7fa5d9e6b4b56a4d66ced497c4fc0"]},"id":"ZaPjgyF2BCX_","outputId":"ccd89412-0955-4f2d-f9fd-97134888209d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Experiment results saved under name: ma_w100_l010_wd20e+00\n","Stratified train subset created with 1000 samples.\n","Number of parameters: 199210\n"]},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/100000 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5267a3ad2d4f4e2894aeb99c24b754d9"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["<ipython-input-19-5b74f0a56b34>:136: UserWarning: Data has no positive values, and therefore cannot be log-scaled.\n","  plt.xscale(\"log\", base=10)\n","<ipython-input-19-5b74f0a56b34>:147: UserWarning: Data has no positive values, and therefore cannot be log-scaled.\n","  plt.xscale(\"log\", base=10)\n"]}]},{"cell_type":"code","source":["#Running ΕMA algoritmh with same args as before"],"metadata":{"id":"7XGwH62ILOzx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["if __name__ == '__main__':\n","    parser = ArgumentParser()\n","    parser.add_argument(\"--label\", default=\"\")\n","    parser.add_argument(\"--seed\", type=int, default=0)\n","\n","    parser.add_argument(\"--train_points\", type=int, default=1000)\n","    parser.add_argument(\"--optimization_steps\", type=int, default=100000)\n","    parser.add_argument(\"--batch_size\", type=int, default=200)\n","    parser.add_argument(\"--loss_function\", type=str, default=\"MSE\")\n","    parser.add_argument(\"--optimizer\", type=str, default=\"AdamW\")\n","    parser.add_argument(\"--weight_decay\", type=float, default=0.01)\n","    parser.add_argument(\"--lr\", type=float, default=1e-3)\n","    parser.add_argument(\"--initialization_scale\", type=float, default=8.0)\n","    parser.add_argument(\"--download_directory\", type=str, default=\".\")\n","    parser.add_argument(\"--depth\", type=int, default=3)\n","    parser.add_argument(\"--width\", type=int, default=200)\n","    parser.add_argument(\"--activation\", type=str, default=\"ReLU\")\n","\n","    # Grokfast\n","    parser.add_argument(\"--filter\", type=str, choices=[\"none\", \"ma\", \"ema\", \"fir\"], default=\"ema\")\n","    parser.add_argument(\"--alpha\", type=float, default=0.99)\n","    parser.add_argument(\"--window_size\", type=int, default=100)\n","    parser.add_argument(\"--lamb\", type=float, default=5.0)\n","    args = parser.parse_args([\n","    \"--alpha\" , \"0.98\",\n","    \"--weight_decay\", \"2.0\",\n","    \"--lamb\" , \"0.1\",\n","    ])\n","\n","    filter_str = ('_' if args.label != '' else '') + args.filter\n","    window_size_str = f'_w{args.window_size}'\n","    alpha_str = f'_a{args.alpha:.3f}'.replace('.', '')\n","    lamb_str = f'_l{args.lamb:.2f}'.replace('.', '')\n","\n","    if args.filter == 'none':\n","        filter_suffix = ''\n","    elif args.filter == 'ma':\n","        filter_suffix = window_size_str + lamb_str\n","    elif args.filter == 'ema':\n","        filter_suffix = alpha_str + lamb_str\n","    else:\n","        raise ValueError(f\"Unrecognized filter type {args.filter}\")\n","\n","    optim_suffix = ''\n","    if args.weight_decay != 0:\n","        optim_suffix = optim_suffix + f'_wd{args.weight_decay:.1e}'.replace('.', '')\n","    if args.lr != 1e-3:\n","        optim_suffix = optim_suffix + f'_lrx{int(args.lr / 1e-3)}'\n","\n","    args.label = args.label + filter_str + filter_suffix + optim_suffix\n","    print(f'Experiment results saved under name: {args.label}')\n","\n","    main(args)"],"metadata":{"id":"c-pr6yMhLGWP","colab":{"base_uri":"https://localhost:8080/","height":171,"referenced_widgets":["520aa6dbf5e842f6bc3dc4f52fe9a931","7da7d91119f945aca7cc3c9a2f232711","308997b0853c4d58a4b716e59584fa3b","ce2d1b0fb355487a94e2e762bf4bc71c","0f76e4cb98774f1f81708370d4c5adbd","71b315b14ad6497e874ff47899bb59af","e78d337bc29a415fbde2140184e99e00","8ee63eda5bf542cf98f9f79fa51759be","4ad8b17e8a044df2b39bd8237a9a91da","727cff1f06aa4c1e847dcf558e35d054","56837a7b20664e21896e7e1593067107"]},"executionInfo":{"status":"ok","timestamp":1736331177781,"user_tz":-120,"elapsed":3380182,"user":{"displayName":"maria","userId":"16941552641738006094"}},"outputId":"1339312e-92d0-4240-e4e4-2fc7f9239b34"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Experiment results saved under name: ema_a0980_l010_wd20e+00\n","Stratified train subset created with 1000 samples.\n","Number of parameters: 199210\n"]},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/100000 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"520aa6dbf5e842f6bc3dc4f52fe9a931"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["<ipython-input-19-5b74f0a56b34>:136: UserWarning: Data has no positive values, and therefore cannot be log-scaled.\n","  plt.xscale(\"log\", base=10)\n","<ipython-input-19-5b74f0a56b34>:147: UserWarning: Data has no positive values, and therefore cannot be log-scaled.\n","  plt.xscale(\"log\", base=10)\n"]}]}]}